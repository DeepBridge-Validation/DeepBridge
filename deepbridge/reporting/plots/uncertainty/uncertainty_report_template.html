<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Uncertainty Analysis Report</title>
    <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            color: #333;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
        }
        h1 {
            color: #2c3e50;
            text-align: center;
            margin-bottom: 30px;
            padding-bottom: 10px;
            border-bottom: 2px solid #eee;
        }
        h2 {
            color: #9b59b6; /* Purple for uncertainty, different from robustness blue */
            margin-top: 30px;
            padding-bottom: 5px;
            border-bottom: 1px solid #eee;
        }
        .summary {
            background-color: #f8f9fa;
            padding: 20px;
            border-radius: 5px;
            margin-bottom: 30px;
            border-left: 5px solid #9b59b6; /* Purple for uncertainty */
        }
        .summary h2 {
            margin-top: 0;
            border-bottom: none;
        }
        .metric {
            font-weight: bold;
            margin-right: 5px;
        }
        .plot-container {
            margin: 30px 0;
            padding: 10px;
            background-color: white;
            box-shadow: 0 1px 3px rgba(0,0,0,0.1);
            border-radius: 5px;
        }
        .two-column {
            display: flex;
            gap: 20px;
            flex-wrap: wrap;
        }
        .two-column > div {
            flex: 1;
            min-width: 400px;
        }
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
        }
        th, td {
            border: 1px solid #ddd;
            padding: 8px 12px;
            text-align: left;
        }
        th {
            background-color: #f2f2f2;
            font-weight: bold;
        }
        tr:nth-child(even) {
            background-color: #f9f9f9;
        }
        .note {
            background-color: #f8f9fa;
            padding: 10px;
            border-left: 3px solid #ffc107;
            margin: 20px 0;
            font-size: 0.9em;
        }
        .tabs {
            display: flex;
            border-bottom: 1px solid #ddd;
            margin-bottom: 20px;
        }
        .tab {
            padding: 10px 20px;
            cursor: pointer;
            border: 1px solid transparent;
            border-bottom: none;
            background-color: #f1f1f1;
            margin-right: 5px;
            border-radius: 5px 5px 0 0;
        }
        .tab.active {
            background-color: white;
            border-color: #ddd;
            border-bottom-color: white;
        }
        .tab-content {
            display: none;
            padding: 15px;
            border: 1px solid #ddd;
            border-top: none;
        }
        .tab-content.active {
            display: block;
        }
        .score-card {
            background-color: #f8f9fa;
            padding: 15px;
            border-radius: 5px;
            margin-bottom: 15px;
            text-align: center;
        }
        .score-value {
            font-size: 2.5em;
            font-weight: bold;
            color: #9b59b6; /* Purple for uncertainty */
            margin: 10px 0;
        }
        .score-label {
            font-size: 1.2em;
            color: #666;
        }
        .feature-bar {
            height: 20px;
            background-color: #9b59b6;
            margin-bottom: 5px;
        }
        .color-scale {
            height: 20px;
            width: 100%;
            background: linear-gradient(to right, #f1c40f, #e74c3c);
            margin-top: 10px;
            position: relative;
            border-radius: 3px;
        }
        .color-scale-labels {
            display: flex;
            justify-content: space-between;
            margin-top: 5px;
            font-size: 0.8em;
            color: #666;
        }
        .uncertainty-band {
            stroke-width: 0;
            fill-opacity: 0.3;
        }
        .footer {
            margin-top: 50px;
            text-align: center;
            font-size: 0.8em;
            color: #666;
            border-top: 1px solid #eee;
            padding-top: 20px;
        }
    </style>
</head>
<body>
    <h1>Uncertainty Analysis Report</h1>
    
    <div class="summary">
        <h2>Executive Summary</h2>
        <p>This report provides an analysis of uncertainty quantification for <b>{{ model_name }}</b> with the following metrics:</p>
        <p>
            <span class="metric">Calibration Score:</span> {{ "%.3f"|format(calibration_score) }}<br>
            <span class="metric">Average Confidence Interval Width:</span> {{ "%.3f"|format(avg_interval_width) }}<br>
            <span class="metric">Empirical Coverage Rate:</span> {{ "%.1f"|format(coverage_rate * 100) }}%<br>
            <span class="metric">Test Metric ({{ metric_name }}):</span> {{ "%.3f"|format(base_score) }}
        </p>
        <p>The model was evaluated using the {{ experiment_type }} approach on a dataset with {{ n_samples }} samples and {{ n_features }} features.</p>
    </div>
    
    <div class="tabs">
        <div class="tab active" onclick="switchTab(event, 'overview')">Overview</div>
        <div class="tab" onclick="switchTab(event, 'comparison')">Model Comparison</div>
        <div class="tab" onclick="switchTab(event, 'feature-analysis')">Feature Analysis</div>
        <div class="tab" onclick="switchTab(event, 'calibration')">Calibration Analysis</div>
    </div>
    
    <div id="overview" class="tab-content active">
        <h2>Performance Overview</h2>
        
        <div class="two-column">
            <div>
                <div class="score-card">
                    <div class="score-label">Calibration Score</div>
                    <div class="score-value">{{ "%.3f"|format(calibration_score) }}</div>
                    <div>How well the model's uncertainty estimations match observed error rates</div>
                </div>
            </div>
            <div>
                <div class="score-card">
                    <div class="score-label">Coverage Rate</div>
                    <div class="score-value">{{ "%.1f"|format(coverage_rate * 100) }}%</div>
                    <div>Percentage of test points where the true value falls within predicted uncertainty intervals</div>
                </div>
            </div>
        </div>
        
        <h2>Uncertainty Intervals Analysis</h2>
        <div class="plot-container">
            <div id="interval-widths-plot"></div>
        </div>
        <p>This plot shows the distribution of uncertainty interval widths across different alpha (confidence) levels.</p>
        
        <div class="plot-container">
            <div id="coverage-vs-width-plot"></div>
        </div>
        <p>This plot shows the trade-off between coverage probability and interval width.</p>
    </div>
    
    <div id="comparison" class="tab-content">
        <h2>Model Comparison</h2>
        
        <div class="plot-container">
            <div id="model-metrics-radar-plot"></div>
        </div>
        <p>This radar chart compares the primary model with alternative models across key metrics.</p>
        
        <div class="plot-container">
            <div id="uncertainty-comparison-plot"></div>
        </div>
        <p>This chart compares uncertainty metrics across different models.</p>
        
        <h2>Model Metrics</h2>
        <table>
            <tr>
                <th>Model</th>
                <th>Calibration Score</th>
                <th>Coverage Rate</th>
                <th>Avg. Width</th>
                <th>{{ metric_name }}</th>
            </tr>
            <tr>
                <td>{{ model_name }}</td>
                <td>{{ "%.3f"|format(calibration_score) }}</td>
                <td>{{ "%.1f"|format(coverage_rate * 100) }}%</td>
                <td>{{ "%.3f"|format(avg_interval_width) }}</td>
                <td>{{ "%.3f"|format(base_score) }}</td>
            </tr>
            {% for model in alt_models %}
            <tr>
                <td>{{ model.name }}</td>
                <td>{{ "%.3f"|format(model.calibration_score) }}</td>
                <td>{{ "%.1f"|format(model.coverage_rate * 100) }}%</td>
                <td>{{ "%.3f"|format(model.avg_interval_width) }}</td>
                <td>{{ "%.3f"|format(model.base_score) }}</td>
            </tr>
            {% endfor %}
        </table>
    </div>
    
    <div id="feature-analysis" class="tab-content">
        <h2>Feature Importance for Uncertainty</h2>
        
        <div class="plot-container">
            <div id="feature-importance-plot"></div>
        </div>
        <p>This plot shows how each feature contributes to model uncertainty in predictions.</p>
        
        <h2>Important Features</h2>
        <table>
            <tr>
                <th>Feature</th>
                <th>Importance (%)</th>
                <th>Impact on Uncertainty</th>
            </tr>
            {% for feature in feature_importance_pct[:10] %}
            <tr>
                <td>{{ feature[0] }}</td>
                <td>{{ "%.2f"|format(feature[1]) }}%</td>
                <td>
                    <div class="feature-bar" style="width: {{ feature[1] }}%"></div>
                </td>
            </tr>
            {% endfor %}
        </table>
    </div>
    
    <div id="calibration" class="tab-content">
        <h2>Calibration Analysis</h2>
        
        <div class="plot-container">
            <div id="calibration-curve-plot"></div>
        </div>
        <p>This plot shows the calibration curve, comparing expected vs. actual probabilities.</p>
        
        <div class="plot-container">
            <div id="calibration-histogram-plot"></div>
        </div>
        <p>This histogram shows the distribution of predicted probabilities, which helps assess calibration.</p>
        
        <h2>Alpha Level Analysis</h2>
        <div class="plot-container">
            <div id="alpha-level-plot"></div>
        </div>
        <p>This plot shows how uncertainty metrics change across different confidence levels (alpha).</p>
    </div>
    
    <div class="footer">
        <p>Report generated by DeepBridge UncertaintyReportGenerator</p>
    </div>
    
    <script>
        // Tab switching functionality
        function switchTab(evt, tabName) {
            let tabs = document.getElementsByClassName('tab');
            for (let i = 0; i < tabs.length; i++) {
                tabs[i].className = tabs[i].className.replace(" active", "");
            }
            
            let tabcontent = document.getElementsByClassName('tab-content');
            for (let i = 0; i < tabcontent.length; i++) {
                tabcontent[i].className = tabcontent[i].className.replace(" active", "");
            }
            
            document.getElementById(tabName).className += " active";
            evt.currentTarget.className += " active";
        }
        
        // Plotly chart for interval widths
        const intervalWidthsData = {
            x: {{ alpha_levels|tojson }},
            y: {{ interval_widths|tojson }},
            mode: 'lines+markers',
            name: 'Interval Width',
            line: {color: '#9b59b6', width: 3},
            marker: {size: 8}
        };
        
        Plotly.newPlot('interval-widths-plot', [intervalWidthsData], {
            title: 'Interval Width vs Alpha Levels',
            xaxis: {title: 'Alpha Level'},
            yaxis: {title: 'Average Interval Width'},
            margin: {l: 50, r: 50, b: 50, t: 50, pad: 4}
        });
        
        // Plotly chart for coverage vs width
        const coverageWidthData = {
            x: {{ coverage_rates|tojson }},
            y: {{ interval_widths|tojson }},
            mode: 'lines+markers',
            name: 'Width vs Coverage',
            line: {color: '#9b59b6', width: 3},
            marker: {size: 8}
        };
        
        Plotly.newPlot('coverage-vs-width-plot', [coverageWidthData], {
            title: 'Interval Width vs Coverage Rate',
            xaxis: {title: 'Coverage Rate', range: [0, 1]},
            yaxis: {title: 'Average Interval Width'},
            margin: {l: 50, r: 50, b: 50, t: 50, pad: 4}
        });
        
        // Radar chart for model comparison
        const modelNames = ['{{ model_name }}', {% for model in alt_models %}'{{ model.name }}'{% if not loop.last %}, {% endif %}{% endfor %}];
        const metrics = ['Accuracy', 'ROC AUC', 'F1 Score', 'Precision', 'Recall'];
        
        const primaryMetrics = {{ primary_metrics_values|tojson }};
        const alternativeMetricsValues = {{ alt_metrics_values|tojson }};
        
        const radarData = [{
            type: 'scatterpolar',
            r: primaryMetrics,
            theta: metrics,
            fill: 'toself',
            name: '{{ model_name }}',
            line: {color: '#9b59b6'}
        }];
        
        {% for i in range(alt_metrics_values|length) %}
        radarData.push({
            type: 'scatterpolar',
            r: alternativeMetricsValues[{{ i }}],
            theta: metrics,
            fill: 'toself',
            name: modelNames[{{ i+1 }}],
            line: {color: 'rgba(149, 165, 166, 0.8)'}
        });
        {% endfor %}
        
        Plotly.newPlot('model-metrics-radar-plot', radarData, {
            polar: {
                radialaxis: {
                    visible: true,
                    range: [0, 1]
                }
            },
            showlegend: true,
            margin: {l: 50, r: 50, b: 50, t: 50, pad: 4}
        });
        
        // Uncertainty comparison chart
        const uncertaintyMetrics = ['Calibration Score', 'Coverage Rate', 'Avg Width'];
        
        // Primary model uncertainty metrics
        const primaryUncertaintyMetrics = [
            {{ calibration_score }},
            {{ coverage_rate }},
            {{ avg_interval_width }}
        ];
        
        // Alternative models uncertainty metrics
        const altUncertaintyMetrics = [
            {% for model in alt_models %}
            [{{ model.calibration_score }}, {{ model.coverage_rate }}, {{ model.avg_interval_width }}]{% if not loop.last %},{% endif %}
            {% endfor %}
        ];
        
        const uncertaintyData = [{
            x: uncertaintyMetrics,
            y: primaryUncertaintyMetrics,
            type: 'bar',
            name: '{{ model_name }}',
            marker: {color: '#9b59b6'}
        }];
        
        {% for i in range(alt_models|length) %}
        uncertaintyData.push({
            x: uncertaintyMetrics,
            y: altUncertaintyMetrics[{{ i }}],
            type: 'bar',
            name: modelNames[{{ i+1 }}],
            marker: {color: 'rgba(149, 165, 166, 0.8)'}
        });
        {% endfor %}
        
        Plotly.newPlot('uncertainty-comparison-plot', uncertaintyData, {
            title: 'Uncertainty Metrics Comparison',
            barmode: 'group',
            margin: {l: 50, r: 50, b: 50, t: 50, pad: 4}
        });
        
        // Feature importance chart
        const featureNames = {{ feature_names|tojson }};
        const featureImportance = {{ feature_importance_values|tojson }};
        
        const featureData = [{
            y: featureNames.slice(0, 10).reverse(),
            x: featureImportance.slice(0, 10).reverse(),
            type: 'bar',
            orientation: 'h',
            marker: {
                color: '#9b59b6'
            }
        }];
        
        Plotly.newPlot('feature-importance-plot', featureData, {
            title: 'Top 10 Features by Uncertainty Importance',
            margin: {l: 150, r: 50, b: 50, t: 50, pad: 4}
        });
        
        // Calibration curve
        const expectedProbs = {{ calibration_curve.expected|tojson }};
        const actualProbs = {{ calibration_curve.actual|tojson }};
        
        const idealLine = {
            x: [0, 1],
            y: [0, 1],
            mode: 'lines',
            name: 'Ideal',
            line: {
                dash: 'dash',
                width: 2,
                color: '#7f8c8d'
            }
        };
        
        const calibrationLine = {
            x: expectedProbs,
            y: actualProbs,
            mode: 'lines+markers',
            name: 'Model',
            line: {color: '#9b59b6', width: 3},
            marker: {size: 8}
        };
        
        Plotly.newPlot('calibration-curve-plot', [idealLine, calibrationLine], {
            title: 'Calibration Curve',
            xaxis: {title: 'Expected Probability', range: [0, 1]},
            yaxis: {title: 'Actual Frequency', range: [0, 1]},
            margin: {l: 50, r: 50, b: 50, t: 50, pad: 4}
        });
        
        // Calibration histogram
        const histData = [{
            x: {{ calibration_histogram|tojson }},
            type: 'histogram',
            marker: {color: '#9b59b6'},
            opacity: 0.7
        }];
        
        Plotly.newPlot('calibration-histogram-plot', histData, {
            title: 'Distribution of Predicted Probabilities',
            xaxis: {title: 'Predicted Probability', range: [0, 1]},
            yaxis: {title: 'Count'},
            margin: {l: 50, r: 50, b: 50, t: 50, pad: 4}
        });
        
        // Alpha level metrics
        const alphaLevelData = [{
            x: {{ alpha_levels|tojson }},
            y: {{ coverage_rates|tojson }},
            mode: 'lines+markers',
            name: 'Coverage Rate',
            line: {color: '#9b59b6', width: 3},
            marker: {size: 8}
        }, {
            x: {{ alpha_levels|tojson }},
            y: {{ alpha_levels|tojson }},
            mode: 'lines',
            name: 'Ideal Coverage',
            line: {
                dash: 'dash',
                width: 2,
                color: '#7f8c8d'
            }
        }];
        
        Plotly.newPlot('alpha-level-plot', alphaLevelData, {
            title: 'Coverage Rate vs Alpha Level',
            xaxis: {title: 'Alpha Level', range: [0, 1]},
            yaxis: {title: 'Coverage Rate', range: [0, 1]},
            margin: {l: 50, r: 50, b: 50, t: 50, pad: 4}
        });
    </script>
</body>
</html>