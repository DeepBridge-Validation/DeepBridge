"""
An√°lise de Fairness em Dados de Produ√ß√£o
=========================================

Este script analisa fairness em modelos j√° treinados com predi√ß√µes existentes.

Dados:
- train_predictions.parquet
- test_predictions.parquet

Target: in_cmst_fun
Probabilidades: pred_proba_class_0, pred_proba_class_1
Classe predita: pred_class (com threshold customizado)

Atributos Protegidos:
- nm_tip_gnr (g√™nero)
- nm_tip_raca (ra√ßa)
- vl_idd_aa (idade)
"""

import numpy as np
import pandas as pd
from pathlib import Path
from sklearn.base import BaseEstimator, ClassifierMixin
import warnings
warnings.filterwarnings('ignore')

# DeepBridge imports
from deepbridge.core.db_data import DBDataset
from deepbridge.core.experiment.experiment import Experiment
from deepbridge.validation.wrappers import FairnessSuite
from deepbridge.validation.fairness import FairnessVisualizer

# ============================================================================
# CLASSE WRAPPER PARA MODELO COM PREDI√á√ïES PR√â-COMPUTADAS
# ============================================================================

class PrecomputedPredictionsModel(BaseEstimator, ClassifierMixin):
    """
    Wrapper que simula um modelo sklearn mas usa predi√ß√µes j√° calculadas.

    √ötil quando voc√™ tem um modelo j√° treinado e quer analisar fairness
    das predi√ß√µes existentes sem re-treinar.
    """

    def __init__(self, predictions_df, proba_cols=['pred_proba_class_0', 'pred_proba_class_1']):
        """
        Parameters:
            predictions_df: DataFrame com as predi√ß√µes
            proba_cols: Colunas com probabilidades por classe
        """
        self.predictions_df = predictions_df.copy()
        self.proba_cols = proba_cols
        self.classes_ = np.array([0, 1])  # Binary classification
        self.n_classes_ = 2

        # Criar √≠ndice para lookup r√°pido
        self.predictions_df['_index'] = range(len(self.predictions_df))

    def fit(self, X, y):
        """N√£o faz nada - modelo j√° est√° 'treinado'"""
        return self

    def predict(self, X):
        """
        Retorna predi√ß√µes usando os √≠ndices para fazer lookup.

        IMPORTANTE: Assume que X tem os mesmos √≠ndices do DataFrame original.
        """
        if isinstance(X, pd.DataFrame):
            indices = X.index
        else:
            # Se for numpy array, assumir ordem sequencial
            indices = range(len(X))

        # Fazer lookup das predi√ß√µes
        predictions = self.predictions_df.loc[indices, 'pred_class'].values

        return predictions

    def predict_proba(self, X):
        """
        Retorna probabilidades usando os √≠ndices para fazer lookup.
        """
        if isinstance(X, pd.DataFrame):
            indices = X.index
        else:
            indices = range(len(X))

        # Fazer lookup das probabilidades
        probas = self.predictions_df.loc[indices, self.proba_cols].values

        return probas

# ============================================================================
# CONFIGURA√á√ïES
# ============================================================================

print("=" * 80)
print("AN√ÅLISE DE FAIRNESS - DADOS DE PRODU√á√ÉO")
print("=" * 80)

# Paths dos dados
DATA_DIR = Path("/home/guhaase/projetos/DeepBridge/simular_lib/analise_v4")
TRAIN_PATH = DATA_DIR / "train_predictions.parquet"
TEST_PATH = DATA_DIR / "test_predictions.parquet"

# Configura√ß√µes
TARGET_COL = 'in_cmst_fun'
PROBA_COLS = ['pred_proba_class_0', 'pred_proba_class_1']
PRED_COL = 'pred_class'

# Atributos protegidos (ajuste conforme necess√°rio)
PROTECTED_ATTRIBUTES = ['nm_tip_gnr', 'nm_tip_raca']  # G√™nero e Ra√ßa
# Nota: vl_idd_aa (idade) pode ser adicionado ap√≥s criar grupos et√°rios

# Diret√≥rio de output
OUTPUT_DIR = Path('./fairness_production_analysis')
OUTPUT_DIR.mkdir(exist_ok=True)

print(f"\nüìÅ Diret√≥rios configurados:")
print(f"   Dados: {DATA_DIR}")
print(f"   Output: {OUTPUT_DIR.absolute()}")

# ============================================================================
# PASSO 1: CARREGAR DADOS
# ============================================================================

print("\n" + "=" * 80)
print("PASSO 1: Carregando Dados")
print("=" * 80)

print("\n1. Carregando train_predictions.parquet...")
df_train = pd.read_parquet(TRAIN_PATH)
print(f"   ‚úì Train: {df_train.shape}")

print("\n2. Carregando test_predictions.parquet...")
df_test = pd.read_parquet(TEST_PATH)
print(f"   ‚úì Test: {df_test.shape}")

# Verificar se colunas necess√°rias existem
required_cols = [TARGET_COL] + PROBA_COLS + [PRED_COL] + PROTECTED_ATTRIBUTES
missing_cols = [col for col in required_cols if col not in df_train.columns]

if missing_cols:
    print(f"\n   ‚ö†Ô∏è  AVISO: Colunas faltando: {missing_cols}")
    print(f"   Colunas dispon√≠veis: {list(df_train.columns)}")
    raise ValueError(f"Colunas necess√°rias n√£o encontradas: {missing_cols}")

print(f"\n   ‚úì Todas as colunas necess√°rias presentes")

# ============================================================================
# PASSO 2: AN√ÅLISE EXPLORAT√ìRIA INICIAL
# ============================================================================

print("\n" + "=" * 80)
print("PASSO 2: An√°lise Explorat√≥ria")
print("=" * 80)

# Usar dados de test para an√°lise (mais representativo de produ√ß√£o)
df = df_test.copy()

print(f"\nüìä ESTAT√çSTICAS GERAIS (Test Set):")
print(f"   Total de amostras: {len(df):,}")
print(f"   Target ({TARGET_COL}):")

# Distribui√ß√£o do target
target_dist = df[TARGET_COL].value_counts()
print(f"      Classe 0: {target_dist.get(0, 0):,} ({target_dist.get(0, 0)/len(df):.1%})")
print(f"      Classe 1: {target_dist.get(1, 0):,} ({target_dist.get(1, 0)/len(df):.1%})")

# Distribui√ß√£o das predi√ß√µes
print(f"\n   Predi√ß√µes ({PRED_COL}):")
pred_dist = df[PRED_COL].value_counts()
print(f"      Classe 0: {pred_dist.get(0, 0):,} ({pred_dist.get(0, 0)/len(df):.1%})")
print(f"      Classe 1: {pred_dist.get(1, 0):,} ({pred_dist.get(1, 0)/len(df):.1%})")

# Acur√°cia geral
accuracy = (df[TARGET_COL] == df[PRED_COL]).mean()
print(f"\n   Acur√°cia geral: {accuracy:.3f}")

# ============================================================================
# PASSO 3: AN√ÅLISE DE ATRIBUTOS PROTEGIDOS
# ============================================================================

print("\n" + "=" * 80)
print("PASSO 3: An√°lise de Atributos Protegidos")
print("=" * 80)

for attr in PROTECTED_ATTRIBUTES:
    print(f"\nüìä {attr.upper()}:")

    # Verificar valores √∫nicos
    unique_vals = df[attr].value_counts()
    print(f"   Valores √∫nicos: {len(unique_vals)}")

    # Top 5 valores
    print(f"   Top 5 grupos:")
    for val, count in unique_vals.head(5).items():
        pct = count / len(df) * 100
        print(f"      {val}: {count:,} ({pct:.1f}%)")

    # Taxa de aprova√ß√£o por grupo (assumindo classe 1 = aprovado)
    print(f"\n   Taxa de aprova√ß√£o (classe 1) por grupo:")
    approval_by_group = df.groupby(attr)[TARGET_COL].mean()

    for val, rate in approval_by_group.head(10).items():
        print(f"      {val}: {rate:.1%}")

    # Taxa de PREDI√á√ÉO positiva por grupo
    print(f"\n   Taxa de PREDI√á√ÉO positiva por grupo:")
    pred_by_group = df.groupby(attr)[PRED_COL].mean()

    for val, rate in pred_by_group.head(10).items():
        print(f"      {val}: {rate:.1%}")

# ============================================================================
# PASSO 4: CRIAR GRUPOS ET√ÅRIOS (OPCIONAL)
# ============================================================================

print("\n" + "=" * 80)
print("PASSO 4: Criando Grupos Et√°rios")
print("=" * 80)

if 'vl_idd_aa' in df.columns:
    print("\n1. Analisando distribui√ß√£o de idade...")

    # Estat√≠sticas de idade
    print(f"   Idade m√≠nima: {df['vl_idd_aa'].min():.0f} anos")
    print(f"   Idade m√°xima: {df['vl_idd_aa'].max():.0f} anos")
    print(f"   Idade m√©dia: {df['vl_idd_aa'].mean():.1f} anos")
    print(f"   Idade mediana: {df['vl_idd_aa'].median():.1f} anos")

    print("\n2. Criando grupos et√°rios...")

    # Criar grupos et√°rios
    df['age_group'] = pd.cut(
        df['vl_idd_aa'],
        bins=[0, 30, 40, 50, 60, 100],
        labels=['18-30', '31-40', '41-50', '51-60', '60+'],
        include_lowest=True
    )

    # Adicionar aos atributos protegidos
    PROTECTED_ATTRIBUTES.append('age_group')

    print(f"   ‚úì Grupos criados:")
    for group, count in df['age_group'].value_counts().sort_index().items():
        pct = count / len(df) * 100
        print(f"      {group}: {count:,} ({pct:.1f}%)")

    print(f"\n   Taxa de aprova√ß√£o por grupo et√°rio:")
    approval_by_age = df.groupby('age_group')[TARGET_COL].mean()
    for group, rate in approval_by_age.items():
        print(f"      {group}: {rate:.1%}")
else:
    print("\n   ‚ö†Ô∏è  Coluna 'vl_idd_aa' n√£o encontrada - pulando grupos et√°rios")

print(f"\n‚úì Atributos protegidos finais: {PROTECTED_ATTRIBUTES}")

# ============================================================================
# PASSO 5: PREPARAR DADOS PARA AN√ÅLISE DE FAIRNESS
# ============================================================================

print("\n" + "=" * 80)
print("PASSO 5: Preparando Dados para An√°lise de Fairness")
print("=" * 80)

# Features s√£o todas as colunas EXCETO target, predi√ß√µes e atributos protegidos
exclude_cols = [TARGET_COL] + PROBA_COLS + [PRED_COL] + PROTECTED_ATTRIBUTES + ['_index']
feature_cols = [col for col in df.columns if col not in exclude_cols]

print(f"\n1. Features selecionadas: {len(feature_cols)} colunas")
print(f"   (Primeiras 10: {feature_cols[:10]})")

# Criar DataFrame final
# IMPORTANTE: Manter o index original para o wrapper funcionar
df_analysis = df.copy()

# Garantir que n√£o h√° NaN nas colunas cr√≠ticas
print(f"\n2. Verificando valores ausentes...")
critical_cols = [TARGET_COL] + PROBA_COLS + [PRED_COL] + PROTECTED_ATTRIBUTES
for col in critical_cols:
    nan_count = df_analysis[col].isna().sum()
    if nan_count > 0:
        print(f"   ‚ö†Ô∏è  {col}: {nan_count} NaN encontrados")
        # Remover linhas com NaN em colunas cr√≠ticas
        df_analysis = df_analysis.dropna(subset=[col])

print(f"   ‚úì Dataset final: {df_analysis.shape}")

# ============================================================================
# PASSO 6: CRIAR MODELO WRAPPER
# ============================================================================

print("\n" + "=" * 80)
print("PASSO 6: Criando Modelo Wrapper")
print("=" * 80)

print("\n1. Criando PrecomputedPredictionsModel...")

# Criar modelo wrapper
model = PrecomputedPredictionsModel(
    predictions_df=df_analysis,
    proba_cols=PROBA_COLS
)

print(f"   ‚úì Modelo criado")
print(f"   Classes: {model.classes_}")

# Testar modelo
print("\n2. Testando modelo wrapper...")
X_sample = df_analysis[feature_cols].iloc[:5]
y_pred_test = model.predict(X_sample)
y_proba_test = model.predict_proba(X_sample)

print(f"   ‚úì predict() funcionando: {y_pred_test}")
print(f"   ‚úì predict_proba() funcionando: shape {y_proba_test.shape}")

# ============================================================================
# PASSO 7: CRIAR DBDATASET
# ============================================================================

print("\n" + "=" * 80)
print("PASSO 7: Criando DBDataset")
print("=" * 80)

print("\n1. Preparando dados...")

# Criar dataset completo (com atributos protegidos para an√°lise)
dataset = DBDataset(
    data=df_analysis,
    target_column=TARGET_COL,
    model=model
)

print(f"   ‚úì DBDataset criado: {df_analysis.shape}")

# ============================================================================
# PASSO 8: AN√ÅLISE DE FAIRNESS - QUICK
# ============================================================================

print("\n" + "=" * 80)
print("PASSO 8: An√°lise de Fairness - Quick (Preview)")
print("=" * 80)

print("\n1. Criando Experiment...")

experiment = Experiment(
    dataset=dataset,
    experiment_type="binary_classification",
    tests=["fairness"],
    protected_attributes=PROTECTED_ATTRIBUTES,
    test_size=0.2,  # Mesmo que j√° seja test set, precisamos de um split interno
    random_state=42
)

print(f"   ‚úì Experiment criado")
print(f"   Protected attributes: {experiment.protected_attributes}")

print("\n2. Executando an√°lise r√°pida (config='quick')...")
print("   (Tempo estimado: 10-30 segundos)")

quick_result = experiment.run_fairness_tests(config='quick')

print(f"\n3. Resultados Quick:")
print(f"   Overall Fairness Score: {quick_result.overall_fairness_score:.3f}")
print(f"   Critical Issues: {len(quick_result.critical_issues)}")
print(f"   Warnings: {len(quick_result.warnings)}")

if quick_result.critical_issues:
    print(f"\n   ‚ö†Ô∏è  CRITICAL ISSUES (primeiros 3):")
    for issue in quick_result.critical_issues[:3]:
        print(f"      - {issue}")

if quick_result.warnings:
    print(f"\n   ‚ö†Ô∏è  WARNINGS (primeiros 3):")
    for warning in quick_result.warnings[:3]:
        print(f"      - {warning}")

# ============================================================================
# PASSO 9: AN√ÅLISE DE FAIRNESS - FULL
# ============================================================================

print("\n" + "=" * 80)
print("PASSO 9: An√°lise de Fairness - Full (Completa)")
print("=" * 80)

print("\n1. Executando an√°lise completa (config='full')...")
print("   ‚ö†Ô∏è  Isso pode levar 5-10 minutos dependendo do tamanho dos dados...")
print("   (Inclui threshold analysis com 99 thresholds)")

full_result = experiment.run_fairness_tests(config='full')

print(f"\n2. Resultados Full:")
print(f"   Overall Fairness Score: {full_result.overall_fairness_score:.3f}")
print(f"   Critical Issues: {len(full_result.critical_issues)}")
print(f"   Warnings: {len(full_result.warnings)}")
print(f"   Protected Attributes: {full_result.protected_attributes}")

# Interpreta√ß√£o do score
score = full_result.overall_fairness_score
if score >= 0.90:
    interpretation = "‚úÖ EXCELENTE - Modelo apresenta fairness muito boa"
    recommendation = "Considerar deploy em produ√ß√£o. Monitorar continuamente."
elif score >= 0.80:
    interpretation = "‚úì BOA - Modelo apresenta fairness aceit√°vel"
    recommendation = "Revisar warnings antes do deploy. Considerar melhorias."
elif score >= 0.70:
    interpretation = "‚ö†Ô∏è  MODERADA - Modelo apresenta problemas de fairness"
    recommendation = "Recomenda-se retreinar com t√©cnicas de mitiga√ß√£o de vi√©s."
else:
    interpretation = "‚ùå CR√çTICA - Modelo apresenta vi√©s significativo"
    recommendation = "N√ÉO recomendado para deploy. Investigar fontes de vi√©s."

print(f"\n3. Interpreta√ß√£o:")
print(f"   {interpretation}")
print(f"\n   Recomenda√ß√£o:")
print(f"   {recommendation}")

# ============================================================================
# PASSO 10: GERAR RELAT√ìRIOS HTML
# ============================================================================

print("\n" + "=" * 80)
print("PASSO 10: Gerando Relat√≥rios HTML")
print("=" * 80)

print("\n1. Relat√≥rio Quick...")
quick_report_path = full_result.save_html(
    file_path=str(OUTPUT_DIR / 'fairness_report_quick.html'),
    model_name='Modelo de Produ√ß√£o - Quick Analysis',
    report_type="interactive"  # Mesmo padr√£o dos outros m√≥dulos
)
print(f"   ‚úì Salvo: {Path(quick_report_path).name}")

print("\n2. Relat√≥rio Full...")
full_report_path = full_result.save_html(
    file_path=str(OUTPUT_DIR / 'fairness_report_full.html'),
    model_name='Modelo de Produ√ß√£o - Full Analysis',
    report_type="interactive"  # Mesmo padr√£o dos outros m√≥dulos
)
print(f"   ‚úì Salvo: {Path(full_report_path).name}")

# ============================================================================
# PASSO 11: GERAR VISUALIZA√á√ïES EST√ÅTICAS
# ============================================================================

print("\n" + "=" * 80)
print("PASSO 11: Gerando Visualiza√ß√µes Est√°ticas")
print("=" * 80)

# Visualiza√ß√µes por atributo protegido
for attr in PROTECTED_ATTRIBUTES:
    print(f"\nüìä Visualiza√ß√µes para '{attr}':")

    # 1. Distribui√ß√£o
    try:
        viz_path = FairnessVisualizer.plot_distribution_by_group(
            df=df_analysis,
            target_col=TARGET_COL,
            sensitive_feature=attr,
            output_path=str(OUTPUT_DIR / f'distribution_{attr}.png')
        )
        print(f"   ‚úì Distribui√ß√£o salva: distribution_{attr}.png")
    except Exception as e:
        print(f"   ‚ö†Ô∏è  Erro ao gerar distribui√ß√£o: {e}")

# Compara√ß√£o de m√©tricas (todas os atributos)
print(f"\nüìä Visualiza√ß√£o comparativa:")

try:
    results = full_result._results
    viz_path = FairnessVisualizer.plot_metrics_comparison(
        metrics_results=results['posttrain_metrics'],
        protected_attrs=PROTECTED_ATTRIBUTES,
        output_path=str(OUTPUT_DIR / 'metrics_comparison.png')
    )
    print(f"   ‚úì Compara√ß√£o salva: metrics_comparison.png")
except Exception as e:
    print(f"   ‚ö†Ô∏è  Erro ao gerar compara√ß√£o: {e}")

# Radar de fairness
try:
    viz_path = FairnessVisualizer.plot_fairness_radar(
        metrics_summary=results['posttrain_metrics'],
        output_path=str(OUTPUT_DIR / 'fairness_radar.png')
    )
    print(f"   ‚úì Radar salvo: fairness_radar.png")
except Exception as e:
    print(f"   ‚ö†Ô∏è  Erro ao gerar radar: {e}")

# ============================================================================
# PASSO 12: AN√ÅLISE DETALHADA POR M√âTRICA
# ============================================================================

print("\n" + "=" * 80)
print("PASSO 12: An√°lise Detalhada por M√©trica")
print("=" * 80)

results = full_result._results

# M√©tricas chave para an√°lise
key_metrics = [
    'statistical_parity',
    'disparate_impact',
    'equal_opportunity',
    'equalized_odds'
]

for metric_name in key_metrics:
    print(f"\nüìä {metric_name.upper().replace('_', ' ')}:")

    for attr in PROTECTED_ATTRIBUTES:
        if attr in results['posttrain_metrics']:
            attr_metrics = results['posttrain_metrics'][attr]

            if metric_name in attr_metrics:
                metric_data = attr_metrics[metric_name]
                value = metric_data.get('value', 'N/A')
                interpretation = metric_data.get('interpretation', '')

                # Formata√ß√£o especial para disparate impact (EEOC)
                if metric_name == 'disparate_impact':
                    eeoc_status = "‚úì EEOC OK" if isinstance(value, (int, float)) and value >= 0.80 else "‚úó EEOC VIOLADO"
                    print(f"   {attr}: {value:.3f if isinstance(value, (int, float)) else value} - {interpretation} ({eeoc_status})")
                else:
                    print(f"   {attr}: {value:.3f if isinstance(value, (int, float)) else value} - {interpretation}")

# Threshold Analysis (se dispon√≠vel)
if 'threshold_analysis' in results:
    print(f"\nüìä THRESHOLD ANALYSIS:")
    threshold_data = results['threshold_analysis']

    optimal = threshold_data.get('optimal_threshold', 'N/A')
    print(f"\n   Threshold atual do modelo: [customizado]")
    print(f"   Threshold √≥timo (fairness): {optimal:.3f if isinstance(optimal, (int, float)) else optimal}")

    if isinstance(optimal, (int, float)):
        print(f"\n   üí° SUGEST√ÉO: Considerar ajustar threshold para {optimal:.3f}")
        print(f"      para melhorar fairness (analisar impacto em performance)")

# ============================================================================
# PASSO 13: RESUMO FINAL E RECOMENDA√á√ïES
# ============================================================================

print("\n" + "=" * 80)
print("RESUMO FINAL E RECOMENDA√á√ïES")
print("=" * 80)

print(f"\nüìä ESTAT√çSTICAS:")
print(f"   Amostras analisadas: {len(df_analysis):,}")
print(f"   Atributos protegidos: {len(PROTECTED_ATTRIBUTES)}")
print(f"   Overall Fairness Score: {full_result.overall_fairness_score:.3f}")
print(f"   Critical Issues: {len(full_result.critical_issues)}")
print(f"   Warnings: {len(full_result.warnings)}")

print(f"\nüìÅ ARQUIVOS GERADOS:")
generated_files = sorted(OUTPUT_DIR.glob('*'))
for f in generated_files:
    if f.is_file():
        size_kb = f.stat().st_size / 1024
        icon = "üåê" if f.suffix == '.html' else "üìä"
        print(f"   {icon} {f.name} ({size_kb:.1f} KB)")

print(f"\nüí° PR√ìXIMOS PASSOS:")

if full_result.overall_fairness_score >= 0.80:
    print(f"   1. ‚úÖ Modelo apresenta fairness aceit√°vel")
    print(f"   2. Revisar relat√≥rio HTML completo")
    print(f"   3. Validar com stakeholders")
    print(f"   4. Implementar monitoramento cont√≠nuo")
else:
    print(f"   1. ‚ö†Ô∏è  Modelo apresenta problemas de fairness")
    print(f"   2. Revisar critical issues e warnings")
    print(f"   3. Considerar t√©cnicas de mitiga√ß√£o:")
    print(f"      - Re-balanceamento de dados")
    print(f"      - Ajuste de threshold")
    print(f"      - Fairness constraints")
    print(f"   4. Re-treinar e re-avaliar")

print(f"\nüìÇ ABRIR RELAT√ìRIOS:")
print(f"   file://{(OUTPUT_DIR / 'fairness_report_full.html').absolute()}")

print("\n" + "=" * 80)
print("‚úÖ AN√ÅLISE DE FAIRNESS CONCLU√çDA COM SUCESSO!")
print("=" * 80)

print(f"\nüìö Para mais informa√ß√µes:")
print(f"   - Tutorial: docs/FAIRNESS_TUTORIAL.md")
print(f"   - Best Practices: docs/FAIRNESS_BEST_PRACTICES.md")
print(f"   - FAQ: docs/FAIRNESS_FAQ.md")
