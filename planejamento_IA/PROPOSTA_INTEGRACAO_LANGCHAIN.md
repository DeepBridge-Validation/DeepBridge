# Proposta de IntegraÃ§Ã£o LangChain + DeepBridge
## EvoluÃ§Ã£o para Plataforma Inteligente de Model Governance

**VersÃ£o:** 1.0
**Data:** Dezembro 2025
**Status:** Proposta para AprovaÃ§Ã£o
**Autores:** Equipe DeepBridge

---

## ğŸ“‹ SumÃ¡rio Executivo

Esta proposta descreve a evoluÃ§Ã£o da biblioteca **DeepBridge** atravÃ©s da integraÃ§Ã£o com **LangChain** como camada opcional de orquestraÃ§Ã£o por agentes inteligentes. O objetivo Ã© transformar a DeepBridge de uma biblioteca puramente tÃ©cnica de validaÃ§Ã£o de modelos em uma **plataforma autÃ´noma de governanÃ§a, validaÃ§Ã£o e auditoria de modelos de Machine Learning**.

### Principais ConclusÃµes

âœ… **VIÃVEL**: Arquitetura atual da DeepBridge estÃ¡ altamente preparada para integraÃ§Ã£o
âœ… **ESTRATÃ‰GICO**: Posiciona DeepBridge como Ãºnica plataforma com agentes + validaÃ§Ã£o rigorosa
âœ… **FACTÃVEL**: Roadmap de 12-14 semanas para production-ready
âœ… **SEGURO**: SeparaÃ§Ã£o clara entre decisÃ£o (LLM) e execuÃ§Ã£o (DeepBridge)

### MÃ©tricas de Impacto Esperadas

- **ReduÃ§Ã£o de tempo de validaÃ§Ã£o**: 80-90% (40h â†’ 5h)
- **Custo por validaÃ§Ã£o com agentes**: <$5 (LLM calls)
- **Adoption rate target**: 30% em 6 meses
- **ROI estimado**: >300% para validaÃ§Ãµes regulares

---

## ğŸ“Š Tabela de ConteÃºdos

1. [VisÃ£o Geral](#1-visÃ£o-geral)
2. [AnÃ¡lise da Arquitetura Atual](#2-anÃ¡lise-da-arquitetura-atual)
3. [MotivaÃ§Ã£o EstratÃ©gica](#3-motivaÃ§Ã£o-estratÃ©gica)
4. [PrincÃ­pios Arquiteturais](#4-princÃ­pios-arquiteturais)
5. [Arquitetura Proposta](#5-arquitetura-proposta)
6. [ImplementaÃ§Ã£o Detalhada](#6-implementaÃ§Ã£o-detalhada)
7. [Casos de Uso](#7-casos-de-uso)
8. [Roadmap de ImplementaÃ§Ã£o](#8-roadmap-de-implementaÃ§Ã£o)
9. [AnÃ¡lise de Riscos](#9-anÃ¡lise-de-riscos)
10. [MÃ©tricas de Sucesso](#10-mÃ©tricas-de-sucesso)
11. [ComparaÃ§Ã£o: Com vs. Sem LangChain](#11-comparaÃ§Ã£o-com-vs-sem-langchain)
12. [RecomendaÃ§Ãµes Finais](#12-recomendaÃ§Ãµes-finais)
13. [PrÃ³ximos Passos](#13-prÃ³ximos-passos)

---

## 1. VisÃ£o Geral

### 1.1 Contexto

A validaÃ§Ã£o tradicional de modelos de ML segue um fluxo manual ou semiautomÃ¡tico que requer expertise tÃ©cnica profunda e consome 20-80 horas por modelo:

```
Fluxo Atual:
UsuÃ¡rio â†’ Script Manual â†’ ConfiguraÃ§Ã£o de Testes â†’ ExecuÃ§Ã£o â†’ InterpretaÃ§Ã£o Manual â†’ RelatÃ³rio
```

### 1.2 Proposta

Integrar LangChain como camada inteligente mantendo DeepBridge como executor determinÃ­stico:

```
Fluxo Proposto:
UsuÃ¡rio â†’ Prompt Natural â†’ Agente LangChain â†’ DeepBridge (Testes) â†’ RelatÃ³rios Automatizados
```

### 1.3 Valor Agregado

Esta evoluÃ§Ã£o posiciona a DeepBridge como:

- âœ… Plataforma de **Model Risk Management (MRM)** automatizado
- âœ… Motor de **validaÃ§Ã£o autÃ´noma** de modelos
- âœ… Base tecnolÃ³gica para **auditoria contÃ­nua de IA**
- âœ… Interface **democratizada** (nÃ£o requer expertise tÃ©cnica profunda)

---

## 2. AnÃ¡lise da Arquitetura Atual

### 2.1 Estrutura Modular da DeepBridge

A anÃ¡lise tÃ©cnica da biblioteca revelou uma arquitetura **altamente preparada** para extensÃµes:

```
deepbridge/
â”œâ”€â”€ core/                    # NÃºcleo - Experimentos e dados
â”‚   â”œâ”€â”€ db_data.py          # DBDataset (dados + modelo)
â”‚   â”œâ”€â”€ experiment/         # Sistema de experimentaÃ§Ã£o
â”‚   â”‚   â”œâ”€â”€ experiment.py   # Classe Experiment (orquestrador)
â”‚   â”‚   â”œâ”€â”€ test_runner.py  # Executor de testes
â”‚   â”‚   â””â”€â”€ managers/       # Gerenciadores especializados
â”‚   â””â”€â”€ base_processor.py   # Base abstrata
â”‚
â”œâ”€â”€ validation/             # SuÃ­tes de validaÃ§Ã£o
â”‚   â””â”€â”€ wrappers/
â”‚       â”œâ”€â”€ robustness_suite.py
â”‚       â”œâ”€â”€ fairness_suite.py
â”‚       â”œâ”€â”€ uncertainty_suite.py
â”‚       â”œâ”€â”€ resilience_suite.py
â”‚       â””â”€â”€ hyperparameter_suite.py
â”‚
â”œâ”€â”€ distillation/           # DestilaÃ§Ã£o de conhecimento
â”œâ”€â”€ synthetic/              # GeraÃ§Ã£o de dados sintÃ©ticos
â”œâ”€â”€ metrics/                # MÃ©tricas de avaliaÃ§Ã£o
â””â”€â”€ utils/                  # UtilitÃ¡rios compartilhados
```

### 2.2 PadrÃµes Arquiteturais Identificados

**PadrÃµes de Design:**
1. **Abstract Base Classes (ABC)**: Interfaces bem definidas
2. **Factory Pattern**: CriaÃ§Ã£o de modelos, testes e estratÃ©gias
3. **Strategy Pattern**: MÃºltiplas estratÃ©gias de teste intercambiÃ¡veis
4. **Facade Pattern**: `Experiment` e `Suites` como fachadas simplificadas
5. **Composition over Inheritance**: Modularidade e flexibilidade

**ImplicaÃ§Ãµes para IntegraÃ§Ã£o:**
- âœ… **Extensibilidade**: FÃ¡cil adicionar novos componentes via Factories
- âœ… **SeparaÃ§Ã£o de Responsabilidades**: Cada mÃ³dulo com funÃ§Ã£o clara
- âœ… **Interfaces EstÃ¡veis**: ABCs garantem contratos bem definidos
- âœ… **Testabilidade**: Componentes isolados facilitam testes

### 2.3 Pontos de IntegraÃ§Ã£o Identificados

**NÃ­veis de IntegraÃ§Ã£o PossÃ­veis:**

1. **NÃ­vel de Teste** (mais simples)
   - Criar `LangChainTestStrategy` implementando `TestStrategy`
   - Integrar no `TestStrategyFactory`
   - Executar via `Experiment.run_test('langchain', config)`

2. **NÃ­vel de Suite** (intermediÃ¡rio)
   - Criar `LangChainSuite` similar a `RobustnessSuite`
   - API familiar: `.config('quick').run()`

3. **NÃ­vel de Manager** (mais controle)
   - Criar `LangChainManager` herdando de `BaseManager`
   - Acesso direto a dados de treino/teste

4. **NÃ­vel de Agente** (orquestraÃ§Ã£o) â­ **RECOMENDADO**
   - Nova camada acima do `Experiment`
   - LLM interpreta prompts e roteia para testes apropriados
   - DeepBridge executa testes determinÃ­sticos

### 2.4 API PÃºblica Atual

**Uso tÃ­pico da DeepBridge:**

```python
from deepbridge import DBDataset, Experiment

# 1. Criar dataset
dataset = DBDataset(
    data=df,
    target_column='target',
    features=['f1', 'f2'],
    model=trained_model
)

# 2. Criar experimento
experiment = Experiment(
    dataset=dataset,
    experiment_type='binary_classification',
    tests=['robustness', 'uncertainty', 'fairness']
)

# 3. Executar testes (requer conhecimento tÃ©cnico)
results = experiment.run_tests(config_name='medium')

# 4. Gerar relatÃ³rio
results.save_html('robustness', 'report.html')
```

**ObservaÃ§Ãµes:**
- âœ… API bem definida e documentada
- âœ… FlexÃ­vel e poderosa
- âŒ Requer expertise tÃ©cnica
- âŒ Workflow manual
- âŒ InterpretaÃ§Ã£o subjetiva dos resultados

---

## 3. MotivaÃ§Ã£o EstratÃ©gica

### 3.1 Problema Atual

A validaÃ§Ã£o de modelos ML em produÃ§Ã£o enfrenta desafios crÃ­ticos:

**Desafios TÃ©cnicos:**
- â±ï¸ **Tempo**: 20-80 horas por modelo para validaÃ§Ã£o completa
- ğŸ’° **Custo**: $6k-$24k por validaÃ§Ã£o (expertise especializada)
- ğŸ¯ **Expertise**: Requer conhecimento profundo em ML, estatÃ­stica E regulaÃ§Ãµes
- ğŸ“Š **InconsistÃªncia**: Resultados variam entre auditores
- ğŸ”„ **FrequÃªncia**: ValidaÃ§Ãµes pontuais vs. monitoramento contÃ­nuo necessÃ¡rio

**Desafios RegulatÃ³rios:**
- ğŸ“‹ **SR 11-7** (Model Risk Management): ValidaÃ§Ã£o independente obrigatÃ³ria
- âš–ï¸ **EEOC/ECOA**: Compliance em fairness para hiring/lending
- ğŸ‡ªğŸ‡º **EU AI Act**: TransparÃªncia e auditabilidade
- ğŸ¯ **Basel III/IV**: GestÃ£o de risco de modelos em bancos

### 3.2 Oportunidade de Mercado

**Segmentos-alvo:**

| Segmento | Tamanho (US) | Pain Point Principal | Valor Proposto |
|----------|--------------|----------------------|----------------|
| **Bancos** | 5,000+ instituiÃ§Ãµes | Compliance SR 11-7 | MRM automatizado |
| **Fintechs** | 10,000+ empresas | EEOC/ECOA em lending/hiring | ValidaÃ§Ã£o contÃ­nua |
| **Big Tech** | 500+ empresas | Escala de validaÃ§Ã£o | AutomaÃ§Ã£o em larga escala |
| **Consultorias** | 1,000+ firmas | Auditoria para clientes | Ferramenta profissional |
| **Reguladores** | Agencies federais/estaduais | SupervisÃ£o em escala | PadronizaÃ§Ã£o de auditorias |

**Tamanho de Mercado Estimado:**
- **TAM (Total Addressable Market)**: $2B+ (Model Risk Management global)
- **SAM (Serviceable Available Market)**: $500M (validaÃ§Ã£o automatizada)
- **SOM (Serviceable Obtainable Market)**: $50M (3 anos, 10% market share)

### 3.3 DiferenciaÃ§Ã£o Competitiva

**ComparaÃ§Ã£o com Alternativas:**

| Feature | Manual Audit | AIF360 | Fairlearn | **DeepBridge + LangChain** |
|---------|--------------|--------|-----------|----------------------------|
| Tempo mÃ©dio | 40h | N/A | N/A | **5h** |
| Custo | $12k | GrÃ¡tis | GrÃ¡tis | **<$100** |
| Interface natural | âŒ | âŒ | âŒ | **âœ…** |
| Compliance EEOC | Manual | Parcial | Parcial | **âœ… Automatizado** |
| Compliance SR 11-7 | âœ… | âŒ | âŒ | **âœ… Automatizado** |
| Stress testing | Manual | âŒ | âŒ | **âœ… Automatizado** |
| InterpretaÃ§Ã£o tÃ©cnica | Humana | âŒ | âŒ | **âœ… LLM** |
| Reproducibilidade | Baixa | Alta | Alta | **Alta** |
| Continuous monitoring | âŒ | Parcial | Parcial | **âœ…** |

**Diferencial Ãšnico:**
> **DeepBridge serÃ¡ a ÃšNICA plataforma que combina rigor tÃ©cnico de validaÃ§Ã£o ML determinÃ­stica com inteligÃªncia de agentes para automaÃ§Ã£o completa de Model Risk Management.**

---

## 4. PrincÃ­pios Arquiteturais

### 4.1 PrincÃ­pios Fundamentais

**1. LangChain como Camada Opcional**
```
âŒ NÃƒO: Tornar DeepBridge dependente de LLMs
âœ… SIM: Adicionar agentes como feature opcional
```

A DeepBridge DEVE continuar funcionando perfeitamente sem LangChain.

**2. SeparaÃ§Ã£o Clara de Responsabilidades**

| Componente | Responsabilidade | O que NÃƒO faz |
|------------|------------------|---------------|
| **LangChain/LLM** | â€¢ Interpretar prompts<br>â€¢ Rotear para testes apropriados<br>â€¢ Gerar explicaÃ§Ãµes tÃ©cnicas | âŒ Calcular mÃ©tricas<br>âŒ Executar testes<br>âŒ Decidir risco sozinho |
| **DeepBridge** | â€¢ Executar testes estatÃ­sticos<br>â€¢ Calcular mÃ©tricas<br>â€¢ Gerar relatÃ³rios tÃ©cnicos | âŒ Interpretar linguagem natural<br>âŒ Gerar narrativas |

**3. Determinismo da ValidaÃ§Ã£o**

Toda execuÃ§Ã£o da DeepBridge deve ser:
- âœ… **ReprodutÃ­vel**: Mesmas entradas â†’ mesmas mÃ©tricas
- âœ… **Versionada**: Configs, prompts, datasets rastreados
- âœ… **AuditÃ¡vel**: Logs completos de execuÃ§Ã£o
- âœ… **Independente**: LLM nÃ£o afeta resultados de testes

**4. LLM Nunca Decide Risco Sozinho**

```
Fluxo Correto:
User Prompt â†’ LLM Interpreta â†’ DeepBridge Executa â†’ MÃ©tricas DeterminÃ­sticas â†’ LLM Explica
                                                      â†‘
                                            Source of Truth
```

**5. Auditabilidade Completa**

Cada execuÃ§Ã£o deve logar:
```json
{
  "timestamp": "2025-12-06T10:30:00Z",
  "user_prompt": "Valide robustez",
  "llm_routing": {
    "tests_selected": ["robustness"],
    "config": "medium",
    "reasoning": "..."
  },
  "deepbridge_execution": {
    "test_type": "robustness",
    "config": "medium",
    "deterministic": true,
    "results_hash": "abc123..."
  },
  "llm_interpretation": {
    "summary": "...",
    "recommendations": [...]
  },
  "costs": {
    "llm_tokens": 1500,
    "estimated_cost_usd": 0.045
  }
}
```

### 4.2 Garantias RegulatÃ³rias

**Para Compliance:**

| Requisito RegulatÃ³rio | Como Garantimos |
|----------------------|-----------------|
| **Reproducibilidade** | DeepBridge executa testes, LLM apenas interpreta |
| **IndependÃªncia de ValidaÃ§Ã£o** | MÃ©tricas calculadas deterministicamente |
| **Rastreabilidade** | Logs completos de execuÃ§Ã£o + versionamento |
| **Explicabilidade** | LLM gera narrativas, mas mÃ©tricas sÃ£o source of truth |
| **Auditabilidade** | Executions logs exportÃ¡veis para reguladores |

---

## 5. Arquitetura Proposta

### 5.1 VisÃ£o de Alto NÃ­vel

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CAMADA DE USUÃRIO                       â”‚
â”‚  Interface: Linguagem Natural (prompts) ou API ClÃ¡ssica    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            CAMADA DE AGENTES (NOVA - OPCIONAL)             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ Validation   â”‚  â”‚ StressTest   â”‚  â”‚Explainabilityâ”‚     â”‚
â”‚  â”‚   Agent      â”‚  â”‚    Agent     â”‚  â”‚    Agent     â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚         â”‚                  â”‚                  â”‚             â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                            â†“                                â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚              â”‚   LangChain Tools       â”‚                   â”‚
â”‚              â”‚  (RobustnessTool, etc)  â”‚                   â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         CAMADA DE ORQUESTRAÃ‡ÃƒO (EXISTENTE)                 â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚              â”‚   Experiment    â”‚  â† Orquestrador Central   â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â”‚                       â†“                                     â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚         â”‚     TestRunner          â”‚                        â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          CAMADA DE EXECUÃ‡ÃƒO (EXISTENTE)                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚ Robustness  â”‚  â”‚  Fairness   â”‚  â”‚ Uncertainty â”‚        â”‚
â”‚  â”‚  Manager    â”‚  â”‚   Manager   â”‚  â”‚   Manager   â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚         â”‚                 â”‚                 â”‚               â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                           â†“                                 â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚              â”‚   Test Strategies  â”‚                        â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              CAMADA DE DADOS (EXISTENTE)                   â”‚
â”‚                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚                  â”‚   DBDataset  â”‚                          â”‚
â”‚                  â”‚  (Dados +    â”‚                          â”‚
â”‚                  â”‚   Modelo)    â”‚                          â”‚
â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           CAMADA DE SAÃDA (EXISTENTE)                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  HTML   â”‚  â”‚   PDF   â”‚  â”‚  JSON   â”‚  â”‚ Jupyter â”‚      â”‚
â”‚  â”‚ Reports â”‚  â”‚ Reports â”‚  â”‚  Logs   â”‚  â”‚  Plots  â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.2 Estrutura de MÃ³dulos Proposta

```python
deepbridge/
â”‚
â”œâ”€â”€ agents/                          # ğŸ†• NOVO MÃ“DULO
â”‚   â”œâ”€â”€ __init__.py                 # Exports pÃºblicos
â”‚   â”‚
â”‚   â”œâ”€â”€ base.py                     # AgentBase (classe abstrata)
â”‚   â”œâ”€â”€ validation_agent.py         # Agente de validaÃ§Ã£o geral
â”‚   â”œâ”€â”€ stress_test_agent.py        # Agente de stress testing
â”‚   â”œâ”€â”€ explainability_agent.py     # Agente de explainability
â”‚   â”œâ”€â”€ comparison_agent.py         # Agente de comparaÃ§Ã£o de modelos
â”‚   â”‚
â”‚   â”œâ”€â”€ tools/                      # LangChain Tools
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base_tool.py           # Base para tools
â”‚   â”‚   â”œâ”€â”€ robustness_tool.py     # Tool: robustez
â”‚   â”‚   â”œâ”€â”€ fairness_tool.py       # Tool: fairness
â”‚   â”‚   â”œâ”€â”€ uncertainty_tool.py    # Tool: incerteza
â”‚   â”‚   â”œâ”€â”€ resilience_tool.py     # Tool: resiliÃªncia
â”‚   â”‚   â”œâ”€â”€ hyperparameter_tool.py # Tool: hiperparÃ¢metros
â”‚   â”‚   â”œâ”€â”€ distillation_tool.py   # Tool: destilaÃ§Ã£o
â”‚   â”‚   â””â”€â”€ synthetic_tool.py      # Tool: dados sintÃ©ticos
â”‚   â”‚
â”‚   â”œâ”€â”€ prompts/                    # Prompt Templates
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ validation_prompts.py  # Prompts para validaÃ§Ã£o
â”‚   â”‚   â”œâ”€â”€ stress_test_prompts.py # Prompts para stress testing
â”‚   â”‚   â”œâ”€â”€ explain_prompts.py     # Prompts para explicabilidade
â”‚   â”‚   â””â”€â”€ system_prompts.py      # System prompts base
â”‚   â”‚
â”‚   â”œâ”€â”€ memory/                     # MemÃ³ria de execuÃ§Ãµes
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ execution_log.py       # Logging de execuÃ§Ãµes
â”‚   â”‚   â”œâ”€â”€ cost_tracker.py        # Tracking de custos LLM
â”‚   â”‚   â””â”€â”€ session_manager.py     # Gerenciamento de sessÃµes
â”‚   â”‚
â”‚   â””â”€â”€ wrappers/                   # Wrappers para compatibilidade
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ llm_model_wrapper.py   # Wrapper LLM â†’ sklearn API
â”‚       â””â”€â”€ chain_wrapper.py       # Wrapper LangChain chains
â”‚
â”œâ”€â”€ core/                           # âœ… EXISTENTE (inalterado)
â”œâ”€â”€ validation/                     # âœ… EXISTENTE (inalterado)
â”œâ”€â”€ distillation/                   # âœ… EXISTENTE (inalterado)
â”œâ”€â”€ synthetic/                      # âœ… EXISTENTE (inalterado)
â”œâ”€â”€ metrics/                        # âœ… EXISTENTE (inalterado)
â””â”€â”€ utils/                          # âœ… EXISTENTE (inalterado)
```

### 5.3 Fluxo de Dados Detalhado

**Exemplo: "Valide este modelo quanto Ã  robustez e viÃ©s"**

```
1. User Input
   â†“
   Prompt: "Valide este modelo quanto Ã  robustez e viÃ©s"

2. ValidationAgent (LangChain Layer)
   â†“
   LLM interpreta prompt:
   {
     "intent": "validation",
     "tests_required": ["robustness", "fairness"],
     "config": "medium",  # inferido do prompt
     "priority": "both"
   }

3. Tool Selection (LangChain Executor)
   â†“
   Seleciona Tools:
   - RobustnessTool
   - FairnessTool

4. RobustnessTool.run()
   â†“
   Chama: experiment.run_test('robustness', 'medium')
   â†“
   ExecuÃ§Ã£o DeepBridge (DETERMINÃSTICA):
   - TestRunner â†’ RobustnessManager â†’ RobustnessStrategy
   - PerturbaÃ§Ãµes Gaussianas
   - CÃ¡lculo de mÃ©tricas
   - DetecÃ§Ã£o de weak spots
   â†“
   Retorna: {
     "robustness_score": 0.82,
     "degradation": 0.12,
     "weak_spots": [("feature_x", 0.25), ...],
     "deterministic": true
   }

5. FairnessTool.run()
   â†“
   Chama: experiment.run_fairness_tests('medium')
   â†“
   ExecuÃ§Ã£o DeepBridge (DETERMINÃSTICA):
   - TestRunner â†’ FairnessManager
   - CÃ¡lculo de 15 mÃ©tricas
   - VerificaÃ§Ã£o EEOC (80% rule)
   - Confusion matrix por grupo
   â†“
   Retorna: {
     "eeoc_compliant": false,
     "metrics": {...},
     "violations": [...],
     "deterministic": true
   }

6. LLM Synthesis (LangChain Layer)
   â†“
   LLM recebe resultados e gera:
   """
   ANÃLISE DE VALIDAÃ‡ÃƒO

   Executei testes de robustez e fairness no modelo.

   ROBUSTEZ: âš ï¸ ATENÃ‡ÃƒO
   - Score: 0.82 (aceitÃ¡vel, mas abaixo de ideal 0.9)
   - DegradaÃ§Ã£o mÃ©dia: 12% sob perturbaÃ§Ãµes
   - Weak spot crÃ­tico: feature_x (25% de degradaÃ§Ã£o)

   FAIRNESS: âŒ NÃƒO-COMPLIANT
   - EEOC 80% Rule: VIOLADO
   - Impact ratio: 0.72 (abaixo de 0.80)
   - Grupo afetado: [detalhes]

   RECOMENDAÃ‡Ã•ES PRIORIZADAS:
   1. [CRÃTICO] Mitigar violaÃ§Ã£o EEOC antes de deployment
   2. [ALTO] Investigar feature_x para robustez
   3. [MÃ‰DIO] Considerar threshold adjustment

   PRÃ“XIMOS PASSOS:
   - Gerar relatÃ³rio tÃ©cnico completo
   - Revisar features para fairness
   - Re-executar testes apÃ³s mitigaÃ§Ãµes
   """

7. Output to User
   â†“
   {
     "answer": "...",  # Texto acima
     "executions": [...],  # Logs de execuÃ§Ã£o
     "results": DBResults,  # Objeto com resultados completos
     "metadata": {
       "deterministic": true,
       "llm_cost_usd": 0.043,
       "duration_seconds": 45.2
     }
   }
```

---

## 6. ImplementaÃ§Ã£o Detalhada

### 6.1 Classe AgentBase

Classe abstrata base para todos os agentes:

```python
# deepbridge/agents/base.py
from abc import ABC, abstractmethod
from typing import Dict, Any, Optional, List
from langchain.agents import AgentExecutor
from langchain.tools import Tool
from deepbridge.core import Experiment, DBDataset
import time
import hashlib

class AgentBase(ABC):
    """
    Classe abstrata para agentes LangChain integrados ao DeepBridge.

    PrincÃ­pios:
    1. LLM apenas roteia e interpreta
    2. DeepBridge executa testes determinÃ­sticos
    3. Logging completo para auditoria
    4. Tracking de custos obrigatÃ³rio para production

    Exemplo:
        >>> class MyAgent(AgentBase):
        ...     def _create_tools(self):
        ...         return [RobustnessTool(experiment=self.experiment)]
        ...
        ...     def _create_agent(self):
        ...         return initialize_agent(...)
    """

    def __init__(
        self,
        dataset: DBDataset,
        llm: Any,  # LangChain LLM
        experiment: Optional[Experiment] = None,
        verbose: bool = True,
        track_costs: bool = True,
        max_iterations: int = 10
    ):
        """
        Inicializa agente base.

        Args:
            dataset: Dataset DeepBridge
            llm: Modelo de linguagem (LangChain compatible)
            experiment: Experimento existente (opcional)
            verbose: Logging verboso
            track_costs: Rastrear custos de LLM calls
            max_iterations: MÃ¡ximo de iteraÃ§Ãµes do agente
        """
        self.dataset = dataset
        self.llm = llm
        self.experiment = experiment or self._create_experiment()
        self.verbose = verbose
        self.track_costs = track_costs
        self.max_iterations = max_iterations

        # Tracking
        self._execution_log: List[Dict] = []
        self._cost_tracker = CostTracker() if track_costs else None
        self._session_id = self._generate_session_id()

        # Setup LangChain
        self.tools = self._create_tools()
        self.agent = self._create_agent()
        self.executor = AgentExecutor.from_agent_and_tools(
            agent=self.agent,
            tools=self.tools,
            verbose=verbose,
            max_iterations=max_iterations,
            handle_parsing_errors=True
        )

    @abstractmethod
    def _create_tools(self) -> List[Tool]:
        """
        Criar LangChain Tools especÃ­ficos do agente.

        Returns:
            Lista de Tools disponÃ­veis para o agente
        """
        pass

    @abstractmethod
    def _create_agent(self) -> Any:
        """
        Criar agente LangChain (agent type, prompts, etc).

        Returns:
            Agente LangChain configurado
        """
        pass

    def _create_experiment(self) -> Experiment:
        """Criar Experiment padrÃ£o se nÃ£o fornecido."""
        return Experiment(
            dataset=self.dataset,
            experiment_type=self._infer_experiment_type(),
            tests=['robustness', 'uncertainty', 'fairness'],
            verbose=self.verbose
        )

    def run(self, query: str, **kwargs) -> Dict[str, Any]:
        """
        Executar query atravÃ©s do agente.

        Args:
            query: Comando em linguagem natural
            **kwargs: ParÃ¢metros adicionais

        Returns:
            {
                'answer': str,           # Resposta do LLM
                'executions': list,      # Testes executados
                'results': Any,          # Resultados dos testes
                'metadata': dict,        # Logs, custos, timestamps
                'deterministic': bool,   # Se execuÃ§Ã£o foi determinÃ­stica
                'session_id': str        # ID da sessÃ£o
            }
        """
        start_time = time.time()

        if self.verbose:
            print(f"[AgentBase] Executando query: {query[:100]}...")

        # Executar atravÃ©s do AgentExecutor
        try:
            response = self.executor.run(query, **kwargs)
        except Exception as e:
            return self._handle_error(e, query, start_time)

        # Compilar resultados
        result = {
            'answer': response,
            'executions': self._execution_log.copy(),
            'results': self._get_latest_results(),
            'metadata': {
                'timestamp': time.time(),
                'duration_seconds': time.time() - start_time,
                'query': query,
                'deterministic': True,  # DeepBridge sempre determinÃ­stico
                'llm_calls': len(self._execution_log),
                'session_id': self._session_id
            },
            'deterministic': True,
            'session_id': self._session_id
        }

        # Adicionar custos se tracking ativo
        if self.track_costs and self._cost_tracker:
            result['metadata']['costs'] = self._cost_tracker.get_summary()

        if self.verbose:
            print(f"[AgentBase] ConcluÃ­do em {result['metadata']['duration_seconds']:.2f}s")

        return result

    def _log_execution(
        self,
        test_type: str,
        config: str,
        results: Any,
        tool_name: str = None
    ):
        """
        Log execuÃ§Ã£o para auditoria.

        Args:
            test_type: Tipo de teste executado
            config: ConfiguraÃ§Ã£o usada
            results: Resultados do teste
            tool_name: Nome da tool LangChain que executou
        """
        execution_entry = {
            'test_type': test_type,
            'config': config,
            'tool_name': tool_name,
            'results_summary': self._summarize_results(results),
            'timestamp': time.time(),
            'results_hash': self._hash_results(results),
            'deterministic': True
        }

        self._execution_log.append(execution_entry)

        if self.verbose:
            print(f"[AgentBase] Logged execution: {test_type} ({config})")

    def _get_latest_results(self) -> Any:
        """
        Obter Ãºltimos resultados de testes.

        Returns:
            Resultados do Ãºltimo teste executado
        """
        if not self._execution_log:
            return None

        # Retornar resultados mais recentes
        latest = self._execution_log[-1]
        return latest.get('results_summary')

    @abstractmethod
    def _summarize_results(self, results: Any) -> Dict:
        """
        Resumir resultados para logging e LLM.

        Args:
            results: Resultados completos do teste

        Returns:
            Resumo estruturado dos resultados
        """
        pass

    def _infer_experiment_type(self) -> str:
        """
        Inferir tipo de experimento do dataset.

        Returns:
            'binary_classification', 'multiclass_classification', ou 'regression'
        """
        target = self.dataset.target
        n_unique = len(target.unique())

        if n_unique == 2:
            return 'binary_classification'
        elif n_unique < 20:
            return 'multiclass_classification'
        else:
            return 'regression'

    def get_audit_trail(self) -> Dict:
        """
        Obter trilha de auditoria completa.

        Returns:
            {
                'session_id': str,
                'executions': list,
                'costs': dict,
                'dataset_hash': str,
                'experiment_config': dict
            }
        """
        return {
            'session_id': self._session_id,
            'executions': self._execution_log,
            'costs': self._cost_tracker.get_detailed() if self.track_costs else None,
            'dataset_info': {
                'n_samples': len(self.dataset.data),
                'n_features': len(self.dataset.features),
                'target_distribution': self.dataset.target.value_counts().to_dict()
            },
            'experiment_type': self.experiment.experiment_type,
            'llm_model': getattr(self.llm, 'model_name', 'unknown')
        }

    def save_audit_trail(self, filepath: str):
        """
        Salvar trilha de auditoria em arquivo JSON.

        Args:
            filepath: Caminho do arquivo de saÃ­da
        """
        import json
        audit = self.get_audit_trail()

        with open(filepath, 'w') as f:
            json.dump(audit, f, indent=2, default=str)

        if self.verbose:
            print(f"[AgentBase] Audit trail saved to {filepath}")

    def _generate_session_id(self) -> str:
        """Gerar ID Ãºnico de sessÃ£o."""
        import uuid
        return f"session_{uuid.uuid4().hex[:12]}"

    def _hash_results(self, results: Any) -> str:
        """Gerar hash dos resultados para rastreabilidade."""
        import json
        results_str = json.dumps(results, sort_keys=True, default=str)
        return hashlib.md5(results_str.encode()).hexdigest()

    def _handle_error(self, error: Exception, query: str, start_time: float) -> Dict:
        """Lidar com erros durante execuÃ§Ã£o."""
        return {
            'answer': f"Erro durante execuÃ§Ã£o: {str(error)}",
            'executions': self._execution_log.copy(),
            'results': None,
            'metadata': {
                'timestamp': time.time(),
                'duration_seconds': time.time() - start_time,
                'query': query,
                'error': str(error),
                'deterministic': False,  # Erro = nÃ£o determinÃ­stico
                'session_id': self._session_id
            },
            'deterministic': False,
            'session_id': self._session_id,
            'error': str(error)
        }


class CostTracker:
    """Rastreador de custos de LLM calls."""

    def __init__(self):
        self.calls = []

    def log_call(self, tokens: int, cost: float, model: str):
        """Log uma chamada LLM."""
        self.calls.append({
            'tokens': tokens,
            'cost': cost,
            'model': model,
            'timestamp': time.time()
        })

    def get_summary(self) -> Dict:
        """Obter resumo de custos."""
        if not self.calls:
            return {'total_calls': 0, 'total_tokens': 0, 'total_cost_usd': 0.0}

        return {
            'total_calls': len(self.calls),
            'total_tokens': sum(c['tokens'] for c in self.calls),
            'total_cost_usd': sum(c['cost'] for c in self.calls),
            'avg_cost_per_call': sum(c['cost'] for c in self.calls) / len(self.calls)
        }

    def get_detailed(self) -> List[Dict]:
        """Obter detalhes completos de todas as chamadas."""
        return self.calls.copy()
```

### 6.2 ValidationAgent

Agente principal para validaÃ§Ã£o automÃ¡tica de modelos:

```python
# deepbridge/agents/validation_agent.py
from langchain.agents import initialize_agent, AgentType
from langchain.tools import Tool
from deepbridge.agents.base import AgentBase
from deepbridge.agents.tools import (
    RobustnessTool,
    FairnessTool,
    UncertaintyTool,
    ResilienceTool,
    HyperparameterTool
)
from deepbridge.agents.prompts import VALIDATION_SYSTEM_PROMPT

class ValidationAgent(AgentBase):
    """
    Agente para validaÃ§Ã£o automÃ¡tica de modelos ML.

    Este agente interpreta comandos em linguagem natural e executa
    testes de validaÃ§Ã£o apropriados usando DeepBridge como executor.

    Testes DisponÃ­veis:
    - Robustez: Testa resiliÃªncia a perturbaÃ§Ãµes
    - Fairness: Verifica viÃ©s e compliance EEOC
    - Incerteza: Avalia calibraÃ§Ã£o e conformal prediction
    - ResiliÃªncia: Analisa performance em hard samples
    - HiperparÃ¢metros: Identifica hiperparÃ¢metros crÃ­ticos

    Exemplo:
        >>> from deepbridge import DBDataset, ValidationAgent
        >>> from langchain.chat_models import ChatOpenAI
        >>>
        >>> dataset = DBDataset(data=df, target_column='target', model=model)
        >>> llm = ChatOpenAI(temperature=0)
        >>> agent = ValidationAgent(dataset=dataset, llm=llm)
        >>>
        >>> result = agent.run('''
        ... Valide este modelo quanto a:
        ... 1. Robustez (nÃ­vel full)
        ... 2. ViÃ©s (verificar EEOC compliance)
        ... Gere relatÃ³rio executivo.
        ... ''')
        >>>
        >>> print(result['answer'])
        >>> result['results'].save_html('robustness', 'report.html')
    """

    def __init__(self, *args, protected_attributes=None, **kwargs):
        """
        Inicializar ValidationAgent.

        Args:
            *args: Argumentos para AgentBase
            protected_attributes: Lista de atributos protegidos para fairness
            **kwargs: Kwargs para AgentBase
        """
        self.protected_attributes = protected_attributes
        super().__init__(*args, **kwargs)

    def _create_tools(self) -> list[Tool]:
        """Criar ferramentas de validaÃ§Ã£o."""
        tools = [
            RobustnessTool(
                experiment=self.experiment,
                cost_tracker=self._cost_tracker,
                execution_logger=self._log_execution
            ),
            FairnessTool(
                experiment=self.experiment,
                protected_attributes=self.protected_attributes,
                cost_tracker=self._cost_tracker,
                execution_logger=self._log_execution
            ),
            UncertaintyTool(
                experiment=self.experiment,
                cost_tracker=self._cost_tracker,
                execution_logger=self._log_execution
            ),
            ResilienceTool(
                experiment=self.experiment,
                cost_tracker=self._cost_tracker,
                execution_logger=self._log_execution
            ),
            HyperparameterTool(
                experiment=self.experiment,
                cost_tracker=self._cost_tracker,
                execution_logger=self._log_execution
            )
        ]

        return tools

    def _create_agent(self):
        """Criar agente conversacional."""
        return initialize_agent(
            tools=self.tools,
            llm=self.llm,
            agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,
            verbose=self.verbose,
            max_iterations=self.max_iterations,
            agent_kwargs={
                'prefix': VALIDATION_SYSTEM_PROMPT,
                'format_instructions': """
Use este formato:

Thought: [seu raciocÃ­nio sobre qual ferramenta usar]
Action: [nome da ferramenta]
Action Input: [parÃ¢metros em JSON]
Observation: [resultado da ferramenta]
... (repita Thought/Action/Observation conforme necessÃ¡rio)
Thought: Agora tenho informaÃ§Ã£o suficiente para responder
Final Answer: [resposta estruturada e completa]
""",
                'suffix': """
Lembre-se:
1. NUNCA calcule mÃ©tricas manualmente
2. SEMPRE use as ferramentas para executar testes
3. Cite valores ESPECÃFICOS das mÃ©tricas nos resultados
4. ForneÃ§a recomendaÃ§Ãµes PRIORIZADAS (CRÃTICO/ALTO/MÃ‰DIO/BAIXO)
5. Baseie anÃ¡lise de risco nos valores das mÃ©tricas

Question: {input}
{agent_scratchpad}
"""
            }
        )

    def _summarize_results(self, results: Any) -> Dict:
        """Resumir resultados de testes para logging."""
        summary = {}

        # Robustness
        if hasattr(results, 'robustness_score'):
            summary['robustness'] = {
                'score': results.robustness_score,
                'status': 'PASS' if results.robustness_score > 0.8 else 'FAIL',
                'degradation': results.avg_degradation if hasattr(results, 'avg_degradation') else None,
                'weak_spots': results.weak_spots[:3] if hasattr(results, 'weak_spots') else []
            }

        # Fairness
        if hasattr(results, 'fairness_metrics'):
            summary['fairness'] = {
                'eeoc_compliant': results.eeoc_compliant if hasattr(results, 'eeoc_compliant') else None,
                'worst_metric': results.worst_metric_value if hasattr(results, 'worst_metric_value') else None,
                'violations': results.violations if hasattr(results, 'violations') else []
            }

        # Uncertainty
        if hasattr(results, 'coverage'):
            summary['uncertainty'] = {
                'coverage': results.coverage,
                'avg_interval_width': results.avg_interval_width if hasattr(results, 'avg_interval_width') else None,
                'calibration_error': results.calibration_error if hasattr(results, 'calibration_error') else None
            }

        return summary
```

*(Continua na prÃ³xima resposta devido ao limite de caracteres)*
