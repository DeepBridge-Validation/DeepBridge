"""
Script de Verifica√ß√£o Pr√©via - An√°lise de Fairness
===================================================

Execute este script ANTES da an√°lise de fairness para verificar
se seus dados est√£o no formato correto.
"""

import pandas as pd
from pathlib import Path

# ============================================================================
# CONFIGURA√á√ïES
# ============================================================================

DATA_DIR = Path("/home/guhaase/projetos/DeepBridge/simular_lib/analise_v4")
TRAIN_PATH = DATA_DIR / "train_predictions.parquet"
TEST_PATH = DATA_DIR / "test_predictions.parquet"

# Colunas esperadas
EXPECTED_COLS = {
    'target': 'in_cmst_fun',
    'proba_0': 'pred_proba_class_0',
    'proba_1': 'pred_proba_class_1',
    'pred_class': 'pred_class',
    'protected': ['nm_tip_gnr', 'nm_tip_raca', 'vl_idd_aa']
}

# ============================================================================
# VERIFICA√á√ÉO
# ============================================================================

print("=" * 80)
print("VERIFICA√á√ÉO PR√âVIA - DADOS PARA AN√ÅLISE DE FAIRNESS")
print("=" * 80)

all_ok = True

# 1. Verificar se arquivos existem
print("\n1. Verificando exist√™ncia dos arquivos...")

for name, path in [("Train", TRAIN_PATH), ("Test", TEST_PATH)]:
    if path.exists():
        size_mb = path.stat().st_size / (1024 * 1024)
        print(f"   ‚úì {name}: {path.name} ({size_mb:.1f} MB)")
    else:
        print(f"   ‚úó {name}: N√ÉO ENCONTRADO - {path}")
        all_ok = False

if not all_ok:
    print("\n‚ùå ERRO: Arquivos n√£o encontrados!")
    print(f"   Verifique se os arquivos est√£o em: {DATA_DIR}")
    exit(1)

# 2. Carregar e verificar estrutura
print("\n2. Carregando dados...")

try:
    df_train = pd.read_parquet(TRAIN_PATH)
    df_test = pd.read_parquet(TEST_PATH)
    print(f"   ‚úì Train: {df_train.shape}")
    print(f"   ‚úì Test: {df_test.shape}")
except Exception as e:
    print(f"   ‚úó ERRO ao carregar: {e}")
    exit(1)

# 3. Verificar colunas
print("\n3. Verificando colunas necess√°rias...")

df = df_test  # Usar test para verifica√ß√£o

# Target
if EXPECTED_COLS['target'] in df.columns:
    print(f"   ‚úì Target: {EXPECTED_COLS['target']}")
else:
    print(f"   ‚úó Target: {EXPECTED_COLS['target']} N√ÉO ENCONTRADA")
    all_ok = False

# Probabilidades
for proba in ['proba_0', 'proba_1']:
    col = EXPECTED_COLS[proba]
    if col in df.columns:
        print(f"   ‚úì Probabilidade: {col}")
    else:
        print(f"   ‚úó Probabilidade: {col} N√ÉO ENCONTRADA")
        all_ok = False

# Classe predita
if EXPECTED_COLS['pred_class'] in df.columns:
    print(f"   ‚úì Classe predita: {EXPECTED_COLS['pred_class']}")
else:
    print(f"   ‚úó Classe predita: {EXPECTED_COLS['pred_class']} N√ÉO ENCONTRADA")
    all_ok = False

# Atributos protegidos
print("\n4. Verificando atributos protegidos...")
found_protected = []
missing_protected = []

for attr in EXPECTED_COLS['protected']:
    if attr in df.columns:
        print(f"   ‚úì {attr}")
        found_protected.append(attr)
    else:
        print(f"   ‚ö†Ô∏è  {attr} N√ÉO ENCONTRADA (opcional)")
        missing_protected.append(attr)

if len(found_protected) == 0:
    print(f"\n   ‚ùå ERRO: Nenhum atributo protegido encontrado!")
    print(f"   √â necess√°rio ter pelo menos 1 atributo protegido para an√°lise de fairness")
    all_ok = False
elif len(found_protected) < len(EXPECTED_COLS['protected']):
    print(f"\n   ‚ö†Ô∏è  AVISO: {len(missing_protected)} atributo(s) n√£o encontrado(s)")
    print(f"   An√°lise ser√° feita apenas com: {found_protected}")

# 5. Verificar valores
print("\n5. Verificando valores das colunas...")

target_col = EXPECTED_COLS['target']
pred_col = EXPECTED_COLS['pred_class']

# Target
if target_col in df.columns:
    unique_vals = df[target_col].unique()
    print(f"   Target ({target_col}):")
    print(f"      Valores √∫nicos: {sorted(unique_vals)}")

    if set(unique_vals) == {0, 1}:
        print(f"      ‚úì Classifica√ß√£o bin√°ria (0, 1)")
    else:
        print(f"      ‚ö†Ô∏è  AVISO: Valores n√£o s√£o apenas 0 e 1")

    # Distribui√ß√£o
    for val in sorted(unique_vals):
        count = (df[target_col] == val).sum()
        pct = count / len(df) * 100
        print(f"      Classe {val}: {count:,} ({pct:.1f}%)")

# Predi√ß√µes
if pred_col in df.columns:
    unique_vals = df[pred_col].unique()
    print(f"\n   Predi√ß√µes ({pred_col}):")
    print(f"      Valores √∫nicos: {sorted(unique_vals)}")

    for val in sorted(unique_vals):
        count = (df[pred_col] == val).sum()
        pct = count / len(df) * 100
        print(f"      Classe {val}: {count:,} ({pct:.1f}%)")

# Probabilidades
proba_cols = [EXPECTED_COLS['proba_0'], EXPECTED_COLS['proba_1']]
if all(col in df.columns for col in proba_cols):
    print(f"\n   Probabilidades:")
    for col in proba_cols:
        min_val = df[col].min()
        max_val = df[col].max()
        mean_val = df[col].mean()
        print(f"      {col}:")
        print(f"         Min: {min_val:.4f}, Max: {max_val:.4f}, Mean: {mean_val:.4f}")

        if min_val < 0 or max_val > 1:
            print(f"         ‚ö†Ô∏è  AVISO: Valores fora do range [0, 1]")

    # Verificar soma = 1
    prob_sum = df[proba_cols].sum(axis=1)
    if (prob_sum.round(4) == 1.0).all():
        print(f"      ‚úì Soma das probabilidades = 1.0")
    else:
        print(f"      ‚ö†Ô∏è  AVISO: Soma das probabilidades != 1.0 para algumas linhas")
        print(f"         Min soma: {prob_sum.min():.4f}, Max soma: {prob_sum.max():.4f}")

# 6. Verificar valores ausentes
print("\n6. Verificando valores ausentes (NaN)...")

critical_cols = [target_col, pred_col] + proba_cols + found_protected
has_nan = False

for col in critical_cols:
    if col in df.columns:
        nan_count = df[col].isna().sum()
        if nan_count > 0:
            pct = nan_count / len(df) * 100
            print(f"   ‚ö†Ô∏è  {col}: {nan_count:,} NaN ({pct:.1f}%)")
            has_nan = True

if not has_nan:
    print(f"   ‚úì Nenhum valor ausente em colunas cr√≠ticas")
else:
    print(f"\n   ‚ö†Ô∏è  ATEN√á√ÉO: Linhas com NaN ser√£o removidas automaticamente na an√°lise")

# 7. An√°lise dos atributos protegidos
print("\n7. An√°lise dos atributos protegidos...")

for attr in found_protected:
    print(f"\n   üìä {attr}:")

    # Valores √∫nicos
    unique_vals = df[attr].value_counts()
    print(f"      Total de grupos: {len(unique_vals)}")

    # Top 5
    print(f"      Top 5 grupos:")
    for val, count in unique_vals.head(5).items():
        pct = count / len(df) * 100
        print(f"         {val}: {count:,} ({pct:.1f}%)")

    # Verificar grupos muito pequenos
    min_group_size = unique_vals.min()
    min_group_pct = min_group_size / len(df) * 100

    if min_group_pct < 1.0:
        print(f"      ‚ö†Ô∏è  AVISO: Menor grupo tem apenas {min_group_size:,} samples ({min_group_pct:.2f}%)")
        print(f"         Grupos muito pequenos podem ter m√©tricas inst√°veis")

    # Taxa de aprova√ß√£o por grupo
    if target_col in df.columns:
        print(f"      Taxa de aprova√ß√£o por grupo:")
        approval_rates = df.groupby(attr)[target_col].mean()

        for val, rate in approval_rates.head(10).items():
            print(f"         {val}: {rate:.1%}")

        # Verificar disparidade
        max_rate = approval_rates.max()
        min_rate = approval_rates.min()
        disparity = max_rate - min_rate

        if disparity > 0.20:
            print(f"      ‚ö†Ô∏è  ATEN√á√ÉO: Grande disparidade detectada!")
            print(f"         Diferen√ßa max-min: {disparity:.1%}")
            print(f"         Isso sugere poss√≠vel vi√©s no modelo")

# 8. Resumo final
print("\n" + "=" * 80)
print("RESUMO DA VERIFICA√á√ÉO")
print("=" * 80)

if all_ok and len(found_protected) > 0:
    print("\n‚úÖ DADOS PRONTOS PARA AN√ÅLISE DE FAIRNESS!")
    print(f"\n   Pr√≥ximos passos:")
    print(f"   1. Executar: python analyze_fairness_production.py")
    print(f"      (an√°lise completa, ~10-15 min)")
    print(f"   2. OU: python analyze_fairness_quick.py")
    print(f"      (an√°lise r√°pida, ~5-8 min)")
    print(f"\n   Atributos protegidos que ser√£o analisados:")
    for attr in found_protected:
        print(f"      - {attr}")

else:
    print("\n‚ùå PROBLEMAS ENCONTRADOS!")
    print(f"\n   Revise os erros acima antes de executar a an√°lise")

    if not all_ok:
        print(f"   - Colunas necess√°rias faltando")

    if len(found_protected) == 0:
        print(f"   - Nenhum atributo protegido encontrado")
        print(f"\n   Sugest√£o: Verificar nomes das colunas:")
        print(f"   python -c \"import pandas as pd; df = pd.read_parquet('{TEST_PATH}'); print(df.columns.tolist())\"")

# 9. Informa√ß√µes adicionais
print("\n" + "=" * 80)
print("INFORMA√á√ïES ADICIONAIS")
print("=" * 80)

print(f"\nüìÅ Localiza√ß√£o dos dados:")
print(f"   {DATA_DIR}")

print(f"\nüìä Estat√≠sticas:")
print(f"   Train samples: {len(df_train):,}")
print(f"   Test samples: {len(df_test):,}")
print(f"   Total: {len(df_train) + len(df_test):,}")

if target_col in df.columns:
    accuracy = (df[target_col] == df[pred_col]).mean()
    print(f"\nüéØ Performance (Test):")
    print(f"   Acur√°cia: {accuracy:.3f}")

print(f"\nüìö Documenta√ß√£o:")
print(f"   - README: FAIRNESS_PRODUCTION_ANALYSIS_README.md")
print(f"   - Tutorial: docs/FAIRNESS_TUTORIAL.md")
print(f"   - FAQ: docs/FAIRNESS_FAQ.md")

print("\n" + "=" * 80)
