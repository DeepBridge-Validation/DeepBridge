{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepBridge Tutorial - Dataset Handling and Basic Experiment\n",
    "\n",
    "This notebook demonstrates how to use the core components of DeepBridge library: `DBDataset` and `Experiment` classes. These classes provide a foundation for model validation and distillation workflows.\n",
    "\n",
    "## Overview\n",
    "\n",
    "1. **DBDataset**: Wraps training and test datasets along with optional model and predictions\n",
    "2. **Experiment**: Handles different types of modeling tasks and their configurations\n",
    "\n",
    "Let's start by importing the necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guhaase/projetos/deepbridge_homol/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.expanduser(\"~/projetos/DeepBridge\"))\n",
    "\n",
    "# Import core DeepBridge components\n",
    "from deepbridge.core.db_data import DBDataset\n",
    "from deepbridge.core.experiment import Experiment\n",
    "from deepbridge.utils.model_registry import ModelType\n",
    "\n",
    "# Additional imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import tempfile\n",
    "import joblib\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Working with DBDataset\n",
    "\n",
    "The `DBDataset` class is a wrapper around datasets that handles feature management, categorical variables, and model predictions. Let's explore its functionality using a synthetic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network model: MLPClassifier\n",
      "Hidden layers: (100, 50)\n",
      "Train accuracy: 0.9979\n",
      "Test accuracy: 0.9897\n",
      "Model size: 0.26 MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import joblib\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "# Gerar dataset sintético com 20 mil registros\n",
    "X, y = make_classification(\n",
    "    n_samples=200000,\n",
    "    n_features=30,\n",
    "    n_informative=25,\n",
    "    n_redundant=5,\n",
    "    n_classes=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(30)])\n",
    "y = pd.Series(y, name='target')\n",
    "\n",
    "# Combinar features e alvo em um único DataFrame antes da separação\n",
    "data = X.copy()\n",
    "data['target'] = y\n",
    "\n",
    "# Dividir em conjuntos de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Criar o modelo de redes neurais (MLPClassifier)\n",
    "nn_model = MLPClassifier(\n",
    "    hidden_layer_sizes=(100, 50),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    max_iter=200,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Treinar o modelo\n",
    "nn_model.fit(X_train, y_train)\n",
    "\n",
    "# Gerar previsões\n",
    "train_probs = nn_model.predict_proba(X_train)\n",
    "test_probs = nn_model.predict_proba(X_test)\n",
    "\n",
    "# Converter para DataFrame\n",
    "train_probs_df = pd.DataFrame(train_probs, columns=['prob_class_0', 'prob_class_1'], index=X_train.index)\n",
    "test_probs_df = pd.DataFrame(test_probs, columns=['prob_class_0', 'prob_class_1'], index=X_test.index)\n",
    "\n",
    "# Salvar o modelo treinado\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "model_path = os.path.join(temp_dir, 'nn_model_large.pkl')\n",
    "joblib.dump(nn_model, model_path)\n",
    "\n",
    "# Exibir informações do modelo\n",
    "print(f\"Neural network model: {type(nn_model).__name__}\")\n",
    "print(f\"Hidden layers: {nn_model.hidden_layer_sizes}\")\n",
    "print(f\"Train accuracy: {nn_model.score(X_train, y_train):.4f}\")\n",
    "print(f\"Test accuracy: {nn_model.score(X_test, y_test):.4f}\")\n",
    "print(f\"Model size: {os.path.getsize(model_path) / (1024 * 1024):.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=(100, 50), random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>MLPClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.neural_network.MLPClassifier.html\">?<span>Documentation for MLPClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>MLPClassifier(hidden_layer_sizes=(100, 50), random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(100, 50), random_state=42)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Creating a DBDataset instance\n",
    "\n",
    "There are multiple ways to create a `DBDataset` instance:\n",
    "\n",
    "1. From a unified dataset that will be split into train/test\n",
    "2. From already split train/test datasets\n",
    "3. With pre-loaded model and predictions\n",
    "\n",
    "Let's demonstrate the first approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DBDataset(with 200000 samples (not split))\n",
      "Features: 30 total (0 categorical, 30 numerical)\n",
      "Target: 'target'\n",
      "Model: loaded\n",
      "Predictions: available\n"
     ]
    }
   ],
   "source": [
    "# Create a DBDataset from unified data\n",
    "db_dataset = DBDataset(\n",
    "    data=data,                   # Unified dataset\n",
    "    target_column='target',      # Name of target column\n",
    "    model=nn_model\n",
    ")\n",
    "\n",
    "# Display information about the dataset\n",
    "print(db_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluating distillation model on train dataset ===\n",
      "Student predictions shape: (160000, 2)\n",
      "First 3 student probabilities: [[9.9999386e-01 6.1506762e-06]\n",
      " [4.0531158e-06 9.9999595e-01]\n",
      " [1.8007445e-01 8.1992555e-01]]\n",
      "Teacher probabilities type: <class 'pandas.core.frame.DataFrame'>\n",
      "Using 'prob_class_1' column from teacher probabilities\n",
      "Teacher probabilities shape: (160000, 2)\n",
      "First 3 teacher probabilities (positive class): [4.06659572e-10 9.99999833e-01 3.13943004e-17]\n",
      "KS Statistic calculation: 0.42930625, p-value: 0.0\n",
      "R² Score calculation: 0.9730334873662196\n",
      "Teacher prob type: <class 'numpy.ndarray'>, shape: (160000,)\n",
      "Student prob type: <class 'numpy.ndarray'>, shape: (160000,)\n",
      "Teacher prob first 5 values: [4.06659572e-10 9.99999833e-01 3.13943004e-17 3.16337256e-18\n",
      " 1.00000000e+00]\n",
      "Student prob first 5 values: [6.1506762e-06 9.9999595e-01 8.1992555e-01 1.8750736e-02 9.9986696e-01]\n",
      "KS calculation successful: (0.42930625, 0.0)\n",
      "Sorted teacher dist - min: 4.368222869789236e-45, max: 1.0, length: 160000\n",
      "Sorted student dist - min: 9.165235326236143e-08, max: 0.9999998807907104, length: 160000\n",
      "R² calculation result: 0.9730334873662196\n",
      "R² calculation successful: 0.9730334873662196\n",
      "Evaluation metrics: {'accuracy': 0.95569375, 'precision': 0.9556762832521544, 'recall': 0.9557837149173755, 'f1_score': 0.9557299960657212, 'auc_roc': 0.9891033562427483, 'auc_pr': 0.9884101083144243, 'log_loss': 0.13573387986638935, 'kl_divergence': 0.12924232328591942, 'ks_statistic': 0.42930625, 'ks_pvalue': 0.0, 'r2_score': 0.9730334873662196, 'distillation_method': 'SurrogateModel'}\n",
      "=== Evaluation complete ===\n",
      "\n",
      "\n",
      "=== Evaluating distillation model on test dataset ===\n",
      "Student predictions shape: (40000, 2)\n",
      "First 3 student probabilities: [[9.9999392e-01 6.0754087e-06]\n",
      " [9.9069047e-01 9.3095163e-03]\n",
      " [1.5753508e-03 9.9842465e-01]]\n",
      "Teacher probabilities type: <class 'pandas.core.frame.DataFrame'>\n",
      "Using 'prob_class_1' column from teacher probabilities\n",
      "Teacher probabilities shape: (40000, 2)\n",
      "First 3 teacher probabilities (positive class): [1.36933094e-10 1.35229335e-11 1.00000000e+00]\n",
      "KS Statistic calculation: 0.42857500000000004, p-value: 0.0\n",
      "R² Score calculation: 0.973230834780692\n",
      "Teacher prob type: <class 'numpy.ndarray'>, shape: (40000,)\n",
      "Student prob type: <class 'numpy.ndarray'>, shape: (40000,)\n",
      "Teacher prob first 5 values: [1.36933094e-10 1.35229335e-11 1.00000000e+00 6.21384239e-19\n",
      " 1.00000000e+00]\n",
      "Student prob first 5 values: [6.0754087e-06 9.3095163e-03 9.9842465e-01 4.4456053e-01 9.9963689e-01]\n",
      "KS calculation successful: (0.42857500000000004, 0.0)\n",
      "Sorted teacher dist - min: 5.988542417165873e-44, max: 1.0, length: 40000\n",
      "Sorted student dist - min: 6.803740149052828e-08, max: 0.9999998807907104, length: 40000\n",
      "R² calculation result: 0.973230834780692\n",
      "R² calculation successful: 0.973230834780692\n",
      "Evaluation metrics: {'accuracy': 0.95155, 'precision': 0.9526431718061674, 'recall': 0.950454500049945, 'f1_score': 0.951547577378869, 'auc_roc': 0.987718128888936, 'auc_pr': 0.9873315938576923, 'log_loss': 0.1468054536998537, 'kl_divergence': 0.1393348893108537, 'ks_statistic': 0.42857500000000004, 'ks_pvalue': 0.0, 'r2_score': 0.973230834780692, 'distillation_method': 'SurrogateModel'}\n",
      "=== Evaluation complete ===\n",
      "\n"
     ]
    }
   ],
   "source": [
    "experiment = Experiment(\n",
    "    dataset=db_dataset,\n",
    "    experiment_type=\"binary_classification\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>metric</th>\n",
       "      <th>teacher_value</th>\n",
       "      <th>student_value</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.997912</td>\n",
       "      <td>0.955694</td>\n",
       "      <td>-0.042219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.997107</td>\n",
       "      <td>0.955676</td>\n",
       "      <td>-0.041431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.998726</td>\n",
       "      <td>0.955784</td>\n",
       "      <td>-0.042942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train</td>\n",
       "      <td>f1_score</td>\n",
       "      <td>0.997916</td>\n",
       "      <td>0.955730</td>\n",
       "      <td>-0.042186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train</td>\n",
       "      <td>auc_roc</td>\n",
       "      <td>0.999976</td>\n",
       "      <td>0.989103</td>\n",
       "      <td>-0.010873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>train</td>\n",
       "      <td>auc_pr</td>\n",
       "      <td>0.999976</td>\n",
       "      <td>0.988410</td>\n",
       "      <td>-0.011566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>train</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>0.006103</td>\n",
       "      <td>0.135734</td>\n",
       "      <td>0.129631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>test</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.989675</td>\n",
       "      <td>0.951550</td>\n",
       "      <td>-0.038125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>test</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.989222</td>\n",
       "      <td>0.952643</td>\n",
       "      <td>-0.036579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>test</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.990161</td>\n",
       "      <td>0.950455</td>\n",
       "      <td>-0.039706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>test</td>\n",
       "      <td>f1_score</td>\n",
       "      <td>0.989691</td>\n",
       "      <td>0.951548</td>\n",
       "      <td>-0.038144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>test</td>\n",
       "      <td>auc_roc</td>\n",
       "      <td>0.994992</td>\n",
       "      <td>0.987718</td>\n",
       "      <td>-0.007274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>test</td>\n",
       "      <td>auc_pr</td>\n",
       "      <td>0.994403</td>\n",
       "      <td>0.987332</td>\n",
       "      <td>-0.007071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>test</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>0.132850</td>\n",
       "      <td>0.146805</td>\n",
       "      <td>0.013956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset     metric  teacher_value  student_value  difference\n",
       "0    train   accuracy       0.997912       0.955694   -0.042219\n",
       "1    train  precision       0.997107       0.955676   -0.041431\n",
       "2    train     recall       0.998726       0.955784   -0.042942\n",
       "3    train   f1_score       0.997916       0.955730   -0.042186\n",
       "4    train    auc_roc       0.999976       0.989103   -0.010873\n",
       "5    train     auc_pr       0.999976       0.988410   -0.011566\n",
       "6    train   log_loss       0.006103       0.135734    0.129631\n",
       "7     test   accuracy       0.989675       0.951550   -0.038125\n",
       "8     test  precision       0.989222       0.952643   -0.036579\n",
       "9     test     recall       0.990161       0.950455   -0.039706\n",
       "10    test   f1_score       0.989691       0.951548   -0.038144\n",
       "11    test    auc_roc       0.994992       0.987718   -0.007274\n",
       "12    test     auc_pr       0.994403       0.987332   -0.007071\n",
       "13    test   log_loss       0.132850       0.146805    0.013956"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.compare_teacher_student_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created distribution comparison: distribution_plots/teacher_student_comparison.png\n",
      "Created cumulative distribution comparison: distribution_plots/teacher_student_cdf.png\n",
      "Created quantile plot: distribution_plots/teacher_student_qq.png\n"
     ]
    }
   ],
   "source": [
    "from deepbridge.visualization.distribution import DistributionVisualizer\n",
    "\n",
    "# Obtenha predições do estudante (student) e do professor (teacher) para o conjunto de teste\n",
    "student_predictions = experiment.get_student_predictions(dataset='test')\n",
    "student_probs = student_predictions['prob_1'].values  # ou outra coluna de probabilidade conforme seu caso\n",
    "\n",
    "# As probabilidades do professor geralmente estão disponíveis no experimento\n",
    "teacher_probs = experiment.prob_test\n",
    "\n",
    "# Crie o visualizador de distribuição\n",
    "output_dir = \"distribution_plots\"  # diretório onde os gráficos serão salvos\n",
    "visualizer = DistributionVisualizer(output_dir=output_dir)\n",
    "\n",
    "# Gere a visualização comparando as distribuições\n",
    "metrics = visualizer.compare_distributions(\n",
    "    teacher_probs=teacher_probs,\n",
    "    student_probs=student_probs,\n",
    "    title=\"Comparação da Distribuição de Probabilidades: Teacher vs Student\",\n",
    "    filename=\"teacher_student_comparison.png\",\n",
    "    show_metrics=True\n",
    ")\n",
    "\n",
    "# Gere também um gráfico de distribuição cumulativa\n",
    "visualizer.compare_cumulative_distributions(\n",
    "    teacher_probs=teacher_probs,\n",
    "    student_probs=student_probs,\n",
    "    title=\"Comparação da Distribuição Cumulativa: Teacher vs Student\",\n",
    "    filename=\"teacher_student_cdf.png\"\n",
    ")\n",
    "\n",
    "# Crie um gráfico de quantil-quantil (Q-Q plot)\n",
    "visualizer.create_quantile_plot(\n",
    "    teacher_probs=teacher_probs,\n",
    "    student_probs=student_probs,\n",
    "    title=\"Q-Q Plot: Teacher vs Student\",\n",
    "    filename=\"teacher_student_qq.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also pre-split our data and provide the train and test sets directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DBDataset('presplit_classification' with 200000 samples (not split))\n",
      "Features: 30 total (0 categorical, 30 numerical)\n",
      "Target: 'target'\n",
      "Model: not loaded\n",
      "Predictions: not available\n"
     ]
    }
   ],
   "source": [
    "# Split data manually\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a DBDataset from pre-split data\n",
    "db_dataset_split = DBDataset(\n",
    "    train_data=train_data,       # Training dataset\n",
    "    test_data=test_data,         # Test dataset\n",
    "    target_column='target',      # Name of target column\n",
    "    dataset_name='presplit_classification'  # Optional name\n",
    ")\n",
    "\n",
    "print(db_dataset_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Accessing dataset properties\n",
    "\n",
    "`DBDataset` provides several properties to access its components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total features: 30\n",
      "Feature names: ['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4']...\n",
      "Target name: target\n",
      "Total samples: 200000\n",
      "Training samples: 160000\n",
      "Test samples: 40000\n"
     ]
    }
   ],
   "source": [
    "# Access properties\n",
    "print(f\"Total features: {len(db_dataset.features)}\")\n",
    "print(f\"Feature names: {db_dataset.features[:5]}...\")\n",
    "print(f\"Target name: {db_dataset.target_name}\")\n",
    "print(f\"Total samples: {len(db_dataset)}\")\n",
    "print(f\"Training samples: {len(db_dataset.train_data)}\")\n",
    "print(f\"Test samples: {len(db_dataset.test_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Working with categorical features\n",
    "\n",
    "Let's create a dataset with both numerical and categorical features to demonstrate categorical feature handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_breast_cancer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load breast cancer dataset (for numerical features)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m breast_cancer \u001b[38;5;241m=\u001b[39m \u001b[43mload_breast_cancer\u001b[49m()\n\u001b[1;32m      3\u001b[0m X_numeric \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(breast_cancer\u001b[38;5;241m.\u001b[39mdata, columns\u001b[38;5;241m=\u001b[39mbreast_cancer\u001b[38;5;241m.\u001b[39mfeature_names)\n\u001b[1;32m      4\u001b[0m y \u001b[38;5;241m=\u001b[39m breast_cancer\u001b[38;5;241m.\u001b[39mtarget\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_breast_cancer' is not defined"
     ]
    }
   ],
   "source": [
    "# Load breast cancer dataset (for numerical features)\n",
    "breast_cancer = load_breast_cancer()\n",
    "X_numeric = pd.DataFrame(breast_cancer.data, columns=breast_cancer.feature_names)\n",
    "y = breast_cancer.target\n",
    "\n",
    "# Add some categorical features\n",
    "X_numeric['age_group'] = pd.cut(np.random.randint(30, 80, size=X_numeric.shape[0]), \n",
    "                               bins=[30, 45, 60, 80], \n",
    "                               labels=['young', 'middle', 'senior'])\n",
    "\n",
    "X_numeric['risk_factor'] = np.random.choice(['low', 'medium', 'high'], size=X_numeric.shape[0])\n",
    "X_numeric['family_history'] = np.random.choice([0, 1], size=X_numeric.shape[0])\n",
    "\n",
    "# Create final dataset\n",
    "mixed_data = X_numeric.copy()\n",
    "mixed_data['target'] = y\n",
    "\n",
    "# Display data types\n",
    "print(\"Data types:\")\n",
    "print(mixed_data.dtypes.value_counts())\n",
    "print(\"\\nSample data:\")\n",
    "mixed_data[['mean radius', 'mean texture', 'age_group', 'risk_factor', 'family_history', 'target']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DBDataset with categorical features\n",
    "db_mixed = DBDataset(\n",
    "    data=mixed_data,\n",
    "    target_column='target',\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    categorical_features=['age_group', 'risk_factor', 'family_history'],  # Specify categorical features\n",
    "    dataset_name='mixed_features_dataset'\n",
    ")\n",
    "\n",
    "# Check categorical features\n",
    "print(f\"Categorical features: {db_mixed.categorical_features}\")\n",
    "print(f\"Numerical features: {db_mixed.numerical_features[:5]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Adding a model and predictions to DBDataset\n",
    "\n",
    "We can train a model and add it to our dataset. This is useful when you want to use DeepBridge's distillation capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(db_dataset.get_feature_data('train'), db_dataset.get_target_data('train'))\n",
    "\n",
    "# Generate predictions\n",
    "train_probas = model.predict_proba(db_dataset.get_feature_data('train'))\n",
    "test_probas = model.predict_proba(db_dataset.get_feature_data('test'))\n",
    "\n",
    "# Create DataFrames for probabilities\n",
    "train_probas_df = pd.DataFrame(train_probas, columns=['prob_class_0', 'prob_class_1'])\n",
    "test_probas_df = pd.DataFrame(test_probas, columns=['prob_class_0', 'prob_class_1'])\n",
    "\n",
    "# Save model to a temporary file\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "model_path = os.path.join(temp_dir, 'rf_model.pkl')\n",
    "joblib.dump(model, model_path)\n",
    "print(f\"Saved model to: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DBDataset with model path\n",
    "db_with_model = DBDataset(\n",
    "    data=data,\n",
    "    target_column='target',\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    model_path=model_path,  # Path to saved model\n",
    "    dataset_name='dataset_with_model'\n",
    ")\n",
    "\n",
    "print(db_with_model)\n",
    "\n",
    "# Check if model is loaded\n",
    "print(f\"\\nModel type: {type(db_with_model.model).__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, create DBDataset with pre-calculated probabilities\n",
    "db_with_probs = DBDataset(\n",
    "    train_data=train_data,\n",
    "    test_data=test_data,\n",
    "    target_column='target',\n",
    "    train_predictions=train_probas_df,  # Pre-calculated train predictions\n",
    "    test_predictions=test_probas_df,    # Pre-calculated test predictions\n",
    "    prob_cols=['prob_class_0', 'prob_class_1'],  # Probability column names\n",
    "    dataset_name='dataset_with_probabilities'\n",
    ")\n",
    "\n",
    "print(db_with_probs)\n",
    "\n",
    "# Access probabilities\n",
    "print(\"\\nSample probabilities:\")\n",
    "print(db_with_probs.original_prob.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Generating synthetic data\n",
    "\n",
    "The `DBDataset` class can also generate synthetic data based on the original dataset distribution. This is useful for experimentation without using the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DBDataset with synthetic data generation enabled\n",
    "db_synthetic = DBDataset(\n",
    "    data=data,\n",
    "    target_column='target',\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    model_path=model_path,                # Model is required for synthetic data\n",
    "    synthetic=True,                       # Enable synthetic data generation\n",
    "    synthetic_sample=200,                 # Number of synthetic samples to generate\n",
    "    dataset_name='dataset_with_synthetic'\n",
    ")\n",
    "\n",
    "print(db_synthetic)\n",
    "\n",
    "# Access synthetic data\n",
    "if db_synthetic.synthetic_data is not None:\n",
    "    print(\"\\nSynthetic data shape:\", db_synthetic.synthetic_data.shape)\n",
    "    print(\"\\nSample synthetic data:\")\n",
    "    print(db_synthetic.synthetic_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Working with Experiment\n",
    "\n",
    "The `Experiment` class handles different types of modeling tasks and their configurations. It works with `DBDataset` to manage experiments, including model training, evaluation, and comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an experiment using the DBDataset with model\n",
    "experiment = Experiment(\n",
    "    dataset=db_with_model,\n",
    "    experiment_type=\"binary_classification\",\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    config={\"verbose\": True}  # Additional configuration\n",
    ")\n",
    "\n",
    "# Show experiment properties\n",
    "print(f\"Experiment type: {experiment.experiment_type}\")\n",
    "print(f\"Test size: {experiment.test_size}\")\n",
    "print(f\"Random state: {experiment.random_state}\")\n",
    "print(f\"Train data shape: {experiment.X_train.shape}\")\n",
    "print(f\"Test data shape: {experiment.X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Training distillation models\n",
    "\n",
    "One of the main functions of the `Experiment` class is to train distillation models. These are simpler models that mimic the behavior of complex models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an experiment using the DBDataset with probabilities\n",
    "experiment_probs = Experiment(\n",
    "    dataset=db_with_probs,\n",
    "    experiment_type=\"binary_classification\",\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    config={\"verbose\": True}\n",
    ")\n",
    "\n",
    "# Fit a distilled model using logistic regression\n",
    "experiment_probs.fit(\n",
    "    student_model_type=ModelType.LOGISTIC_REGRESSION,\n",
    "    temperature=1.0,\n",
    "    alpha=0.5,\n",
    "    use_probabilities=True,  # Use pre-calculated probabilities\n",
    "    n_trials=10,  # Number of hyperparameter optimization trials\n",
    "    distillation_method=\"surrogate\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Evaluating and comparing models\n",
    "\n",
    "After training, we can evaluate the distilled model and compare it to the original model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get metrics for both train and test sets\n",
    "metrics = experiment_probs.metrics\n",
    "\n",
    "# Print metrics\n",
    "print(\"Training set metrics:\")\n",
    "for key, value in metrics['train'].items():\n",
    "    if key not in ['best_params', 'distillation_method'] and value is not None:\n",
    "        print(f\"  {key}: {value:.4f}\")\n",
    "\n",
    "print(\"\\nTest set metrics:\")\n",
    "for key, value in metrics['test'].items():\n",
    "    if key not in ['best_params', 'distillation_method'] and value is not None:\n",
    "        print(f\"  {key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get student model predictions\n",
    "student_predictions = experiment_probs.get_student_predictions('test')\n",
    "\n",
    "# Display sample predictions\n",
    "print(\"Student model predictions:\")\n",
    "print(student_predictions.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Comparing teacher and student models\n",
    "\n",
    "We can directly compare the teacher (original) and student (distilled) models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare teacher and student models\n",
    "comparison = experiment_probs.compare_teacher_student_metrics()\n",
    "\n",
    "# Display comparison for test set\n",
    "test_comparison = comparison[comparison['dataset'] == 'test']\n",
    "test_comparison.sort_values('metric', inplace=True)\n",
    "\n",
    "print(\"Teacher vs Student Model Comparison (Test Set):\")\n",
    "print(test_comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Filter metrics for plotting\n",
    "metrics_to_plot = ['accuracy', 'precision', 'recall', 'f1_score', 'auc_roc', 'auc_pr']\n",
    "plot_data = test_comparison[test_comparison['metric'].isin(metrics_to_plot)]\n",
    "\n",
    "# Create bar plot\n",
    "x = np.arange(len(plot_data))\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(x - width/2, plot_data['teacher_value'], width, label='Teacher')\n",
    "plt.bar(x + width/2, plot_data['student_value'], width, label='Student')\n",
    "\n",
    "plt.xlabel('Metric')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Teacher vs Student Model Performance')\n",
    "plt.xticks(x, plot_data['metric'])\n",
    "plt.ylim([0.8, 1.0])  # Adjust as needed\n",
    "plt.legend()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Trying Different Distillation Methods\n",
    "\n",
    "DeepBridge supports different distillation methods. The two main ones are:\n",
    "\n",
    "1. **Surrogate Model**: Directly fits a model to the outputs of the teacher model\n",
    "2. **Knowledge Distillation**: Uses a combination of soft targets and hard labels for training\n",
    "\n",
    "Let's try the knowledge distillation method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a distilled model using knowledge distillation\n",
    "experiment_kd = Experiment(\n",
    "    dataset=db_with_probs,\n",
    "    experiment_type=\"binary_classification\",\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "experiment_kd.fit(\n",
    "    student_model_type=ModelType.GBM,  # Try a different model type\n",
    "    temperature=2.0,  # Higher temperature for softer probabilities\n",
    "    alpha=0.7,  # More weight on the teacher's soft targets\n",
    "    use_probabilities=True,\n",
    "    n_trials=10,\n",
    "    distillation_method=\"knowledge_distillation\"  # Use knowledge distillation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare results of different methods\n",
    "surrogate_metrics = experiment_probs.metrics['test']\n",
    "kd_metrics = experiment_kd.metrics['test']\n",
    "\n",
    "# Print comparison table\n",
    "print(\"Comparison of Distillation Methods (Test Set Metrics):\")\n",
    "print(\"\\nMetric         | Surrogate    | Knowledge Distillation\")\n",
    "print(\"--------------|--------------|-----------------------\")\n",
    "\n",
    "for metric in ['accuracy', 'precision', 'recall', 'f1_score', 'auc_roc', 'auc_pr']:\n",
    "    if metric in surrogate_metrics and metric in kd_metrics:\n",
    "        print(f\"{metric.ljust(14)}| {surrogate_metrics[metric]:.4f}      | {kd_metrics[metric]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Distribution similarity metrics\n",
    "\n",
    "DeepBridge provides metrics to measure how well the student model mimics the probability distribution of the teacher model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare distribution similarity metrics\n",
    "print(\"Distribution Similarity Metrics:\")\n",
    "print(\"\\nMetric             | Surrogate    | Knowledge Distillation\")\n",
    "print(\"-------------------|--------------|-----------------------\")\n",
    "\n",
    "for metric in ['kl_divergence', 'ks_statistic', 'r2_score']:\n",
    "    if metric in surrogate_metrics and metric in kd_metrics:\n",
    "        print(f\"{metric.ljust(19)}| {surrogate_metrics[metric]:.4f}      | {kd_metrics[metric]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the probability distributions to see how well each method mimics the teacher's outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions from all models\n",
    "surrogate_preds = experiment_probs.get_student_predictions('test')\n",
    "kd_preds = experiment_kd.get_student_predictions('test')\n",
    "\n",
    "# Extract teacher probabilities\n",
    "teacher_probs = db_with_probs.test_data.copy()\n",
    "for col in db_with_probs.original_prob.columns:\n",
    "    if col in ['prob_class_1', 'prob_1']:\n",
    "        teacher_probs = db_with_probs.original_prob[col].values\n",
    "        break\n",
    "if isinstance(teacher_probs, pd.DataFrame):\n",
    "    teacher_probs = teacher_probs.iloc[:, 1].values  # Get positive class probability\n",
    "\n",
    "# Plot distributions\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "sns.kdeplot(teacher_probs, label='Teacher', color='blue', linewidth=2)\n",
    "sns.kdeplot(surrogate_preds['prob_1'], label='Surrogate', color='red', linewidth=2)\n",
    "sns.kdeplot(kd_preds['prob_1'], label='Knowledge Distillation', color='green', linewidth=2)\n",
    "\n",
    "plt.xlabel('Probability of Positive Class')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Comparison of Probability Distributions')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we explored the core components of the DeepBridge library:\n",
    "\n",
    "1. **DBDataset**: A versatile class for managing datasets, features, and models\n",
    "   - Creating datasets from unified or split data\n",
    "   - Handling categorical features\n",
    "   - Adding models and predictions\n",
    "   - Generating synthetic data\n",
    "\n",
    "2. **Experiment**: A powerful tool for running distillation experiments\n",
    "   - Training student models using different distillation methods\n",
    "   - Evaluating and comparing model performance\n",
    "   - Analyzing distribution similarity\n",
    "\n",
    "3. **Distillation Methods**: Different approaches to model compression\n",
    "   - Surrogate models for direct mimicry\n",
    "   - Knowledge distillation for more nuanced learning\n",
    "\n",
    "DeepBridge makes it easy to compress complex models into simpler ones without significantly sacrificing performance, enabling faster inference, reduced memory requirements, and easier deployment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepbridge_homol",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
