{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Análise do Efeito da Temperatura na Destilação de Conhecimento\n",
    "\n",
    "Este notebook investiga como o parâmetro de temperatura afeta o processo de destilação de conhecimento usando a biblioteca DeepBridge. Exploraremos tanto os aspectos teóricos quanto práticos da temperatura na destilação, com visualizações e experimentos sistemáticos.\n",
    "\n",
    "## 1. Introdução à Temperatura na Destilação\n",
    "\n",
    "### O que é a Temperatura na Destilação de Conhecimento?\n",
    "\n",
    "Na destilação de conhecimento, a \"temperatura\" (T) é um hiperparâmetro que controla a suavidade das distribuições de probabilidade produzidas pelo modelo professor antes de serem usadas para treinar o modelo aluno.\n",
    "\n",
    "Matematicamente, a temperatura é aplicada às logits (valores pré-softmax) do modelo professor da seguinte forma:\n",
    "\n",
    "$$q_i = \\frac{\\exp(z_i/T)}{\\sum_j \\exp(z_j/T)}$$\n",
    "\n",
    "Onde:\n",
    "- $z_i$ são as logits originais do modelo professor\n",
    "- $T$ é o parâmetro de temperatura\n",
    "- $q_i$ são as probabilidades suavizadas\n",
    "\n",
    "#### Importância da Temperatura\n",
    "\n",
    "- **T = 1**: Comportamento padrão (softmax normal)\n",
    "- **T > 1**: Produz distribuições mais suaves, revelando mais informação sobre as relações entre classes\n",
    "- **T < 1**: Produz distribuições mais acentuadas, aproximando-se de one-hot encoding\n",
    "\n",
    "O efeito da temperatura é crucial porque determina a quantidade de \"conhecimento escuro\" transferido do professor para o aluno.\n",
    "\n",
    "## 2. Configuração do Ambiente e Importação de Bibliotecas\n",
    "\n",
    "\n",
    "```python\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, log_loss\n",
    "from scipy.special import softmax\n",
    "import warnings\n",
    "\n",
    "# Importações da biblioteca DeepBridge\n",
    "from deepbridge.db_data import DBDataset\n",
    "from deepbridge.auto_distiller import AutoDistiller\n",
    "from deepbridge.distillation.classification.model_registry import ModelType\n",
    "from deepbridge.auto.config import DistillationConfig\n",
    "from deepbridge.visualizer.distribution_visualizer import DistributionVisualizer\n",
    "\n",
    "# Configurar o estilo das visualizações\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurar o tamanho das figuras\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "```\n",
    "\n",
    "## 3. Efeito Visual da Temperatura nas Distribuições\n",
    "\n",
    "Para entender melhor o efeito da temperatura, vamos visualizar como diferentes valores de temperatura transformam as distribuições de probabilidade:\n",
    "\n",
    "\n",
    "```python\n",
    "def visualize_temperature_effect(logits, temperatures=[0.5, 1.0, 2.0, 5.0, 10.0]):\n",
    "    \"\"\"Visualiza o efeito da temperatura nas distribuições de probabilidade.\"\"\"\n",
    "    fig, axes = plt.subplots(len(temperatures), 1, figsize=(12, 4*len(temperatures)))\n",
    "    \n",
    "    # Certifique-se de que axes seja sempre uma lista, mesmo com um único subplot\n",
    "    if len(temperatures) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i, T in enumerate(temperatures):\n",
    "        # Aplicar temperatura nas logits\n",
    "        scaled_logits = logits / T\n",
    "        probs = softmax(scaled_logits, axis=1)\n",
    "        \n",
    "        # Plotar a distribuição de probabilidades\n",
    "        for j in range(min(5, probs.shape[0])):  # Limitar a 5 exemplos para clareza\n",
    "            axes[i].bar(range(probs.shape[1]), probs[j], alpha=0.7, \n",
    "                      label=f'Exemplo {j+1}' if i == 0 else \"\")\n",
    "            \n",
    "        axes[i].set_title(f'Temperatura T = {T}')\n",
    "        axes[i].set_xlabel('Classes')\n",
    "        axes[i].set_ylabel('Probabilidade')\n",
    "        axes[i].set_ylim(0, 1)\n",
    "        \n",
    "        # Calcular entropia para esta temperatura\n",
    "        entropy = -np.sum(probs * np.log(probs + 1e-10), axis=1).mean()\n",
    "        axes[i].text(0.02, 0.95, f'Entropia Média: {entropy:.4f}', \n",
    "                   transform=axes[i].transAxes, bbox=dict(facecolor='white', alpha=0.8))\n",
    "        \n",
    "    # Legenda apenas no primeiro gráfico\n",
    "    axes[0].legend(loc='upper right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Gerar logits sintéticos para demonstração\n",
    "np.random.seed(42)\n",
    "synthetic_logits = np.random.randn(5, 10) * 2  # 5 exemplos, 10 classes\n",
    "\n",
    "# Tornar a classe 3 tipicamente a mais forte para demonstração\n",
    "synthetic_logits[:, 3] += 2\n",
    "\n",
    "# Visualizar o efeito\n",
    "visualize_temperature_effect(synthetic_logits)\n",
    "```\n",
    "\n",
    "### Análise do Efeito da Temperatura:\n",
    "\n",
    "Como podemos observar nos gráficos acima:\n",
    "\n",
    "1. **T = 0.5**: Com temperatura baixa, as probabilidades se concentram fortemente na classe dominante, aproximando-se de uma codificação one-hot. Isso resulta em menor entropia.\n",
    "\n",
    "2. **T = 1.0**: Representa o comportamento padrão do softmax, onde a distribuição já mostra alguma incerteza entre classes.\n",
    "\n",
    "3. **T = 2.0**: A distribuição se torna mais suave, revelando mais informação sobre as relações entre classes. A entropia aumenta.\n",
    "\n",
    "4. **T = 5.0** e **T = 10.0**: Com temperaturas muito altas, as distribuições se aproximam de uma distribuição uniforme, onde as diferenças sutis entre classes são amplificadas. A entropia continua aumentando.\n",
    "\n",
    "Este efeito de suavização é essencial para a destilação porque:\n",
    "- Revela o \"conhecimento escuro\" do modelo professor\n",
    "- Expõe relações entre classes que não são evidentes nas previsões binárias\n",
    "- Permite que o modelo aluno aprenda padrões mais sutis\n",
    "\n",
    "## 4. Preparação dos Dados para Experimentos\n",
    "\n",
    "\n",
    "```python\n",
    "# Criar um conjunto de dados sintético para experimentação\n",
    "X, y = make_classification(\n",
    "    n_samples=5000,\n",
    "    n_features=20,\n",
    "    n_informative=15,\n",
    "    n_redundant=5,\n",
    "    n_classes=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Dividir em conjuntos de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Treinar um modelo professor (Random Forest)\n",
    "teacher_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "teacher_model.fit(X_train, y_train)\n",
    "\n",
    "# Gerar probabilidades do modelo professor\n",
    "train_probs = teacher_model.predict_proba(X_train)\n",
    "test_probs = teacher_model.predict_proba(X_test)\n",
    "\n",
    "# Criar DataFrames para as probabilidades\n",
    "train_prob_df = pd.DataFrame(train_probs, columns=['prob_class_0', 'prob_class_1'])\n",
    "test_prob_df = pd.DataFrame(test_probs, columns=['prob_class_0', 'prob_class_1'])\n",
    "\n",
    "# Criar DataFrames para os dados de entrada\n",
    "train_df = pd.DataFrame(X_train, columns=[f'feature_{i}' for i in range(X_train.shape[1])])\n",
    "train_df['target'] = y_train\n",
    "train_df = pd.concat([train_df, train_prob_df], axis=1)\n",
    "\n",
    "test_df = pd.DataFrame(X_test, columns=[f'feature_{i}' for i in range(X_test.shape[1])])\n",
    "test_df['target'] = y_test\n",
    "test_df = pd.concat([test_df, test_prob_df], axis=1)\n",
    "\n",
    "# Criar um DBDataset\n",
    "dataset = DBDataset(\n",
    "    train_data=train_df,\n",
    "    test_data=test_df,\n",
    "    target_column='target',\n",
    "    prob_cols=['prob_class_0', 'prob_class_1']\n",
    ")\n",
    "\n",
    "print(f\"Conjunto de dados criado: {len(train_df)} amostras de treino, {len(test_df)} amostras de teste\")\n",
    "print(f\"Performance do modelo professor no conjunto de teste:\")\n",
    "print(f\"  Acurácia: {accuracy_score(y_test, teacher_model.predict(X_test)):.4f}\")\n",
    "print(f\"  AUC-ROC: {roc_auc_score(y_test, test_probs[:, 1]):.4f}\")\n",
    "print(f\"  Log Loss: {log_loss(y_test, test_probs):.4f}\")\n",
    "```\n",
    "\n",
    "## 5. Experimentos com Diferentes Temperaturas\n",
    "\n",
    "Agora, vamos explorar como diferentes valores de temperatura afetam o desempenho dos modelos destilados. Executaremos uma série de experimentos sistemáticos com diferentes combinações de modelos, temperaturas e valores de alpha (peso entre o erro de destilação e o erro de classificação).\n",
    "\n",
    "\n",
    "```python\n",
    "# Configurar experimentação sistemática com diferentes temperaturas\n",
    "temperatures = [0.5, 1.0, 2.0, 3.0, 5.0, 10.0]\n",
    "alphas = [0.3, 0.5, 0.7, 0.9]\n",
    "\n",
    "# Modelos a serem testados\n",
    "model_types = [\n",
    "    ModelType.LOGISTIC_REGRESSION,\n",
    "    ModelType.DECISION_TREE,\n",
    "    ModelType.GBM,\n",
    "]\n",
    "\n",
    "# Diretório para salvar resultados\n",
    "output_dir = \"temperatura_destilacao_resultados\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Configuração do AutoDistiller\n",
    "config = DistillationConfig(\n",
    "    output_dir=output_dir,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    n_trials=10,  # Reduzido para economizar tempo\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Personalizar a configuração\n",
    "config.customize(\n",
    "    model_types=model_types,\n",
    "    temperatures=temperatures,\n",
    "    alphas=alphas\n",
    ")\n",
    "\n",
    "# Criar o AutoDistiller\n",
    "distiller = AutoDistiller(\n",
    "    dataset=dataset,\n",
    "    output_dir=output_dir,\n",
    "    random_state=42,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Personalizar a configuração\n",
    "distiller.customize_config(\n",
    "    model_types=model_types,\n",
    "    temperatures=temperatures,\n",
    "    alphas=alphas\n",
    ")\n",
    "\n",
    "# Executar os experimentos\n",
    "print(\"Executando experimentos de destilação com diferentes temperaturas...\")\n",
    "results_df = distiller.run(verbose_output=False)\n",
    "\n",
    "# Salvar resultados em CSV para análise posterior\n",
    "results_df.to_csv(os.path.join(output_dir, \"temperatura_resultados.csv\"), index=False)\n",
    "print(f\"Experimentos concluídos. Resultados salvos em {output_dir}/temperatura_resultados.csv\")\n",
    "```\n",
    "\n",
    "## 6. Análise dos Resultados: Efeito da Temperatura\n",
    "\n",
    "Agora, vamos analisar os resultados dos experimentos para entender como a temperatura afeta diferentes aspectos do modelo destilado:\n",
    "\n",
    "\n",
    "```python\n",
    "# Carregar os resultados\n",
    "results_df = pd.read_csv(os.path.join(output_dir, \"temperatura_resultados.csv\"))\n",
    "\n",
    "# Função para criar gráficos de temperatura versus métricas\n",
    "def plot_temperature_vs_metrics(results_df, metrics, model_type=None):\n",
    "    \"\"\"\n",
    "    Plota a relação entre temperatura e múltiplas métricas.\n",
    "    \n",
    "    Args:\n",
    "        results_df: DataFrame com resultados\n",
    "        metrics: Lista de tuplas (métrica, título, minimize)\n",
    "        model_type: Filtrar por tipo de modelo (opcional)\n",
    "    \"\"\"\n",
    "    if model_type:\n",
    "        df = results_df[results_df['model_type'] == model_type].copy()\n",
    "        title_suffix = f\" - {model_type}\"\n",
    "    else:\n",
    "        df = results_df.copy()\n",
    "        title_suffix = \" - Todos os Modelos\"\n",
    "    \n",
    "    # Número de métricas determina o layout\n",
    "    n_metrics = len(metrics)\n",
    "    fig, axes = plt.subplots(n_metrics, 1, figsize=(12, 5*n_metrics))\n",
    "    \n",
    "    # Garantir que axes seja sempre uma lista\n",
    "    if n_metrics == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i, (metric, title, minimize) in enumerate(metrics):\n",
    "        # Agrupar por temperatura e calcular média/desvio padrão\n",
    "        temp_grouped = df.groupby('temperature')[metric].agg(['mean', 'std']).reset_index()\n",
    "        \n",
    "        # Plotar a relação\n",
    "        axes[i].errorbar(temp_grouped['temperature'], temp_grouped['mean'], \n",
    "                       yerr=temp_grouped['std'], marker='o', linestyle='-', linewidth=2, \n",
    "                       elinewidth=1, capsize=5)\n",
    "        \n",
    "        # Adicionar linha de tendência\n",
    "        z = np.polyfit(temp_grouped['temperature'], temp_grouped['mean'], 2)\n",
    "        p = np.poly1d(z)\n",
    "        x_trend = np.linspace(min(temp_grouped['temperature']), max(temp_grouped['temperature']), 100)\n",
    "        axes[i].plot(x_trend, p(x_trend), \"r--\", alpha=0.7)\n",
    "        \n",
    "        # Encontrar a temperatura ótima\n",
    "        if minimize:\n",
    "            best_idx = temp_grouped['mean'].idxmin()\n",
    "            best_direction = \"menor\"\n",
    "        else:\n",
    "            best_idx = temp_grouped['mean'].idxmax() \n",
    "            best_direction = \"maior\"\n",
    "            \n",
    "        best_temp = temp_grouped.loc[best_idx, 'temperature']\n",
    "        best_value = temp_grouped.loc[best_idx, 'mean']\n",
    "        \n",
    "        # Destacar a temperatura ótima\n",
    "        axes[i].scatter([best_temp], [best_value], s=100, c='red', zorder=5)\n",
    "        axes[i].annotate(f'Melhor: T={best_temp}\\n{metric}={best_value:.4f}', \n",
    "                       xy=(best_temp, best_value),\n",
    "                       xytext=(10, -20), textcoords='offset points',\n",
    "                       arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=.2'))\n",
    "        \n",
    "        # Configurar o gráfico\n",
    "        axes[i].set_title(f\"{title}{title_suffix}\")\n",
    "        axes[i].set_xlabel('Temperatura')\n",
    "        axes[i].set_ylabel(metric)\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Adicionar anotação sobre melhor valor\n",
    "        axes[i].text(0.02, 0.95, f'Temperatura ótima: {best_temp} ({best_direction} {metric})',\n",
    "                   transform=axes[i].transAxes, bbox=dict(facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Definir métricas para análise\n",
    "metrics_to_analyze = [\n",
    "    ('test_accuracy', 'Acurácia vs Temperatura', False),\n",
    "    ('test_auc_roc', 'AUC-ROC vs Temperatura', False),\n",
    "    ('test_kl_divergence', 'KL Divergência vs Temperatura', True),\n",
    "    ('test_r2_score', 'R² Score vs Temperatura', False)\n",
    "]\n",
    "\n",
    "# Análise geral (todos os modelos)\n",
    "fig_all = plot_temperature_vs_metrics(results_df, metrics_to_analyze)\n",
    "plt.savefig(os.path.join(output_dir, \"temperatura_vs_metricas_geral.png\"))\n",
    "plt.show()\n",
    "\n",
    "# Análise por tipo de modelo\n",
    "for model_type in model_types:\n",
    "    model_name = model_type.name\n",
    "    fig_model = plot_temperature_vs_metrics(results_df, metrics_to_analyze, model_name)\n",
    "    plt.savefig(os.path.join(output_dir, f\"temperatura_vs_metricas_{model_name}.png\"))\n",
    "    plt.show()\n",
    "```\n",
    "\n",
    "### Análise da Temperatura Ótima\n",
    "\n",
    "Vamos identificar a temperatura ótima para cada métrica e tipo de modelo:\n",
    "\n",
    "\n",
    "```python\n",
    "def find_optimal_temperatures(results_df):\n",
    "    \"\"\"\n",
    "    Encontra a temperatura ótima para cada métrica e tipo de modelo.\n",
    "    \"\"\"\n",
    "    metrics = [\n",
    "        ('test_accuracy', False),\n",
    "        ('test_auc_roc', False),\n",
    "        ('test_kl_divergence', True),\n",
    "        ('test_r2_score', False)\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Análise global (todos os modelos)\n",
    "    for metric, minimize in metrics:\n",
    "        # Agrupar por temperatura\n",
    "        temp_grouped = results_df.groupby('temperature')[metric].mean().reset_index()\n",
    "        \n",
    "        # Encontrar valor ótimo\n",
    "        if minimize:\n",
    "            best_idx = temp_grouped[metric].idxmin()\n",
    "        else:\n",
    "            best_idx = temp_grouped[metric].idxmax()\n",
    "            \n",
    "        optimal_temp = temp_grouped.loc[best_idx, 'temperature']\n",
    "        optimal_value = temp_grouped.loc[best_idx, metric]\n",
    "        \n",
    "        results.append({\n",
    "            'Métrica': metric,\n",
    "            'Modelo': 'Global',\n",
    "            'Temperatura Ótima': optimal_temp,\n",
    "            'Valor Ótimo': optimal_value\n",
    "        })\n",
    "    \n",
    "    # Análise por tipo de modelo\n",
    "    for model in results_df['model_type'].unique():\n",
    "        model_df = results_df[results_df['model_type'] == model]\n",
    "        \n",
    "        for metric, minimize in metrics:\n",
    "            # Agrupar por temperatura\n",
    "            temp_grouped = model_df.groupby('temperature')[metric].mean().reset_index()\n",
    "            \n",
    "            # Encontrar valor ótimo\n",
    "            if minimize:\n",
    "                best_idx = temp_grouped[metric].idxmin()\n",
    "            else:\n",
    "                best_idx = temp_grouped[metric].idxmax()\n",
    "                \n",
    "            optimal_temp = temp_grouped.loc[best_idx, 'temperature']\n",
    "            optimal_value = temp_grouped.loc[best_idx, metric]\n",
    "            \n",
    "            results.append({\n",
    "                'Métrica': metric,\n",
    "                'Modelo': model,\n",
    "                'Temperatura Ótima': optimal_temp,\n",
    "                'Valor Ótimo': optimal_value\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Encontrar temperaturas ótimas\n",
    "optimal_temps_df = find_optimal_temperatures(results_df)\n",
    "\n",
    "# Pivot para visualização mais clara\n",
    "optimal_temps_pivot = optimal_temps_df.pivot_table(\n",
    "    index='Modelo', \n",
    "    columns='Métrica',\n",
    "    values=['Temperatura Ótima', 'Valor Ótimo']\n",
    ")\n",
    "\n",
    "# Exibir resultados\n",
    "print(\"Temperatura Ótima por Modelo e Métrica:\")\n",
    "print(optimal_temps_pivot)\n",
    "\n",
    "# Salvar resultados\n",
    "optimal_temps_df.to_csv(os.path.join(output_dir, \"temperaturas_otimas.csv\"), index=False)\n",
    "optimal_temps_pivot.to_csv(os.path.join(output_dir, \"temperaturas_otimas_pivot.csv\"))\n",
    "```\n",
    "\n",
    "## 7. Visualização Detalhada das Distribuições de Probabilidade\n",
    "\n",
    "Para entender melhor o impacto da temperatura na transferência de conhecimento, vamos examinar as distribuições de probabilidade do professor e dos modelos alunos treinados com diferentes temperaturas:\n",
    "\n",
    "\n",
    "```python\n",
    "# Funções para visualizar as distribuições de probabilidade\n",
    "def plot_probability_distributions_comparison(teacher_probs, student_probs_dict, title=\"Comparação de Distribuições de Probabilidade\"):\n",
    "    \"\"\"\n",
    "    Plota comparação entre distribuições de probabilidade do professor e vários modelos alunos.\n",
    "    \n",
    "    Args:\n",
    "        teacher_probs: Probabilidades do modelo professor\n",
    "        student_probs_dict: Dicionário {nome: probs} com probabilidades dos modelos alunos\n",
    "        title: Título do gráfico\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    \n",
    "    # Histograma do professor\n",
    "    sns.kdeplot(teacher_probs, fill=True, color=\"royalblue\", alpha=0.6, label=\"Modelo Professor\")\n",
    "    \n",
    "    # Histogramas dos alunos\n",
    "    colors = ['crimson', 'forestgreen', 'darkorange', 'purple', 'brown']\n",
    "    for i, (name, probs) in enumerate(student_probs_dict.items()):\n",
    "        sns.kdeplot(probs, fill=False, color=colors[i % len(colors)], lw=2, label=name)\n",
    "    \n",
    "    plt.xlabel(\"Probabilidade da Classe Positiva\")\n",
    "    plt.ylabel(\"Densidade\")\n",
    "    plt.title(title)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Encontrar os melhores modelos para diferentes temperaturas\n",
    "def get_best_models_for_temperatures(results_df, model_type, temperatures, metric='test_accuracy'):\n",
    "    \"\"\"\n",
    "    Obtém os melhores modelos (por alpha) para cada temperatura especificada.\n",
    "    \"\"\"\n",
    "    best_models = {}\n",
    "    \n",
    "    for temp in temperatures:\n",
    "        # Filtrar por modelo e temperatura\n",
    "        filtered = results_df[(results_df['model_type'] == model_type) & \n",
    "                             (results_df['temperature'] == temp)]\n",
    "        \n",
    "        if filtered.empty:\n",
    "            continue\n",
    "            \n",
    "        # Encontrar o melhor alpha para esta temperatura\n",
    "        best_idx = filtered[metric].idxmax()\n",
    "        best_row = filtered.loc[best_idx]\n",
    "        \n",
    "        best_models[temp] = {\n",
    "            'temperature': temp,\n",
    "            'alpha': best_row['alpha'],\n",
    "            'accuracy': best_row['test_accuracy'],\n",
    "            'auc_roc': best_row.get('test_auc_roc', None),\n",
    "            'kl_divergence': best_row.get('test_kl_divergence', None)\n",
    "        }\n",
    "    \n",
    "    return best_models\n",
    "\n",
    "# Selecionar um modelo para visualização detalhada\n",
    "selected_model_type = 'GBM'  # Pode ser alterado para outro modelo\n",
    "temperatures_to_visualize = [0.5, 1.0, 2.0, 5.0]\n",
    "\n",
    "# Obter os melhores modelos para cada temperatura\n",
    "best_models = get_best_models_for_temperatures(\n",
    "    results_df, \n",
    "    selected_model_type,\n",
    "    temperatures_to_visualize\n",
    ")\n",
    "\n",
    "# Criar e treinar os modelos para visualização\n",
    "print(f\"Treinando modelos {selected_model_type} com diferentes temperaturas para visualização...\")\n",
    "\n",
    "# Obter probabilidades do professor para o conjunto de teste\n",
    "teacher_probs = test_prob_df['prob_class_1'].values\n",
    "\n",
    "# Dicionário para armazenar probabilidades dos modelos alunos\n",
    "student_probs_dict = {}\n",
    "\n",
    "# Criar e treinar um modelo para cada temperatura selecionada\n",
    "for temp, model_info in best_models.items():\n",
    "    # Configurar e treinar um modelo para esta temperatura\n",
    "    temp_distiller = AutoDistiller(\n",
    "        dataset=dataset,\n",
    "        output_dir=os.path.join(output_dir, f\"temp_{temp}\"),\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    # Customizar para esta configuração específica\n",
    "    temp_distiller.customize_config(\n",
    "        model_types=[ModelType[selected_model_type]],\n",
    "        temperatures=[temp],\n",
    "        alphas=[model_info['alpha']]\n",
    "    )\n",
    "    \n",
    "    # Executar o treinamento\n",
    "    temp_results = temp_distiller.run(verbose_output=False)\n",
    "    \n",
    "    # Obter o melhor modelo\n",
    "    best_model = temp_distiller.find_best_model()\n",
    "    \n",
    "    # Obter o modelo treinado\n",
    "    model = temp_distiller.get_trained_model(\n",
    "        model_type=best_model['model_type'],\n",
    "        temperature=best_model['temperature'],\n",
    "        alpha=best_model['alpha']\n",
    "    )\n",
    "    \n",
    "    # Gerar probabilidades para o conjunto de teste\n",
    "    X_test_features = test_df.drop(['target', 'prob_class_0', 'prob_class_1'], axis=1).values\n",
    "    student_probs = model.predict_proba(X_test_features)[:, 1]\n",
    "    \n",
    "    # Armazenar no dicionário\n",
    "    student_probs_dict[f\"T={temp}, α={model_info['alpha']}\"] = student_probs\n",
    "\n",
    "# Visualizar as distribuições\n",
    "plot_probability_distributions_comparison(\n",
    "    teacher_probs, \n",
    "    student_probs_dict,\n",
    "    title=f\"Comparação de Distribuições de Probabilidade - Modelo {selected_model_type}\"\n",
    ")\n",
    "\n",
    "# Criar visualizador de distribuição para análise mais detalhada\n",
    "visualizer = DistributionVisualizer(os.path.join(output_dir, \"distribuicoes\"))\n",
    "\n",
    "# Comparar as distribuições para cada temperatura\n",
    "for name, probs in student_probs_dict.items():\n",
    "    visualizer.compare_distributions(\n",
    "        teacher_probs=teacher_probs,\n",
    "        student_probs=probs,\n",
    "        title=f\"Distribuição de Probabilidades - {name}\",\n",
    "        filename=f\"distribuicao_{name.replace('=', '_').replace(', ', '_').replace('.', 'p')}.png\",\n",
    "        show_metrics=True\n",
    "    )\n",
    "    \n",
    "    # Gráfico QQ para verificar alinhamento de distribuições\n",
    "    visualizer.create_quantile_plot(\n",
    "        teacher_probs=teacher_probs,\n",
    "        student_probs=probs,\n",
    "        title=f\"Q-Q Plot - {name}\",\n",
    "        filename=f\"qq_plot_{name.replace('=', '_').replace(', ', '_').replace('.', 'p')}.png\"\n",
    "    )\n",
    "```\n",
    "\n",
    "## 8. Análise da Interação entre Temperatura e Alpha\n",
    "\n",
    "Vamos agora analisar como a temperatura e o parâmetro alpha interagem:\n",
    "\n",
    "\n",
    "```python\n",
    "# Criar um heatmap para visualizar a interação entre temperatura e alpha\n",
    "def plot_temperature_alpha_heatmap(results_df, metric, model_type, title=None):\n",
    "    \"\"\"\n",
    "    Cria um heatmap para visualizar o efeito conjunto de temperatura e alpha.\n",
    "    \n",
    "    Args:\n",
    "        results_df: DataFrame com resultados\n",
    "        metric: Métrica a ser visualizada\n",
    "        model_type: Tipo de modelo a analisar\n",
    "        title: Título do gráfico (opcional)\n",
    "    \"\"\"\n",
    "    # Filtrar por modelo\n",
    "    filtered_df = results_df[results_df['model_type'] == model_type]\n",
    "    \n",
    "    # Criar pivot table\n",
    "    pivot = filtered_df.pivot_table(\n",
    "        index='alpha', \n",
    "        columns='temperature', \n",
    "        values=metric,\n",
    "        aggfunc='mean'\n",
    "    )\n",
    "    \n",
    "    # Determinar colormap com base na métrica\n",
    "    if metric == 'test_kl_divergence' or metric == 'test_ks_statistic':\n",
    "        cmap = 'viridis_r'  # Valores menores são melhores\n",
    "        best_text = \"menor\"\n",
    "    else:\n",
    "        cmap = 'viridis'  # Valores maiores são melhores\n",
    "        best_text = \"maior\"\n",
    "    \n",
    "    # Plotar heatmap\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    ax = sns.heatmap(pivot, annot=True, fmt=\".4f\", cmap=cmap, \n",
    "                    linewidths=.5, cbar_kws={'label': metric})\n",
    "    \n",
    "    # Encontrar a combinação ótima\n",
    "    if metric == 'test_kl_divergence' or metric == 'test_ks_statistic':\n",
    "        best_value = pivot.min().min()\n",
    "        best_idx = pivot.stack().idxmin()\n",
    "    else:\n",
    "        best_value = pivot.max().max()\n",
    "        best_idx = pivot.stack().idxmax()\n",
    "    \n",
    "    best_alpha, best_temp = best_idx\n",
    "    \n",
    "    # Título do gráfico\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    else:\n",
    "        plt.title(f\"{metric} por Temperatura e Alpha - {model_type}\")\n",
    "    \n",
    "    plt.xlabel(\"Temperatura\")\n",
    "    plt.ylabel(\"Alpha\")\n",
    "    \n",
    "    # Adicionar anotação com melhor combinação\n",
    "    plt.figtext(0.5, 0.01, \n",
    "               f\"Melhor combinação: Temperatura = {best_temp}, Alpha = {best_alpha}\\n\"\n",
    "               f\"Valor {best_text}: {best_value:.4f}\", \n",
    "               ha=\"center\", fontsize=12, bbox={\"facecolor\":\"white\", \"alpha\":0.8, \"pad\":5})\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0.05, 1, 1])\n",
    "    return plt.gcf()\n",
    "\n",
    "# Analisar a interação para diferentes métricas e modelos\n",
    "metrics_to_visualize = {\n",
    "    'test_accuracy': 'Acurácia',\n",
    "    'test_auc_roc': 'AUC-ROC',\n",
    "    'test_kl_divergence': 'KL Divergência',\n",
    "    'test_r2_score': 'R² Score'\n",
    "}\n",
    "\n",
    "for model_type in model_types:\n",
    "    model_name = model_type.name\n",
    "    for metric, metric_name in metrics_to_visualize.items():\n",
    "        if metric in results_df.columns:\n",
    "            fig = plot_temperature_alpha_heatmap(\n",
    "                results_df, \n",
    "                metric, \n",
    "                model_name,\n",
    "                f\"{metric_name} por Temperatura e Alpha - {model_name}\"\n",
    "            )\n",
    "            plt.savefig(os.path.join(output_dir, f\"heatmap_{metric}_{model_name}.png\"))\n",
    "            plt.show()\n",
    "```\n",
    "\n",
    "## 9. Recomendações para Seleção de Temperatura Ótima\n",
    "\n",
    "Com base nos experimentos realizados, podemos extrair recomendações sobre como selecionar a temperatura ideal para diferentes cenários:\n",
    "\n",
    "\n",
    "```python\n",
    "# Função para fornecer recomendações baseadas nos resultados\n",
    "def provide_temperature_recommendations(results_df):\n",
    "    \"\"\"\n",
    "    Fornece recomendações sobre seleção de temperatura com base nos resultados.\n",
    "    \"\"\"\n",
    "    # Calcular médias agrupadas por temperatura\n",
    "    temp_metrics = results_df.groupby('temperature').agg({\n",
    "        'test_accuracy': 'mean',\n",
    "        'test_auc_roc': 'mean',\n",
    "        'test_kl_divergence': 'mean',\n",
    "        'test_r2_score': 'mean'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Identificar temperaturas ótimas por métrica\n",
    "    best_accuracy_temp = temp_metrics.loc[temp_metrics['test_accuracy'].idxmax(), 'temperature']\n",
    "    best_auc_temp = temp_metrics.loc[temp_metrics['test_auc_roc'].idxmax(), 'temperature']\n",
    "    best_kl_temp = temp_metrics.loc[temp_metrics['test_kl_divergence'].idxmin(), 'temperature']\n",
    "    best_r2_temp = temp_metrics.loc[temp_metrics['test_r2_score'].idxmax(), 'temperature']\n",
    "    \n",
    "    # Calcular temperatura média \"ótima\"\n",
    "    mean_optimal_temp = np.mean([best_accuracy_temp, best_auc_temp, best_r2_temp])\n",
    "    \n",
    "    # Identificar temperaturas por tipo de modelo\n",
    "    model_temp_recommendations = {}\n",
    "    for model in results_df['model_type'].unique():\n",
    "        model_df = results_df[results_df['model_type'] == model]\n",
    "        model_temp_metrics = model_df.groupby('temperature').agg({\n",
    "            'test_accuracy': 'mean',\n",
    "            'test_kl_divergence': 'mean'\n",
    "        }).reset_index()\n",
    "        \n",
    "        best_acc_temp = model_temp_metrics.loc[model_temp_metrics['test_accuracy'].idxmax(), 'temperature']\n",
    "        best_kl_diverg_temp = model_temp_metrics.loc[model_temp_metrics['test_kl_divergence'].idxmin(), 'temperature']\n",
    "        \n",
    "        model_temp_recommendations[model] = {\n",
    "            'accuracy_temp': best_acc_temp,\n",
    "            'kl_divergence_temp': best_kl_diverg_temp\n",
    "        }\n",
    "    \n",
    "    # Preparar recomendações\n",
    "    recommendations = {\n",
    "        'general': {\n",
    "            'best_accuracy_temp': best_accuracy_temp,\n",
    "            'best_auc_temp': best_auc_temp,\n",
    "            'best_kl_temp': best_kl_temp,\n",
    "            'best_r2_temp': best_r2_temp,\n",
    "            'mean_optimal_temp': mean_optimal_temp\n",
    "        },\n",
    "        'by_model': model_temp_recommendations\n",
    "    }\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "# Gerar recomendações\n",
    "recommendations = provide_temperature_recommendations(results_df)\n",
    "\n",
    "# Exibir recomendações\n",
    "print(\"### Recomendações para Seleção de Temperatura Ótima ###\\n\")\n",
    "print(\"Recomendações Gerais:\")\n",
    "for metric, value in recommendations['general'].items():\n",
    "    print(f\" - {metric}: {value:.2f}\")\n",
    "\n",
    "print(\"\\nRecomendações por Modelo:\")\n",
    "for model, recs in recommendations['by_model'].items():\n",
    "    print(f\" - {model}:\")\n",
    "    for metric, value in recs.items():\n",
    "        print(f\"   * {metric}: {value:.2f}\")\n",
    "```\n",
    "\n",
    "Baseando-se em todos os experimentos e análises realizadas, podemos estabelecer algumas diretrizes gerais para seleção da temperatura na destilação:\n",
    "\n",
    "1. **Para maximizar precisão geral (acurácia e AUC):**\n",
    "   - Temperaturas entre 2.0 e 3.0 tendem a oferecer o melhor equilíbrio\n",
    "   - Modelos mais simples (como Regressão Logística) se beneficiam de temperaturas mais altas\n",
    "\n",
    "2. **Para melhor correspondência de distribuições (KL divergência e R²):**\n",
    "   - Temperaturas entre 1.0 e 2.0 geralmente produzem distribuições mais similares\n",
    "   - A correspondência de distribuição tende a piorar com temperaturas extremas (muito altas ou muito baixas)\n",
    "\n",
    "3. **Recomendações específicas por modelo:**\n",
    "   - **Regressão Logística**: Temperaturas mais altas (2.0-5.0) compensam a capacidade limitada do modelo\n",
    "   - **Árvores de Decisão**: Temperaturas médias (1.0-2.0) funcionam melhor\n",
    "   - **GBM/XGB**: Temperaturas entre 2.0 e 3.0 oferecem bom equilíbrio entre precisão e correspondência de distribuição\n",
    "\n",
    "4. **Considerações sobre o valor de alpha:**\n",
    "   - Com temperaturas mais altas (T > 3.0), valores de alpha mais baixos (0.3-0.5) tendem a funcionar melhor\n",
    "   - Com temperaturas médias (T = 1.0-3.0), valores de alpha intermediários (0.5-0.7) são mais eficazes\n",
    "   - Com temperaturas baixas (T < 1.0), valores de alpha mais altos (0.7-0.9) geralmente são preferíveis\n",
    "\n",
    "## 10. Estudo de Caso: Identificando a Temperatura e Alpha Ideais\n",
    "\n",
    "\n",
    "```python\n",
    "# Função para avaliar o desempenho de temperatura e alpha específicos\n",
    "def evaluate_specific_configuration(dataset, model_type, temperature, alpha, n_trials=5):\n",
    "    \"\"\"\n",
    "    Avalia detalhadamente uma configuração específica de temperatura e alpha.\n",
    "    \n",
    "    Args:\n",
    "        dataset: DBDataset para treinamento\n",
    "        model_type: Tipo de modelo a usar\n",
    "        temperature: Valor de temperatura a avaliar\n",
    "        alpha: Valor de alpha a avaliar\n",
    "        n_trials: Número de execuções para estabilidade estatística\n",
    "    \n",
    "    Returns:\n",
    "        Dicionário com resultados médios\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for trial in range(n_trials):\n",
    "        # Configurar um distiller específico\n",
    "        specific_distiller = AutoDistiller(\n",
    "            dataset=dataset,\n",
    "            output_dir=os.path.join(output_dir, f\"config_test_{temperature}_{alpha}_{trial}\"),\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        # Customizar a configuração\n",
    "        specific_distiller.customize_config(\n",
    "            model_types=[ModelType[model_type]],\n",
    "            temperatures=[temperature],\n",
    "            alphas=[alpha]\n",
    "        )\n",
    "        \n",
    "        # Executar treinamento\n",
    "        trial_results = specific_distiller.run(verbose_output=False)\n",
    "        \n",
    "        # Obter métricas\n",
    "        if not trial_results.empty:\n",
    "            row = trial_results.iloc[0]\n",
    "            results.append({\n",
    "                'trial': trial,\n",
    "                'accuracy': row.get('test_accuracy', None),\n",
    "                'auc_roc': row.get('test_auc_roc', None),\n",
    "                'kl_divergence': row.get('test_kl_divergence', None),\n",
    "                'r2_score': row.get('test_r2_score', None)\n",
    "            })\n",
    "    \n",
    "    # Calcular médias\n",
    "    if results:\n",
    "        avg_results = {\n",
    "            'model_type': model_type,\n",
    "            'temperature': temperature,\n",
    "            'alpha': alpha,\n",
    "            'accuracy': np.mean([r['accuracy'] for r in results if r['accuracy'] is not None]),\n",
    "            'auc_roc': np.mean([r['auc_roc'] for r in results if r['auc_roc'] is not None]),\n",
    "            'kl_divergence': np.mean([r['kl_divergence'] for r in results if r['kl_divergence'] is not None]),\n",
    "            'r2_score': np.mean([r['r2_score'] for r in results if r['r2_score'] is not None]),\n",
    "            'n_trials': len(results)\n",
    "        }\n",
    "        return avg_results\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Selecionar uma configuração ótima baseada nas análises anteriores\n",
    "optimal_config = {\n",
    "    'model_type': 'GBM',\n",
    "    'temperature': 2.0,  # Baseado nas análises anteriores\n",
    "    'alpha': 0.7         # Baseado nas análises anteriores\n",
    "}\n",
    "\n",
    "# Avaliar a configuração ótima (3 trials para estabilidade)\n",
    "print(f\"Avaliando configuração ótima: {optimal_config}...\")\n",
    "optimal_results = evaluate_specific_configuration(\n",
    "    dataset,\n",
    "    optimal_config['model_type'],\n",
    "    optimal_config['temperature'],\n",
    "    optimal_config['alpha'],\n",
    "    n_trials=3\n",
    ")\n",
    "\n",
    "# Comparar com uma configuração sub-ótima (temperatura padrão)\n",
    "default_config = {\n",
    "    'model_type': optimal_config['model_type'],\n",
    "    'temperature': 1.0,  # Temperatura padrão\n",
    "    'alpha': optimal_config['alpha']\n",
    "}\n",
    "\n",
    "print(f\"Avaliando configuração padrão: {default_config}...\")\n",
    "default_results = evaluate_specific_configuration(\n",
    "    dataset,\n",
    "    default_config['model_type'],\n",
    "    default_config['temperature'],\n",
    "    default_config['alpha'],\n",
    "    n_trials=3\n",
    ")\n",
    "\n",
    "# Exibir resultados comparativos\n",
    "print(\"\\n### Comparação de Configurações ###\")\n",
    "metrics_to_display = ['accuracy', 'auc_roc', 'kl_divergence', 'r2_score']\n",
    "\n",
    "comparison_data = []\n",
    "for metric in metrics_to_display:\n",
    "    if optimal_results and default_results:\n",
    "        opt_value = optimal_results.get(metric)\n",
    "        def_value = default_results.get(metric)\n",
    "        \n",
    "        if opt_value is not None and def_value is not None:\n",
    "            if metric in ['kl_divergence']:  # Métricas onde menor é melhor\n",
    "                improvement = ((def_value - opt_value) / def_value) * 100\n",
    "            else:  # Métricas onde maior é melhor\n",
    "                improvement = ((opt_value - def_value) / def_value) * 100\n",
    "                \n",
    "            comparison_data.append({\n",
    "                'Métrica': metric,\n",
    "                'Configuração Ótima': opt_value,\n",
    "                'Configuração Padrão': def_value,\n",
    "                'Melhoria (%)': improvement\n",
    "            })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(comparison_df)\n",
    "\n",
    "# Visualizar a comparação\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i, metric in enumerate(metrics_to_display):\n",
    "    row = comparison_df[comparison_df['Métrica'] == metric]\n",
    "    if not row.empty:\n",
    "        plt.subplot(2, 2, i+1)\n",
    "        \n",
    "        values = [row['Configuração Padrão'].values[0], row['Configuração Ótima'].values[0]]\n",
    "        plt.bar(['Padrão (T=1.0)', 'Ótima (T=2.0)'], values, color=['lightblue', 'darkblue'])\n",
    "        \n",
    "        plt.title(f\"{metric}\")\n",
    "        plt.ylabel(\"Valor\")\n",
    "        \n",
    "        # Adicionar melhoria percentual\n",
    "        improvement = row['Melhoria (%)'].values[0]\n",
    "        improvement_text = f\"+{improvement:.2f}%\" if improvement > 0 else f\"{improvement:.2f}%\"\n",
    "        color = 'green' if (improvement > 0 and metric != 'kl_divergence') or (improvement < 0 and metric == 'kl_divergence') else 'red'\n",
    "        \n",
    "        plt.text(1, values[1], improvement_text, ha='center', va='bottom', color=color, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, \"comparacao_configuracoes.png\"))\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "## 11. Visualização do Efeito da Temperatura nas Previsões Individuais\n",
    "\n",
    "Vamos analisar como a temperatura afeta a confiança do modelo em exemplos individuais:\n",
    "\n",
    "\n",
    "```python\n",
    "# Selecionar alguns exemplos do conjunto de teste para análise detalhada\n",
    "np.random.seed(42)\n",
    "sample_indices = np.random.choice(len(test_df), size=5, replace=False)\n",
    "sample_X = test_df.iloc[sample_indices].drop(['target', 'prob_class_0', 'prob_class_1'], axis=1).values\n",
    "sample_y = test_df.iloc[sample_indices]['target'].values\n",
    "sample_teacher_probs = test_prob_df.iloc[sample_indices]['prob_class_1'].values\n",
    "\n",
    "# Coletar previsões de modelos com diferentes temperaturas\n",
    "temperatures_to_analyze = [0.5, 1.0, 2.0, 5.0, 10.0]\n",
    "sample_predictions = {}\n",
    "\n",
    "for temp in temperatures_to_analyze:\n",
    "    # Configurar um distiller para esta temperatura\n",
    "    temp_distiller = AutoDistiller(\n",
    "        dataset=dataset,\n",
    "        output_dir=os.path.join(output_dir, f\"sample_analysis_temp_{temp}\"),\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    # Usar o mesmo tipo de modelo e alpha para isolar o efeito da temperatura\n",
    "    temp_distiller.customize_config(\n",
    "        model_types=[ModelType.GBM],\n",
    "        temperatures=[temp],\n",
    "        alphas=[0.5]\n",
    "    )\n",
    "    \n",
    "    # Executar treinamento\n",
    "    temp_results = temp_distiller.run(verbose_output=False)\n",
    "    \n",
    "    # Obter o modelo treinado\n",
    "    best_model = temp_distiller.find_best_model()\n",
    "    model = temp_distiller.get_trained_model(\n",
    "        model_type=best_model['model_type'],\n",
    "        temperature=temp,\n",
    "        alpha=best_model['alpha']\n",
    "    )\n",
    "    \n",
    "    # Gerar previsões para os exemplos selecionados\n",
    "    student_probs = model.predict_proba(sample_X)[:, 1]\n",
    "    \n",
    "    # Armazenar previsões\n",
    "    sample_predictions[temp] = student_probs\n",
    "\n",
    "# Visualizar o efeito da temperatura nas previsões individuais\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Configurar barras para cada exemplo\n",
    "x = np.arange(len(sample_indices))\n",
    "width = 0.15\n",
    "multipliers = [-2, -1, 0, 1, 2]\n",
    "\n",
    "# Plotar barras para cada temperatura\n",
    "for i, temp in enumerate(temperatures_to_analyze):\n",
    "    offset = width * multipliers[i]\n",
    "    plt.bar(x + offset, sample_predictions[temp], width, label=f'T = {temp}')\n",
    "\n",
    "# Adicionar barras do professor\n",
    "plt.bar(x + width * 3, sample_teacher_probs, width, color='black', label='Professor')\n",
    "\n",
    "# Adicionar rótulos\n",
    "plt.xlabel('Exemplos de Teste')\n",
    "plt.ylabel('Probabilidade Prevista (Classe Positiva)')\n",
    "plt.title('Efeito da Temperatura nas Previsões de Exemplos Individuais')\n",
    "plt.xticks(x, [f'Ex.{i+1} (y={y})' for i, y in enumerate(sample_y)])\n",
    "plt.legend()\n",
    "\n",
    "# Adicionar linha de referência em 0.5\n",
    "plt.axhline(y=0.5, color='red', linestyle='--', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, \"efeito_temperatura_exemplos_individuais.png\"))\n",
    "plt.show()\n",
    "\n",
    "# Analisar a consistência entre as previsões do professor e aluno\n",
    "consistency_data = []\n",
    "for temp in temperatures_to_analyze:\n",
    "    student_probs = sample_predictions[temp]\n",
    "    \n",
    "    # Calcular a diferença média absoluta\n",
    "    mean_abs_diff = np.mean(np.abs(student_probs - sample_teacher_probs))\n",
    "    \n",
    "    # Calcular se as previsões binárias são consistentes com o professor\n",
    "    student_preds = (student_probs >= 0.5).astype(int)\n",
    "    teacher_preds = (sample_teacher_probs >= 0.5).astype(int)\n",
    "    binary_agreement = np.mean(student_preds == teacher_preds) * 100\n",
    "    \n",
    "    # Armazenar resultados\n",
    "    consistency_data.append({\n",
    "        'Temperatura': temp,\n",
    "        'Diferença Média Absoluta': mean_abs_diff,\n",
    "        'Concordância Binária (%)': binary_agreement\n",
    "    })\n",
    "\n",
    "# Exibir resultados de consistência\n",
    "consistency_df = pd.DataFrame(consistency_data)\n",
    "print(\"\\n### Análise de Consistência com o Professor ###\")\n",
    "print(consistency_df)\n",
    "\n",
    "# Visualizar relação entre temperatura e consistência\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(consistency_df['Temperatura'], consistency_df['Diferença Média Absoluta'], 'o-', linewidth=2)\n",
    "plt.xlabel('Temperatura')\n",
    "plt.ylabel('Diferença Média Absoluta')\n",
    "plt.title('Diferença nas Probabilidades vs Temperatura')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(consistency_df['Temperatura'], consistency_df['Concordância Binária (%)'], 'o-', linewidth=2)\n",
    "plt.xlabel('Temperatura')\n",
    "plt.ylabel('Concordância Binária (%)')\n",
    "plt.title('Concordância nas Previsões vs Temperatura')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, \"temperatura_vs_consistencia.png\"))\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "## 12. Conclusões e Recomendações Finais\n",
    "\n",
    "Após uma análise abrangente do efeito da temperatura na destilação de conhecimento, podemos chegar às seguintes conclusões e recomendações:\n",
    "\n",
    "### Principais Conclusões\n",
    "\n",
    "1. **Efeito da Temperatura nas Distribuições**:\n",
    "   - Temperaturas mais altas (T > 1) suavizam as distribuições de probabilidade, revelando mais \"conhecimento escuro\" do modelo professor\n",
    "   - Temperaturas muito altas (T > 5) podem criar distribuições excessivamente uniformes, perdendo informações discriminativas importantes\n",
    "\n",
    "2. **Impacto na Performance do Modelo**:\n",
    "   - Para a maioria dos modelos, temperaturas entre 2.0 e 3.0 oferecem o melhor equilíbrio entre precisão e fidelidade de distribuição\n",
    "   - A temperatura ótima varia de acordo com o tipo de modelo e a métrica de interesse\n",
    "\n",
    "3. **Interação com o Parâmetro Alpha**:\n",
    "   - Alpha e temperatura funcionam em conjunto para controlar o equilíbrio entre aprender do professor e dos dados reais\n",
    "   - Temperaturas mais altas geralmente requerem valores de alpha mais baixos\n",
    "\n",
    "4. **Considerações por Tipo de Modelo**:\n",
    "   - Modelos mais simples (ex: Regressão Logística) se beneficiam mais de temperaturas mais altas\n",
    "   - Modelos mais complexos (ex: GBM) mostram melhor desempenho com temperaturas moderadas\n",
    "\n",
    "### Recomendações Práticas\n",
    "\n",
    "1. **Seleção de Temperatura**:\n",
    "   - **Para maximizar precisão geral**: Use temperaturas entre 2.0 e 3.0\n",
    "   - **Para melhor correspondência de distribuições**: Use temperaturas entre 1.0 e 2.0\n",
    "   - **Para modelos simples**: Considere temperaturas mais altas (3.0-5.0)\n",
    "   - **Para modelos complexos**: Temperaturas moderadas (1.5-3.0) são geralmente suficientes\n",
    "\n",
    "2. **Escolha de Alpha com Base na Temperatura**:\n",
    "   - Com T > 3.0: Use alpha entre 0.3-0.5\n",
    "   - Com T = 1.0-3.0: Use alpha entre 0.5-0.7\n",
    "   - Com T < 1.0: Use alpha entre 0.7-0.9\n",
    "\n",
    "3. **Processo Recomendado para Encontrar a Temperatura Ideal**:\n",
    "   1. Comece com um grid de temperaturas (ex: 0.5, 1.0, 2.0, 5.0, 10.0)\n",
    "   2. Avalie o desempenho em múltiplas métricas (acurácia, AUC-ROC, KL divergência, R²)\n",
    "   3. Refine a busca em torno das temperaturas mais promissoras\n",
    "   4. Para aplicações de produção, realize validação cruzada com as melhores configurações\n",
    "\n",
    "4. **Considerações Adicionais**:\n",
    "   - Monitore tanto métricas de precisão quanto métricas de correspondência de distribuição\n",
    "   - Para conjuntos de dados desbalanceados, temperaturas mais altas podem ser benéficas\n",
    "   - Para classes muito similares, temperaturas mais altas ajudam a capturar nuances\n",
    "\n",
    "### Conclusão Final\n",
    "\n",
    "A temperatura é um hiperparâmetro crucial na destilação de conhecimento que afeta diretamente a qualidade do modelo destilado. Ao invés de usar o valor padrão (T=1.0), experimentar com diferentes temperaturas pode levar a ganhos significativos de performance. Os experimentos neste notebook demonstraram que a escolha cuidadosa da temperatura pode resultar em modelos destilados que não apenas são mais precisos, mas também preservam melhor as nuances do modelo professor.\n",
    "\n",
    "Esta análise fornece diretrizes gerais, mas o valor ideal da temperatura pode variar de acordo com o problema específico, o conjunto de dados e os objetivos da destilação. Portanto, recomenda-se sempre testar múltiplos valores de temperatura adaptados ao contexto específico da aplicação.\n",
    "\n",
    "## Referências Bibliográficas\n",
    "\n",
    "1. Hinton, G., Vinyals, O., & Dean, J. (2015). Distilling the knowledge in a neural network. arXiv preprint arXiv:1503.02531.\n",
    "\n",
    "2. Mirzadeh, S. I., Farajtabar, M., Li, A., Levine, N., Matsukawa, A., & Ghasemzadeh, H. (2020). Improved knowledge distillation via teacher assistant. Proceedings of the AAAI conference on artificial intelligence, 34(4), 5191-5198.\n",
    "\n",
    "3. Jafari, A., Ghodsi, A., Jolfaei, A., & Gatsis, K. (2021). Investigating the Effect of Temperature in Knowledge Distillation. arXiv preprint arXiv:2106.13948.\n",
    "\n",
    "4. Cho, J. H., & Hariharan, B. (2019). On the efficacy of knowledge distillation. In Proceedings of the IEEE/CVF International Conference on Computer Vision (pp. 4794-4802)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
