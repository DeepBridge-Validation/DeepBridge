{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the Experiment Class in DeepBridge\n",
    "\n",
    "This notebook explains the purpose and functionality of the `Experiment` class in the DeepBridge library, which is a key component for managing and executing model validation and distillation tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction to the Experiment Class\n",
    "\n",
    "The `Experiment` class in DeepBridge serves as a container for experiments related to model validation and distillation. It encapsulates the entire workflow of preparing data, running experiments, and evaluating results.\n",
    "\n",
    "Let's first import the necessary modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guhaase/projetos/deepbridge_homol/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "sys.path.append(os.path.expanduser(\"~/projetos/DeepBridge\"))\n",
    "\n",
    "# Importações atualizadas para a nova estrutura\n",
    "from deepbridge.core.db_data import DBDataset\n",
    "from deepbridge.core.experiment import Experiment\n",
    "from deepbridge.utils.model_registry import ModelType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating a Basic Experiment\n",
    "\n",
    "To demonstrate the Experiment class, let's first generate some synthetic data and a teacher model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a synthetic classification dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=10, \n",
    "                           n_classes=2, random_state=42)\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "X_df = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(X.shape[1])])\n",
    "y_df = pd.Series(y, name='target')\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a \"teacher\" model (e.g., a complex RandomForest)\n",
    "teacher_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "teacher_model.fit(X_train, y_train)\n",
    "\n",
    "# Generate probability predictions from the teacher model\n",
    "train_probs = teacher_model.predict_proba(X_train)\n",
    "test_probs = teacher_model.predict_proba(X_test)\n",
    "\n",
    "# Create DataFrame with probabilities\n",
    "train_probs_df = pd.DataFrame(train_probs, columns=['prob_class_0', 'prob_class_1'], index=X_train.index)\n",
    "test_probs_df = pd.DataFrame(test_probs, columns=['prob_class_0', 'prob_class_1'], index=X_test.index)\n",
    "\n",
    "# Create a DBDataset instance\n",
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "test_data = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "dataset = DBDataset(\n",
    "    train_data=train_data,\n",
    "    test_data=test_data,\n",
    "    target_column='target',\n",
    "    features=X_df.columns.tolist(),\n",
    "    train_predictions=train_probs_df,\n",
    "    test_predictions=test_probs_df,\n",
    "    prob_cols=['prob_class_0', 'prob_class_1']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our dataset prepared, we can create an Experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluating distillation model on train dataset ===\n",
      "Student predictions shape: (800, 2)\n",
      "First 3 student probabilities: [[3.20679257e-04 9.99679321e-01]\n",
      " [9.99951268e-01 4.87318541e-05]\n",
      " [9.99710938e-01 2.89061720e-04]]\n",
      "Teacher probabilities type: <class 'pandas.core.frame.DataFrame'>\n",
      "Using 'prob_class_1' column from teacher probabilities\n",
      "Teacher probabilities shape: (800, 2)\n",
      "First 3 teacher probabilities (positive class): [0.71 0.   0.08]\n",
      "KS Statistic calculation: 0.47, p-value: 3.1408946187192175e-80\n",
      "R² Score calculation: 0.8846692436908336\n",
      "Teacher prob type: <class 'numpy.ndarray'>, shape: (800,)\n",
      "Student prob type: <class 'numpy.ndarray'>, shape: (800,)\n",
      "Teacher prob first 5 values: [0.71 0.   0.08 0.88 0.39]\n",
      "Student prob first 5 values: [9.99679321e-01 4.87318541e-05 2.89061720e-04 9.99927453e-01\n",
      " 6.18127369e-04]\n",
      "KS calculation successful: (0.47, 3.1408946187192175e-80)\n",
      "Sorted teacher dist - min: 0.0, max: 1.0, length: 800\n",
      "Sorted student dist - min: 2.8611958523003585e-05, max: 0.9999662378411595, length: 800\n",
      "R² calculation result: 0.8846692436908336\n",
      "R² calculation successful: 0.8846692436908336\n",
      "Evaluation metrics: {'accuracy': 0.97625, 'precision': 0.9655172413793104, 'recall': 0.9874055415617129, 'f1_score': 0.9763387297633873, 'auc_roc': 0.9964810520591784, 'auc_pr': 0.9950938354800609, 'log_loss': 0.11264260878532095, 'kl_divergence': 0.6581820973227428, 'ks_statistic': 0.47, 'ks_pvalue': 3.1408946187192175e-80, 'r2_score': 0.8846692436908336, 'distillation_method': 'SurrogateModel'}\n",
      "=== Evaluation complete ===\n",
      "\n",
      "\n",
      "=== Evaluating distillation model on test dataset ===\n",
      "Student predictions shape: (200, 2)\n",
      "First 3 student probabilities: [[9.99749716e-01 2.50284358e-04]\n",
      " [1.78102985e-04 9.99821897e-01]\n",
      " [8.62804031e-02 9.13719597e-01]]\n",
      "Teacher probabilities type: <class 'pandas.core.frame.DataFrame'>\n",
      "Using 'prob_class_1' column from teacher probabilities\n",
      "Teacher probabilities shape: (200, 2)\n",
      "First 3 teacher probabilities (positive class): [0.92 0.94 0.92]\n",
      "KS Statistic calculation: 0.46, p-value: 1.8323127534838935e-19\n",
      "R² Score calculation: 0.8975702803391267\n",
      "Teacher prob type: <class 'numpy.ndarray'>, shape: (200,)\n",
      "Student prob type: <class 'numpy.ndarray'>, shape: (200,)\n",
      "Teacher prob first 5 values: [0.92 0.94 0.92 0.77 0.02]\n",
      "Student prob first 5 values: [2.50284358e-04 9.99821897e-01 9.13719597e-01 9.77039272e-01\n",
      " 4.38807656e-05]\n",
      "KS calculation successful: (0.46, 1.8323127534838935e-19)\n",
      "Sorted teacher dist - min: 0.0, max: 1.0, length: 200\n",
      "Sorted student dist - min: 2.846419174500984e-07, max: 0.9999919390814311, length: 200\n",
      "R² calculation result: 0.8975702803391267\n",
      "R² calculation successful: 0.8975702803391267\n",
      "Evaluation metrics: {'accuracy': 0.85, 'precision': 0.8135593220338984, 'recall': 0.9230769230769231, 'f1_score': 0.8648648648648649, 'auc_roc': 0.945713141025641, 'auc_pr': 0.9384151864215601, 'log_loss': 0.5436413500322007, 'kl_divergence': 0.6192884480731168, 'ks_statistic': 0.46, 'ks_pvalue': 1.8323127534838935e-19, 'r2_score': 0.8975702803391267, 'distillation_method': 'SurrogateModel'}\n",
      "=== Evaluation complete ===\n",
      "\n",
      "Experiment type: binary_classification\n",
      "Training data shape: (800, 20)\n",
      "Test data shape: (200, 20)\n",
      "Training labels shape: (800,)\n",
      "Test labels shape: (200,)\n",
      "Training probability predictions shape: (800, 2)\n",
      "Test probability predictions shape: (200, 2)\n"
     ]
    }
   ],
   "source": [
    "# Create an experiment\n",
    "experiment = Experiment(\n",
    "    dataset=dataset,\n",
    "    experiment_type=\"binary_classification\"\n",
    ")\n",
    "\n",
    "# Let's verify our experiment has been initialized correctly\n",
    "print(f\"Experiment type: {experiment.experiment_type}\")\n",
    "print(f\"Training data shape: {experiment.X_train.shape}\")\n",
    "print(f\"Test data shape: {experiment.X_test.shape}\")\n",
    "print(f\"Training labels shape: {experiment.y_train.shape}\")\n",
    "print(f\"Test labels shape: {experiment.y_test.shape}\")\n",
    "print(f\"Training probability predictions shape: {experiment.prob_train.shape}\")\n",
    "print(f\"Test probability predictions shape: {experiment.prob_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<deepbridge.distillation.techniques.surrogate.SurrogateModel at 0x7fced5ddd580>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1763773627.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[4], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    =\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepbridge_homol",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
