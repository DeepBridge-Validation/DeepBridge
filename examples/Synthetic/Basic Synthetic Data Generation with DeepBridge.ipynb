{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Synthetic Data Generation with DeepBridge\n",
    "\n",
    "This tutorial demonstrates how to generate synthetic data using the DeepBridge library. I'll walk you through creating synthetic datasets with different methods and comparing their results.\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this demonstration, we'll:\n",
    "1. Create a sample dataset with mixed data types\n",
    "2. Generate synthetic versions using three different methods:\n",
    "   - Gaussian Copula\n",
    "   - CTGAN (Conditional Tabular GAN)\n",
    "   - UltraLight Generator\n",
    "3. Evaluate and compare the quality of each method\n",
    "4. Visualize the differences between original and synthetic data\n",
    "\n",
    "## Understanding the Different Methods\n",
    "\n",
    "Each synthetic data generation method has its unique characteristics:\n",
    "\n",
    "### Gaussian Copula\n",
    "- Statistical method that preserves the marginal distributions and correlations between features\n",
    "- Good balance between quality and computational efficiency\n",
    "- Works well for numerical data with linear relationships\n",
    "- Medium memory requirements\n",
    "\n",
    "### CTGAN (Conditional Tabular GAN)\n",
    "- Neural network-based approach using Generative Adversarial Networks\n",
    "- Can capture complex, non-linear relationships in the data\n",
    "- Highest quality for capturing complex patterns\n",
    "- More computationally intensive and requires more memory\n",
    "- Longer training time\n",
    "\n",
    "### UltraLight Generator\n",
    "- Simplest and fastest approach with minimal memory requirements\n",
    "- Uses basic statistical modeling rather than complex ML models\n",
    "- Excellent for large datasets or limited computational resources\n",
    "- Quality may be lower for complex relationships\n",
    "\n",
    "## Example Implementation\n",
    "\n",
    "Let's look at the code to implement these methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guhaase/projetos/deepbridge_homol/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando e preparando dados...\n",
      "Valores NaN em X antes da limpeza: 0\n",
      "Valores infinitos em X: 0\n",
      "NaN em train_df: 0\n",
      "NaN em test_df: 0\n",
      "\n",
      "Treinando modelo...\n",
      "\n",
      "Criando objeto de dataset...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.expanduser(\"~/projetos/DeepBridge\"))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from deepbridge.core.db_data import DBDataset\n",
    "from deepbridge.synthetic import Synthesize\n",
    "from deepbridge.core.experiment import Experiment\n",
    "\n",
    "\n",
    "from deepbridge.validation.wrappers import (\n",
    "    RobustnessSuite, UncertaintySuite, \n",
    ")\n",
    "\n",
    "from deepbridge.utils.robustness import run_robustness_tests\n",
    "from deepbridge.utils.uncertainty import run_uncertainty_tests\n",
    "from deepbridge.utils.resilience import run_resilience_tests\n",
    "from deepbridge.utils.hyperparameter import run_hyperparameter_tests\n",
    "#---------------------------------------------------------\n",
    "# Preparação de dados com cuidado especial \n",
    "#---------------------------------------------------------\n",
    "print(\"Carregando e preparando dados...\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Gerar dados sintéticos com duas classes\n",
    "X, y = make_classification(n_samples=10000, n_features=20, n_classes=2, random_state=42)\n",
    "X = pd.DataFrame(X, columns=[f\"feature_{i}\" for i in range(20)])\n",
    "y = pd.Series(y)\n",
    "\n",
    "# Verificar e lidar com valores ausentes\n",
    "print(f\"Valores NaN em X antes da limpeza: {X.isna().sum().sum()}\")\n",
    "print(f\"Valores infinitos em X: {np.isinf(X.values).sum()}\")\n",
    "\n",
    "# Resetar índices para garantir alinhamento limpo\n",
    "X = X.reset_index(drop=True)\n",
    "y = y.reset_index(drop=True)\n",
    "\n",
    "# Dividir dados\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Resetar índices novamente após a divisão\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "# Criar DataFrames de treino e teste com nomes explícitos de colunas\n",
    "train_df = X_train.copy()\n",
    "train_df['target'] = y_train\n",
    "test_df = X_test.copy()\n",
    "test_df['target'] = y_test\n",
    "\n",
    "# Verificação final\n",
    "print(f\"NaN em train_df: {train_df.isna().sum().sum()}\")\n",
    "print(f\"NaN em test_df: {test_df.isna().sum().sum()}\")\n",
    "\n",
    "# Treinar modelo\n",
    "print(\"\\nTreinando modelo...\")\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Criar objeto de dataset\n",
    "print(\"\\nCriando objeto de dataset...\")\n",
    "dataset = DBDataset(\n",
    "    train_data=train_df,\n",
    "    test_data=test_df,\n",
    "    target_column='target',\n",
    "    model=model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DBDataset(with 10000 samples (not split))\n",
       "Features: 20 total (0 categorical, 20 numerical)\n",
       "Target: 'target'\n",
       "Model: loaded\n",
       "Predictions: available"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Initialize the Experiment class\n",
    "experiment = Experiment(\n",
    "    dataset=dataset,\n",
    "    experiment_type=\"binary_classification\", \n",
    "    tests=['robustness', 'uncertainty', 'resilience']\n",
    ")\n",
    "\n",
    "results = experiment.run_tests(\"quick\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['resilience']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Run robustness tests\n",
    "print(\"\\nRunning quick robustness tests...\")\n",
    "quick_results = run_robustness_tests(dataset, config_name=\"quick\", verbose=False)\n",
    "    \n",
    "print(\"\\nRunning full robustness tests...\")\n",
    "full_results = run_robustness_tests(dataset, config_name=\"full\", verbose=False)\n",
    "\n",
    "\n",
    "    # Run robustness tests\n",
    "print(\"\\nRunning quick robustness tests...\")\n",
    "quick_results = run_uncertainty_tests(dataset, config_name=\"quick\", verbose=False)\n",
    "    \n",
    "print(\"\\nRunning full robustness tests...\")\n",
    "full_results = run_uncertainty_tests(dataset, config_name=\"full\", verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertainty = UncertaintySuite(dataset, verbose=True)\n",
    "uncertainty.config('quick')\n",
    "results = uncertainty.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robustness_results = experiment.get_robustness_results()\n",
    "# Verifica se os resultados existem\n",
    "print(\"Visualizações disGuponíveis:\", list(experiment.get_robustness_visualizations().keys()))\n",
    "# Agora tente mostrar o gráfico\n",
    "comparison_plot = experiment.plot_robustness_comparison()\n",
    "if comparison_plot:\n",
    "    comparison_plot.show()\n",
    "else:\n",
    "    print(\"Visualização ainda não disponível\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.alternative_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Initialize the Experiment class\n",
    "experiment = Experiment(\n",
    "    dataset=dataset,\n",
    "    experiment_type=\"binary_classification\", \n",
    "    auto_fit=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comprehensive_results = experiment.get_comprehensive_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comprehensive_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obter e avaliar os modelos alternativos\n",
    "alternative_models = experiment.get_alternative_models()\n",
    "print(f\"Número de modelos alternativos criados: {len(alternative_models)}\")\n",
    "\n",
    "# Ver quais modelos foram criados\n",
    "for name, model in alternative_models.items():\n",
    "    print(f\"- {name}: {type(model).__name__}\")\n",
    "\n",
    "# Comparar o desempenho dos modelos\n",
    "comparison_results = experiment.evaluate_alternative_models(dataset='test')\n",
    "print(\"\\nComparação de desempenho dos modelos no conjunto de teste:\")\n",
    "print(comparison_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alternative_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(experiment.distillation_model.__class__.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import matplotlib as plt\n",
    "\n",
    "# Filtrar os avisos relacionados a feature names\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, \n",
    "                       message=\"X does not have valid feature names\")\n",
    "\n",
    "# # Criar suite de robustez e configurar\n",
    "# print(\"\\nExecutando testes de robustez...\")\n",
    "# suite = RobustnessSuite(dataset, verbose=True)\n",
    "\n",
    "# # Método 1: Configurar e executar\n",
    "# results_quick = suite.config('quick').run()\n",
    "# print(f\"Pontuação de robustez (quick): {results_quick['robustness_scores']['overall_score']:.3f}\")\n",
    "\n",
    "# # Método 2: Configurar para teste completo\n",
    "# results_full = suite.config('full').run()\n",
    "# print(f\"Pontuação de robustez (full): {results_full['robustness_scores']['overall_score']:.3f}\")\n",
    "\n",
    "# # Usuários avançados ainda podem personalizar completamente os testes\n",
    "# custom_config = {\n",
    "#     'feature_perturbation': [\n",
    "#         {'type': 'noise', 'params': {'feature_name': 'mean radius', 'level': 0.3}}\n",
    "#     ],\n",
    "#     'outlier_robustness': [\n",
    "#         {'type': 'isolation_forest', 'params': {'contamination': 0.15}}\n",
    "#     ]\n",
    "# }\n",
    "\n",
    "# # Executar com configuração personalizada\n",
    "# results_custom = suite.run_custom_test(custom_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepbridge.validation.wrappers.robustness_suite import RobustnessSuite\n",
    "\n",
    "# Inicializar com um conjunto de dados\n",
    "suite = RobustnessSuite(dataset, verbose=True)\n",
    "\n",
    "# Usar configuração 'full' padrão\n",
    "results_full = suite.config('full').run()\n",
    "\n",
    "# Salvar relatório HTML\n",
    "suite.save_report(\"robustness_report_full.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suite = RobustnessSuite(dataset, verbose=True)\n",
    "results_full = suite.config('full').run()\n",
    "\n",
    "\n",
    "\n",
    "suite.save_report(\"report_quick.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_full\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suite.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "suite.save_report(\"report1.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suite.config('quick')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acessar resultados organizados\n",
    "robustness_results = results_full['results']\n",
    "\n",
    "# Acessar visualizações\n",
    "visualizations = robustness_results['visualizations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.genmod.families import Binomial\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Configurar semente para reprodutibilidade\n",
    "np.random.seed(42)\n",
    "\n",
    "# Gerar dados sintéticos para classificação\n",
    "def gerar_dados_classificacao(n_amostras=1000, n_features=2):\n",
    "    \"\"\"\n",
    "    Gera conjunto de dados sintéticos para classificação binária.\n",
    "    \"\"\"\n",
    "    # Gerar features com alguma correlação\n",
    "    covariancia = np.array([[1.0, 0.5], [0.5, 1.0]])\n",
    "    X = np.random.multivariate_normal(mean=[0, 0], cov=covariancia, size=n_amostras)\n",
    "    \n",
    "    # Adicionar mais features independentes se necessário\n",
    "    if n_features > 2:\n",
    "        X_extra = np.random.normal(size=(n_amostras, n_features-2))\n",
    "        X = np.hstack((X, X_extra))\n",
    "    \n",
    "    # Gerar coeficientes reais\n",
    "    beta = np.random.uniform(-1, 1, size=n_features)\n",
    "    intercept = 0.5\n",
    "    \n",
    "    # Calcular log-odds\n",
    "    log_odds = intercept + np.dot(X, beta)\n",
    "    \n",
    "    # Transformar em probabilidades\n",
    "    p = 1 / (1 + np.exp(-log_odds))\n",
    "    \n",
    "    # Gerar rótulos binários\n",
    "    y = np.random.binomial(1, p)\n",
    "    \n",
    "    return X, y, np.append(intercept, beta)\n",
    "\n",
    "# Gerar dados\n",
    "X, y, coef_verdadeiros = gerar_dados_classificacao(n_amostras=1000, n_features=3)\n",
    "\n",
    "# Dividir em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Padronizar os dados para o modelo sklearn\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# ======================================================\n",
    "# 1. MODELO GLM USANDO STATSMODELS\n",
    "# ======================================================\n",
    "print(\"=\"*50)\n",
    "print(\"1. MODELO GLM PARA CLASSIFICAÇÃO (STATSMODELS)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Adicionar constante para o intercepto\n",
    "X_train_sm = sm.add_constant(X_train)\n",
    "X_test_sm = sm.add_constant(X_test)\n",
    "\n",
    "# Ajustar GLM com família binomial e função de ligação logit\n",
    "glm_model = sm.GLM(y_train, X_train_sm, family=Binomial())\n",
    "glm_results = glm_model.fit()\n",
    "\n",
    "# Resumo do modelo\n",
    "print(glm_results.summary())\n",
    "\n",
    "# Fazer previsões (probabilidades)\n",
    "y_pred_proba_glm = glm_results.predict(X_test_sm)\n",
    "\n",
    "# Converter probabilidades para classes (0 ou 1)\n",
    "y_pred_glm = (y_pred_proba_glm >= 0.5).astype(int)\n",
    "\n",
    "# Avaliar o modelo GLM\n",
    "accuracy_glm = accuracy_score(y_test, y_pred_glm)\n",
    "print(f\"\\nAcurácia do modelo GLM: {accuracy_glm:.4f}\")\n",
    "\n",
    "# Matriz de confusão\n",
    "conf_matrix_glm = confusion_matrix(y_test, y_pred_glm)\n",
    "print(\"\\nMatriz de Confusão (GLM):\")\n",
    "print(conf_matrix_glm)\n",
    "\n",
    "# Relatório de classificação\n",
    "print(\"\\nRelatório de Classificação (GLM):\")\n",
    "print(classification_report(y_test, y_pred_glm))\n",
    "\n",
    "# ======================================================\n",
    "# 2. REGRESSÃO LOGÍSTICA USANDO SCIKIT-LEARN\n",
    "# ======================================================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"2. REGRESSÃO LOGÍSTICA (SCIKIT-LEARN)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Ajustar modelo de regressão logística\n",
    "logreg_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "logreg_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Fazer previsões (probabilidades)\n",
    "y_pred_proba_logreg = logreg_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Converter probabilidades para classes (0 ou 1)\n",
    "y_pred_logreg = (y_pred_proba_logreg >= 0.5).astype(int)\n",
    "\n",
    "# Avaliar o modelo de regressão logística\n",
    "accuracy_logreg = accuracy_score(y_test, y_pred_logreg)\n",
    "print(f\"\\nAcurácia da Regressão Logística: {accuracy_logreg:.4f}\")\n",
    "\n",
    "# Matriz de confusão\n",
    "conf_matrix_logreg = confusion_matrix(y_test, y_pred_logreg)\n",
    "print(\"\\nMatriz de Confusão (Regressão Logística):\")\n",
    "print(conf_matrix_logreg)\n",
    "\n",
    "# Relatório de classificação\n",
    "print(\"\\nRelatório de Classificação (Regressão Logística):\")\n",
    "print(classification_report(y_test, y_pred_logreg))\n",
    "\n",
    "# ======================================================\n",
    "# 3. COMPARAÇÃO DOS MODELOS\n",
    "# ======================================================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"3. COMPARAÇÃO DOS MODELOS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Comparar coeficientes\n",
    "print(\"\\nCoeficientes verdadeiros:\", coef_verdadeiros)\n",
    "print(\"Coeficientes GLM:\", glm_results.params)\n",
    "print(\"Coeficientes Regressão Logística:\", \n",
    "      np.append(logreg_model.intercept_[0], logreg_model.coef_[0]))\n",
    "\n",
    "# Calcular o ROC AUC para ambos os modelos\n",
    "fpr_glm, tpr_glm, _ = roc_curve(y_test, y_pred_proba_glm)\n",
    "roc_auc_glm = auc(fpr_glm, tpr_glm)\n",
    "\n",
    "fpr_logreg, tpr_logreg, _ = roc_curve(y_test, y_pred_proba_logreg)\n",
    "roc_auc_logreg = auc(fpr_logreg, tpr_logreg)\n",
    "\n",
    "print(f\"\\nROC AUC (GLM): {roc_auc_glm:.4f}\")\n",
    "print(f\"ROC AUC (Regressão Logística): {roc_auc_logreg:.4f}\")\n",
    "\n",
    "# ======================================================\n",
    "# 4. VISUALIZAÇÃO\n",
    "# ======================================================\n",
    "\n",
    "# Plotar curvas ROC\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(fpr_glm, tpr_glm, 'b-', linewidth=2, label=f'GLM (AUC = {roc_auc_glm:.3f})')\n",
    "plt.plot(fpr_logreg, tpr_logreg, 'r--', linewidth=2, label=f'Regressão Logística (AUC = {roc_auc_logreg:.3f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=1)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Taxa de Falso Positivo')\n",
    "plt.ylabel('Taxa de Verdadeiro Positivo')\n",
    "plt.title('Curva ROC - Comparação dos Modelos')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('comparacao_roc_curve.png')\n",
    "\n",
    "# Visualizar as probabilidades preditas\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(y_pred_proba_glm, y_pred_proba_logreg, alpha=0.5)\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=1)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('Probabilidades GLM')\n",
    "plt.ylabel('Probabilidades Regressão Logística')\n",
    "plt.title('Comparação das Probabilidades Preditas pelos Modelos')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('comparacao_probabilidades.png')\n",
    "\n",
    "# Exemplo de aplicação: Fazer previsão para uma nova observação\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"5. EXEMPLO DE APLICAÇÃO\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Criar exemplo de nova observação\n",
    "nova_obs = np.array([[0.5, -0.3, 0.8]])\n",
    "nova_obs_scaled = scaler.transform(nova_obs)\n",
    "\n",
    "# Adicionar constante para o GLM\n",
    "nova_obs_sm = sm.add_constant(nova_obs)\n",
    "\n",
    "# Fazer previsões\n",
    "prob_glm = glm_results.predict(nova_obs_sm)[0]\n",
    "prob_logreg = logreg_model.predict_proba(nova_obs_scaled)[0, 1]\n",
    "\n",
    "print(f\"\\nNova observação: {nova_obs[0]}\")\n",
    "print(f\"Probabilidade predita pelo GLM: {prob_glm:.4f}\")\n",
    "print(f\"Probabilidade predita pela Regressão Logística: {prob_logreg:.4f}\")\n",
    "print(f\"Classe predita pelo GLM: {1 if prob_glm >= 0.5 else 0}\")\n",
    "print(f\"Classe predita pela Regressão Logística: {1 if prob_logreg >= 0.5 else 0}\")\n",
    "\n",
    "# ======================================================\n",
    "# FUNÇÕES PARA USO PRÁTICO DOS MODELOS\n",
    "# ======================================================\n",
    "\n",
    "def prever_probabilidade_glm(modelo, nova_obs, adicionar_constante=True):\n",
    "    \"\"\"\n",
    "    Faz previsão de probabilidade usando o modelo GLM.\n",
    "    \n",
    "    Args:\n",
    "        modelo: Modelo GLM treinado\n",
    "        nova_obs: Array numpy com features da nova observação\n",
    "        adicionar_constante: Se True, adiciona coluna de 1's para o intercepto\n",
    "        \n",
    "    Returns:\n",
    "        Probabilidade de pertencer à classe positiva\n",
    "    \"\"\"\n",
    "    if adicionar_constante:\n",
    "        nova_obs = sm.add_constant(nova_obs)\n",
    "    return modelo.predict(nova_obs)\n",
    "\n",
    "def prever_probabilidade_logreg(modelo, nova_obs, scaler=None):\n",
    "    \"\"\"\n",
    "    Faz previsão de probabilidade usando o modelo de Regressão Logística.\n",
    "    \n",
    "    Args:\n",
    "        modelo: Modelo de regressão logística treinado\n",
    "        nova_obs: Array numpy com features da nova observação\n",
    "        scaler: Scaler usado para padronizar os dados, se aplicável\n",
    "        \n",
    "    Returns:\n",
    "        Probabilidade de pertencer à classe positiva\n",
    "    \"\"\"\n",
    "    if scaler is not None:\n",
    "        nova_obs = scaler.transform(nova_obs)\n",
    "    return modelo.predict_proba(nova_obs)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifique primeiro se a visualização existe\n",
    "if 'feature_importance' in visualizations:\n",
    "    with open('feature_importance.html', 'w') as f:\n",
    "        f.write(visualizations['feature_importance'])\n",
    "else:\n",
    "    print(\"Visualização 'feature_importance' não disponível.\")\n",
    "\n",
    "    \n",
    "# Exemplo: Exibir uma visualização específica em um notebook\n",
    "from IPython.display import HTML\n",
    "HTML(visualizations['robustness_summary'])\n",
    "\n",
    "# Exemplo: Salvar uma visualização em um arquivo HTML\n",
    "with open('feature_importance.html', 'w') as f:\n",
    "    f.write(visualizations['feature_importance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_df = Synthesize(\n",
    "    dataset=dataset,\n",
    "    method='gaussian',\n",
    "    num_samples=1000,  \n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepbridge.synthetic.metrics.similarity import calculate_similarity\n",
    "\n",
    "# Acesse os dados originais e os dados sintéticos\n",
    "original_data = synthetic_df.original_data\n",
    "synthetic_data = synthetic_df.data\n",
    "\n",
    "# Calcule a similaridade\n",
    "similarity_scores = calculate_similarity(\n",
    "    original_data=original_data,\n",
    "    synthetic_data=synthetic_data,\n",
    "    # Parâmetros opcionais:\n",
    "    metric='euclidean',         # Métrica de distância a ser usada\n",
    "    n_neighbors=5,              # Número de vizinhos a considerar\n",
    "    sample_size=10000,          # Tamanho máximo da amostra a usar\n",
    "    random_state=42,            # Seed para reprodutibilidade\n",
    "    verbose=True                # Mostrar informações de progresso\n",
    ")\n",
    "\n",
    "# similarity_scores é um pandas.Series com um score para cada amostra sintética\n",
    "# Valores mais próximos de 1 indicam maior similaridade (mais parecidos)\n",
    "# Valores mais próximos de 0 indicam menor similaridade (mais diferentes)\n",
    "\n",
    "# Estatísticas de similaridade\n",
    "print(f\"Similaridade média: {similarity_scores.mean():.4f}\")\n",
    "print(f\"Similaridade mínima: {similarity_scores.min():.4f}\")\n",
    "print(f\"Similaridade máxima: {similarity_scores.max():.4f}\")\n",
    "\n",
    "# Você também pode visualizar a distribuição dos scores\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(similarity_scores, bins=50)\n",
    "plt.title('Distribuição dos Scores de Similaridade')\n",
    "plt.xlabel('Score de Similaridade')\n",
    "plt.ylabel('Frequência')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepbridge.synthetic.metrics.similarity import filter_by_similarity\n",
    "\n",
    "# Filtra dados com similaridade acima de um limiar\n",
    "filtered_data = filter_by_similarity(\n",
    "    original_data=original_data,\n",
    "    synthetic_data=synthetic_data,\n",
    "    threshold=0.9,              # Remove samples com similaridade >= 0.9\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"Amostras originais: {len(synthetic_data)}\")\n",
    "print(f\"Amostras após filtragem: {len(filtered_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliação da diversidade dos dados sintéticos\n",
    "from deepbridge.synthetic.metrics.similarity import calculate_diversity\n",
    "\n",
    "diversity_metrics = calculate_diversity(\n",
    "    synthetic_data=synthetic_df.data,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Avaliação das diferenças de correlação entre variáveis numéricas\n",
    "from deepbridge.synthetic.metrics.similarity import evaluate_pairwise_correlations\n",
    "\n",
    "correlation_analysis = evaluate_pairwise_correlations(\n",
    "    original_data=original_data,\n",
    "    synthetic_data=synthetic_data\n",
    ")\n",
    "\n",
    "# Mostrar pares de colunas com maiores diferenças de correlação\n",
    "print(correlation_analysis.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from deepbridge.synthetic.metrics.similarity import plot_distribution_comparison\n",
    "    \n",
    "    fig = plot_distribution_comparison(\n",
    "        original_data=original_data,\n",
    "        synthetic_data=synthetic_data\n",
    "    )\n",
    "    plt.show()\n",
    "except ImportError:\n",
    "    print(\"Módulo de visualização não disponível\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando um relatório HTML\n",
    "report_path = synthetic_df.save_report(\"relatorio_dados_sinteticos.html\")\n",
    "print(f\"Relatório gerado e salvo em: {report_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = synthetic_df.data.drop('target', axis=1)\n",
    "y = synthetic_df.data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 6. Avaliação do modelo\n",
    "# accuracy = accuracy_score(y, y_pred)\n",
    "# report = classification_report(y, y_pred)\n",
    "\n",
    "# print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "import sys # Para sair em caso de erro crítico\n",
    "\n",
    "# --- 1. Configurações ---\n",
    "DB_HOST = '127.0.0.1'\n",
    "DB_PORT = 3306 # Porta geralmente é um inteiro\n",
    "DB_USER = 'root'\n",
    "DB_PASSWORD = 'rootpass'\n",
    "DB_NAME = 'gevao'\n",
    "CSV_FILE_PATH = '/home/guhaase/projetos/DeepBridge/examples/Synthetic/EST_MOD_ANA_MON.csv'\n",
    "TABLE_NAME = 'EST_MOD_ANA_MON' # Nome da tabela no MySQL\n",
    "\n",
    "# --- 2. Montar a String de Conexão SQLAlchemy ---\n",
    "# Formato: mysql+mysqlconnector://user:password@host:port/database\n",
    "try:\n",
    "    db_connection_str = f'mysql+mysqlconnector://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}'\n",
    "    print(f\"String de conexão (sem senha): mysql+mysqlconnector://{DB_USER}:***@{DB_HOST}:{DB_PORT}/{DB_NAME}\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao formatar a string de conexão: {e}\")\n",
    "    sys.exit(1) # Sai do script se não conseguir nem formatar a string\n",
    "\n",
    "# --- 3. Criar o Engine de Conexão ---\n",
    "engine = None # Inicializa engine como None\n",
    "try:\n",
    "    engine = create_engine(db_connection_str)\n",
    "    # Tenta conectar para verificar as credenciais e a disponibilidade do DB\n",
    "    with engine.connect() as connection:\n",
    "        print(f\"Conexão com o banco de dados '{DB_NAME}' estabelecida com sucesso!\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao conectar ao banco de dados MySQL: {e}\")\n",
    "    print(\"Verifique se o servidor MySQL está rodando, as credenciais estão corretas e o banco de dados existe.\")\n",
    "    sys.exit(1) # Sai do script se a conexão falhar\n",
    "\n",
    "# --- 4. Ler o arquivo CSV ---\n",
    "try:\n",
    "    print(f\"Lendo o arquivo CSV: {CSV_FILE_PATH}\")\n",
    "    df = pd.read_csv(CSV_FILE_PATH)\n",
    "    print(f\"Arquivo CSV lido com sucesso. Shape: {df.shape}\")\n",
    "\n",
    "    # Pré-tratamento: Remover colunas \"Unnamed\" se existirem (opcional, mas boa prática)\n",
    "    unnamed_cols = [col for col in df.columns if col.startswith('Unnamed')]\n",
    "    if unnamed_cols:\n",
    "        print(f\"Removendo colunas 'Unnamed': {unnamed_cols}\")\n",
    "        df = df.drop(columns=unnamed_cols)\n",
    "        print(f\"Colunas removidas. Novo shape: {df.shape}\")\n",
    "\n",
    "    # Opcional: Limpar nomes de colunas para serem compatíveis com SQL (ex: remover espaços, caracteres especiais)\n",
    "    # df.columns = df.columns.str.replace(' ', '_', regex=False).str.replace('[^A-Za-z0-9_]+', '', regex=True)\n",
    "    # print(\"Nomes das colunas após limpeza básica:\", df.columns.tolist())\n",
    "\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Erro: Arquivo CSV não encontrado em '{CSV_FILE_PATH}'\")\n",
    "    if engine:\n",
    "        engine.dispose() # Libera recursos do engine se ele foi criado\n",
    "    sys.exit(1)\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao ler ou pré-processar o arquivo CSV: {e}\")\n",
    "    if engine:\n",
    "        engine.dispose()\n",
    "    sys.exit(1)\n",
    "\n",
    "# --- 5. Enviar o DataFrame para o MySQL ---\n",
    "try:\n",
    "    print(f\"Enviando dados para a tabela '{TABLE_NAME}' no MySQL...\")\n",
    "    # Usando 'replace': Se a tabela existir, ela será excluída e recriada.\n",
    "    # Use 'append' se quiser adicionar os dados a uma tabela existente.\n",
    "    # Use 'fail' (padrão) se não quiser sobrescrever e gerar erro se a tabela existir.\n",
    "    df.to_sql(name=TABLE_NAME, con=engine, if_exists='replace', index=False, chunksize=1000)\n",
    "    # chunksize=1000 ajuda a enviar dados em lotes, útil para tabelas grandes\n",
    "\n",
    "    print(f\"Dados enviados com sucesso para a tabela '{TABLE_NAME}'.\")\n",
    "\n",
    "    # Verifica quantas linhas foram inseridas (opcional)\n",
    "    with engine.connect() as connection:\n",
    "        result = connection.execute(text(f\"SELECT COUNT(*) FROM {TABLE_NAME}\"))\n",
    "        count = result.scalar()\n",
    "        print(f\"Verificação: A tabela '{TABLE_NAME}' contém {count} linhas.\")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao enviar dados para o MySQL: {e}\")\n",
    "    print(\"Verifique permissões do usuário, tipos de dados incompatíveis ou outros problemas no DB.\")\n",
    "\n",
    "finally:\n",
    "    # --- 6. Fechar a Conexão (liberar recursos) ---\n",
    "    if engine:\n",
    "        engine.dispose()\n",
    "        print(\"Conexão com o banco de dados fechada.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepbridge_homol",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
