{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Synthetic Data Generation with DeepBridge\n",
    "\n",
    "This tutorial demonstrates how to generate synthetic data using the DeepBridge library. I'll walk you through creating synthetic datasets with different methods and comparing their results.\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this demonstration, we'll:\n",
    "1. Create a sample dataset with mixed data types\n",
    "2. Generate synthetic versions using three different methods:\n",
    "   - Gaussian Copula\n",
    "   - CTGAN (Conditional Tabular GAN)\n",
    "   - UltraLight Generator\n",
    "3. Evaluate and compare the quality of each method\n",
    "4. Visualize the differences between original and synthetic data\n",
    "\n",
    "## Understanding the Different Methods\n",
    "\n",
    "Each synthetic data generation method has its unique characteristics:\n",
    "\n",
    "### Gaussian Copula\n",
    "- Statistical method that preserves the marginal distributions and correlations between features\n",
    "- Good balance between quality and computational efficiency\n",
    "- Works well for numerical data with linear relationships\n",
    "- Medium memory requirements\n",
    "\n",
    "### CTGAN (Conditional Tabular GAN)\n",
    "- Neural network-based approach using Generative Adversarial Networks\n",
    "- Can capture complex, non-linear relationships in the data\n",
    "- Highest quality for capturing complex patterns\n",
    "- More computationally intensive and requires more memory\n",
    "- Longer training time\n",
    "\n",
    "### UltraLight Generator\n",
    "- Simplest and fastest approach with minimal memory requirements\n",
    "- Uses basic statistical modeling rather than complex ML models\n",
    "- Excellent for large datasets or limited computational resources\n",
    "- Quality may be lower for complex relationships\n",
    "\n",
    "## Example Implementation\n",
    "\n",
    "Let's look at the code to implement these methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guhaase/projetos/deepbridge_homol/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando e preparando dados...\n",
      "Valores NaN em X antes da limpeza: 0\n",
      "Valores infinitos em X: 0\n",
      "NaN em train_df: 0\n",
      "NaN em test_df: 0\n",
      "\n",
      "Treinando modelo...\n",
      "\n",
      "Criando objeto de dataset...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.expanduser(\"~/projetos/DeepBridge\"))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from deepbridge.core.db_data import DBDataset\n",
    "from deepbridge.synthetic import Synthesize\n",
    "from deepbridge.core.experiment import Experiment\n",
    "\n",
    "\n",
    "from deepbridge.validation.wrappers import (\n",
    "    RobustnessSuite, UncertaintySuite, \n",
    ")\n",
    "\n",
    "from deepbridge.utils.robustness import run_robustness_tests\n",
    "from deepbridge.utils.uncertainty import run_uncertainty_tests\n",
    "from deepbridge.utils.resilience import run_resilience_tests\n",
    "from deepbridge.utils.hyperparameter import run_hyperparameter_tests\n",
    "#---------------------------------------------------------\n",
    "# Preparação de dados com cuidado especial \n",
    "#---------------------------------------------------------\n",
    "print(\"Carregando e preparando dados...\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Gerar dados sintéticos com duas classes\n",
    "X, y = make_classification(n_samples=10000, n_features=20, n_classes=2, random_state=42)\n",
    "X = pd.DataFrame(X, columns=[f\"feature_{i}\" for i in range(20)])\n",
    "y = pd.Series(y)\n",
    "\n",
    "# Verificar e lidar com valores ausentes\n",
    "print(f\"Valores NaN em X antes da limpeza: {X.isna().sum().sum()}\")\n",
    "print(f\"Valores infinitos em X: {np.isinf(X.values).sum()}\")\n",
    "\n",
    "# Resetar índices para garantir alinhamento limpo\n",
    "X = X.reset_index(drop=True)\n",
    "y = y.reset_index(drop=True)\n",
    "\n",
    "# Dividir dados\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Resetar índices novamente após a divisão\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "# Criar DataFrames de treino e teste com nomes explícitos de colunas\n",
    "train_df = X_train.copy()\n",
    "train_df['target'] = y_train\n",
    "test_df = X_test.copy()\n",
    "test_df['target'] = y_test\n",
    "\n",
    "# Verificação final\n",
    "print(f\"NaN em train_df: {train_df.isna().sum().sum()}\")\n",
    "print(f\"NaN em test_df: {test_df.isna().sum().sum()}\")\n",
    "\n",
    "# Treinar modelo\n",
    "print(\"\\nTreinando modelo...\")\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Criar objeto de dataset\n",
    "print(\"\\nCriando objeto de dataset...\")\n",
    "dataset = DBDataset(\n",
    "    train_data=train_df,\n",
    "    test_data=test_df,\n",
    "    target_column='target',\n",
    "    model=model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar e executar o experimento\n",
    "experiment = Experiment(\n",
    "      dataset=dataset,\n",
    "      experiment_type=\"binary_classification\",\n",
    "      tests=[\"robustness\", \"uncertainty\"],\n",
    "      feature_subset=['feature_0', 'feature_1'],\n",
    "      suite = \"quick\"\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.982,\n",
       " 'f1': 0.9819959474671671,\n",
       " 'precision': 0.982151158739503,\n",
       " 'recall': 0.982}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.initial_results['models']['primary_model']['metrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.935,\n",
       " 'f1': 0.9349988946805626,\n",
       " 'precision': 0.9349996598898043,\n",
       " 'recall': 0.935}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.initial_results['models']['DECISION_TREE']['metrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.892,\n",
       " 'f1': 0.891998163998164,\n",
       " 'precision': 0.892512069910651,\n",
       " 'recall': 0.892}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.initial_results['models']['LOGISTIC_REGRESSION']['metrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9375,\n",
       " 'f1': 0.9374750876950666,\n",
       " 'precision': 0.9377924782923626,\n",
       " 'recall': 0.9375}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.initial_results['models']['GBM']['metrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Using direct metrics from primary model: {'auc': 0.97, 'roc_auc': 0.97, 'accuracy': 0.96, 'f1': 0.96, 'precision': 0.96, 'recall': 0.96}\n",
      "DEBUG: Forced unique metrics for DECISION_TREE: AUC=0.885\n",
      "DEBUG: Model DECISION_TREE metrics: {'auc': 0.885, 'accuracy': 0.865, 'f1': 0.875, 'precision': 0.88, 'recall': 0.87}\n",
      "DEBUG: Forced unique metrics for LOGISTIC_REGRESSION: AUC=0.9129\n",
      "DEBUG: Model LOGISTIC_REGRESSION metrics: {'auc': 0.9129, 'accuracy': 0.9019, 'f1': 0.9119, 'precision': 0.9169, 'recall': 0.9069}\n",
      "DEBUG: Forced unique metrics for GBM: AUC=0.9491999999999999\n",
      "DEBUG: Model GBM metrics: {'auc': 0.9491999999999999, 'accuracy': 0.9311999999999999, 'f1': 0.9411999999999999, 'precision': 0.9461999999999999, 'recall': 0.9361999999999999}\n",
      "DEBUG: Experiment report - primary model metrics:\n",
      "DEBUG: Primary model metrics: {'auc': 0.97, 'roc_auc': 0.97, 'accuracy': 0.96, 'f1': 0.96, 'precision': 0.96, 'recall': 0.96}\n",
      "DEBUG: Models in experiment_info: ['primary_model', 'DECISION_TREE', 'LOGISTIC_REGRESSION', 'GBM']\n",
      "DEBUG: primary_model metrics: {'accuracy': 0.982, 'f1': 0.9819959474671671, 'precision': 0.982151158739503, 'recall': 0.982}\n",
      "DEBUG: DECISION_TREE metrics: {'auc': 0.885, 'accuracy': 0.865, 'f1': 0.875, 'precision': 0.88, 'recall': 0.87}\n",
      "DEBUG: LOGISTIC_REGRESSION metrics: {'auc': 0.9129, 'accuracy': 0.9019, 'f1': 0.9119, 'precision': 0.9169, 'recall': 0.9069}\n",
      "DEBUG: GBM metrics: {'auc': 0.9491999999999999, 'accuracy': 0.9311999999999999, 'f1': 0.9411999999999999, 'precision': 0.9461999999999999, 'recall': 0.9361999999999999}\n",
      "DEBUG: Using nested results structure\n",
      "DEBUG: Primary model results keys: ['base_score', 'raw', 'quantile', 'feature_importance', 'feature_subset', 'avg_raw_impact', 'avg_quantile_impact', 'avg_overall_impact', 'n_iterations', 'metric', 'metrics']\n",
      "DEBUG: Alternative models: ['DECISION_TREE', 'LOGISTIC_REGRESSION', 'GBM']\n",
      "DEBUG: Primary metrics found (before override): {'accuracy': 0.982, 'f1': 0.9819959474671671, 'precision': 0.982151158739503, 'recall': 0.982}\n",
      "DEBUG: Primary metrics FORCED to: {'auc': 0.97, 'accuracy': 0.96, 'f1': 0.97, 'precision': 0.96, 'recall': 0.97}\n",
      "DEBUG: Found AUC in primary_metrics['auc']: 0.97\n",
      "DEBUG: FORCING primary model AUC to: 0.97\n",
      "DEBUG: AUC value after processing: 0.97\n",
      "DEBUG: Primary metrics values for charts: [0.96, 0.97, 0.97, 0.96, 0.97]\n",
      "\n",
      "DEBUG: Processing alternative model metrics\n",
      "DEBUG: model_names: ['DECISION_TREE', 'LOGISTIC_REGRESSION', 'GBM']\n",
      "DEBUG: alternative_models keys: ['DECISION_TREE', 'LOGISTIC_REGRESSION', 'GBM']\n",
      "DEBUG: FORCING DECISION_TREE AUC to: 0.885\n",
      "DEBUG: Generated forced metrics for DECISION_TREE: {'auc': 0.885, 'accuracy': 0.865, 'f1': 0.875, 'precision': 0.88, 'recall': 0.87}\n",
      "DEBUG: Final metrics for DECISION_TREE: [0.865, 0.885, 0.875, 0.88, 0.87]\n",
      "DEBUG: FORCING LOGISTIC_REGRESSION AUC to: 0.9129\n",
      "DEBUG: Generated forced metrics for LOGISTIC_REGRESSION: {'auc': 0.9129, 'accuracy': 0.9019, 'f1': 0.9119, 'precision': 0.9169, 'recall': 0.9069}\n",
      "DEBUG: Final metrics for LOGISTIC_REGRESSION: [0.9019, 0.9129, 0.9119, 0.9169, 0.9069]\n",
      "DEBUG: FORCING GBM AUC to: 0.9491999999999999\n",
      "DEBUG: Generated forced metrics for GBM: {'auc': 0.9491999999999999, 'accuracy': 0.9311999999999999, 'f1': 0.9411999999999999, 'precision': 0.9461999999999999, 'recall': 0.9361999999999999}\n",
      "DEBUG: Final metrics for GBM: [0.9311999999999999, 0.9491999999999999, 0.9411999999999999, 0.9461999999999999, 0.9361999999999999]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'rob.html'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.save_report(\"robustness\", \"rob.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<deepbridge.core.experiment.experiment.Experiment at 0x7f15f7e058b0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepbridge_homol",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
