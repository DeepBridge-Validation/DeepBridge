{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Synthetic Data Generation with DeepBridge\n",
    "\n",
    "This tutorial demonstrates how to generate synthetic data using the DeepBridge library. I'll walk you through creating synthetic datasets with different methods and comparing their results.\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this demonstration, we'll:\n",
    "1. Create a sample dataset with mixed data types\n",
    "2. Generate synthetic versions using three different methods:\n",
    "   - Gaussian Copula\n",
    "   - CTGAN (Conditional Tabular GAN)\n",
    "   - UltraLight Generator\n",
    "3. Evaluate and compare the quality of each method\n",
    "4. Visualize the differences between original and synthetic data\n",
    "\n",
    "## Understanding the Different Methods\n",
    "\n",
    "Each synthetic data generation method has its unique characteristics:\n",
    "\n",
    "### Gaussian Copula\n",
    "- Statistical method that preserves the marginal distributions and correlations between features\n",
    "- Good balance between quality and computational efficiency\n",
    "- Works well for numerical data with linear relationships\n",
    "- Medium memory requirements\n",
    "\n",
    "### CTGAN (Conditional Tabular GAN)\n",
    "- Neural network-based approach using Generative Adversarial Networks\n",
    "- Can capture complex, non-linear relationships in the data\n",
    "- Highest quality for capturing complex patterns\n",
    "- More computationally intensive and requires more memory\n",
    "- Longer training time\n",
    "\n",
    "### UltraLight Generator\n",
    "- Simplest and fastest approach with minimal memory requirements\n",
    "- Uses basic statistical modeling rather than complex ML models\n",
    "- Excellent for large datasets or limited computational resources\n",
    "- Quality may be lower for complex relationships\n",
    "\n",
    "## Example Implementation\n",
    "\n",
    "Let's look at the code to implement these methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guhaase/projetos/deepbridge_homol/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando e preparando dados...\n",
      "Valores NaN em X antes da limpeza: 0\n",
      "Valores infinitos em X: 0\n",
      "NaN em train_df: 0\n",
      "NaN em test_df: 0\n",
      "\n",
      "Treinando modelo...\n",
      "\n",
      "Criando objeto de dataset...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.expanduser(\"~/projetos/DeepBridge\"))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from deepbridge.core.db_data import DBDataset\n",
    "from deepbridge.synthetic import Synthesize\n",
    "from deepbridge.core.experiment import Experiment\n",
    "\n",
    "\n",
    "from deepbridge.validation.wrappers import (\n",
    "    RobustnessSuite, UncertaintySuite, \n",
    ")\n",
    "\n",
    "from deepbridge.utils.robustness import run_robustness_tests\n",
    "from deepbridge.utils.uncertainty import run_uncertainty_tests\n",
    "from deepbridge.utils.resilience import run_resilience_tests\n",
    "from deepbridge.utils.hyperparameter import run_hyperparameter_tests\n",
    "#---------------------------------------------------------\n",
    "# Preparação de dados com cuidado especial \n",
    "#---------------------------------------------------------\n",
    "print(\"Carregando e preparando dados...\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Gerar dados sintéticos com duas classes\n",
    "X, y = make_classification(n_samples=10000, n_features=20, n_classes=2, random_state=42)\n",
    "X = pd.DataFrame(X, columns=[f\"feature_{i}\" for i in range(20)])\n",
    "y = pd.Series(y)\n",
    "\n",
    "# Verificar e lidar com valores ausentes\n",
    "print(f\"Valores NaN em X antes da limpeza: {X.isna().sum().sum()}\")\n",
    "print(f\"Valores infinitos em X: {np.isinf(X.values).sum()}\")\n",
    "\n",
    "# Resetar índices para garantir alinhamento limpo\n",
    "X = X.reset_index(drop=True)\n",
    "y = y.reset_index(drop=True)\n",
    "\n",
    "# Dividir dados\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Resetar índices novamente após a divisão\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "# Criar DataFrames de treino e teste com nomes explícitos de colunas\n",
    "train_df = X_train.copy()\n",
    "train_df['target'] = y_train\n",
    "test_df = X_test.copy()\n",
    "test_df['target'] = y_test\n",
    "\n",
    "# Verificação final\n",
    "print(f\"NaN em train_df: {train_df.isna().sum().sum()}\")\n",
    "print(f\"NaN em test_df: {test_df.isna().sum().sum()}\")\n",
    "\n",
    "# Treinar modelo\n",
    "print(\"\\nTreinando modelo...\")\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Criar objeto de dataset\n",
    "print(\"\\nCriando objeto de dataset...\")\n",
    "dataset = DBDataset(\n",
    "    train_data=train_df,\n",
    "    test_data=test_df,\n",
    "    target_column='target',\n",
    "    model=model\n",
    ")\n",
    "\n",
    "# 5. Initialize the Experiment class\n",
    "experiment = Experiment(\n",
    "    dataset=dataset,\n",
    "    experiment_type=\"binary_classification\", \n",
    "    tests=['robustness', 'uncertainty', 'resilience', 'hyperparameters']\n",
    ")\n",
    "\n",
    "results = experiment.run_tests(\"full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'primary_model': {'importance': {'by_config': {'cv5_subs20_size0.5': {'method': 'importance',\n",
       "     'cv': 5,\n",
       "     'n_subsamples': 20,\n",
       "     'subsample_size': 0.5,\n",
       "     'raw_importance_scores': {'n_estimators': np.float64(0.000700120560373446),\n",
       "      'max_depth': np.float64(0.001746169167903763),\n",
       "      'min_samples_split': np.float64(0.00090245829766938),\n",
       "      'min_samples_leaf': np.float64(0.0012448463606773044)},\n",
       "     'normalized_importance': {'n_estimators': np.float64(0.15241235978782322),\n",
       "      'max_depth': np.float64(0.38013133527601833),\n",
       "      'min_samples_split': np.float64(0.1964601620676941),\n",
       "      'min_samples_leaf': np.float64(0.2709961428684643)},\n",
       "     'sorted_importance': {'max_depth': np.float64(0.38013133527601833),\n",
       "      'min_samples_leaf': np.float64(0.2709961428684643),\n",
       "      'min_samples_split': np.float64(0.1964601620676941),\n",
       "      'n_estimators': np.float64(0.15241235978782322)},\n",
       "     'param_variations': {'n_estimators': [np.float64(0.0007126966450997297),\n",
       "       np.float64(0.0008192690730517255),\n",
       "       np.float64(0.0006734350297014818),\n",
       "       np.float64(0.0003563483225499094),\n",
       "       np.float64(0.0005870870479017735),\n",
       "       np.float64(0.0003563483225499094),\n",
       "       np.float64(0.0004856209060564136),\n",
       "       np.float64(0.0006172133998483682),\n",
       "       np.float64(0.0011507662831995195),\n",
       "       np.float64(0.0013669238185150237),\n",
       "       np.float64(0.00013468700594026497),\n",
       "       np.float64(0.000699854212223701),\n",
       "       np.float64(0.0005870870479018156),\n",
       "       np.float64(6.409875621278546e-17),\n",
       "       np.float64(0.00040406101782089964),\n",
       "       np.float64(0.0004856209060563846),\n",
       "       np.float64(0.0014061736247841883),\n",
       "       np.float64(0.0003563483225498698),\n",
       "       np.float64(0.0010519391444940701),\n",
       "       np.float64(0.001750931077223809)],\n",
       "      'max_depth': [np.float64(0.0014846149779162367),\n",
       "       np.float64(0.0019833490538449746),\n",
       "       np.float64(0.0018557687223951036),\n",
       "       np.float64(0.0024619554199448806),\n",
       "       np.float64(0.002075119863762012),\n",
       "       np.float64(0.0009476070829587105),\n",
       "       np.float64(0.002350640381700612),\n",
       "       np.float64(0.002254247691151427),\n",
       "       np.float64(0.0011605769149479973),\n",
       "       np.float64(0.0016536909861128784),\n",
       "       np.float64(0.0024774493137178005),\n",
       "       np.float64(0.00281395937194166),\n",
       "       np.float64(0.002188793349434954),\n",
       "       np.float64(0.0009897433186107924),\n",
       "       np.float64(0.0004285714285714541),\n",
       "       np.float64(0.0017540041654012584),\n",
       "       np.float64(0.0011134612334370334),\n",
       "       np.float64(0.0014051653980647677),\n",
       "       np.float64(0.00281395937194166),\n",
       "       np.float64(0.0007107053122190384)],\n",
       "      'min_samples_split': [np.float64(0.0011664236870397133),\n",
       "       np.float64(0.0007126966450999078),\n",
       "       np.float64(0.0005870870479018996),\n",
       "       np.float64(0.0010168645954315055),\n",
       "       np.float64(0.0013669238185149877),\n",
       "       np.float64(0.000538748023761217),\n",
       "       np.float64(0.0010690449676496391),\n",
       "       np.float64(0.0004665694748158309),\n",
       "       np.float64(0.0010774960475224077),\n",
       "       np.float64(0.001993185670138673),\n",
       "       np.float64(0.0008832017614757217),\n",
       "       np.float64(0.0005387480237611122),\n",
       "       np.float64(0.0007126966450998386),\n",
       "       np.float64(0.0010690449676496886),\n",
       "       np.float64(0.0007499055118105862),\n",
       "       np.float64(0.0004856209060563846),\n",
       "       np.float64(0.0010168645954315885),\n",
       "       np.float64(0.00023328473740796078),\n",
       "       np.float64(0.0008832017614757615),\n",
       "       np.float64(0.0014815570653431765)],\n",
       "      'min_samples_leaf': [np.float64(0.0013265131692557649),\n",
       "       np.float64(0.0009331389496316618),\n",
       "       np.float64(0.0010774960475224862),\n",
       "       np.float64(0.0015532863266952027),\n",
       "       np.float64(0.0013669238185149903),\n",
       "       np.float64(0.0010774960475223815),\n",
       "       np.float64(0.0024578072191549917),\n",
       "       np.float64(0.0008832017614757935),\n",
       "       np.float64(0.0006172133998483853),\n",
       "       np.float64(0.0011971242942834916),\n",
       "       np.float64(0.002138089935299397),\n",
       "       np.float64(0.0012988744473319352),\n",
       "       np.float64(0.0010774960475223815),\n",
       "       np.float64(0.000134687005940422),\n",
       "       np.float64(0.00023328473740787012),\n",
       "       np.float64(0.001425393290199608),\n",
       "       np.float64(0.0002693740118806346),\n",
       "       np.float64(0.0019931856701387207),\n",
       "       np.float64(0.001719568579549259),\n",
       "       np.float64(0.0021167724543707093)]},\n",
       "     'performance_data': {'n_estimators': {'50': np.float64(0.9314),\n",
       "       '100': np.float64(0.9324714285714286),\n",
       "       '200': np.float64(0.9324285714285713)},\n",
       "      'max_depth': {'None': np.float64(0.9314),\n",
       "       '10': np.float64(0.927414285714286),\n",
       "       '20': np.float64(0.931342857142857),\n",
       "       '30': np.float64(0.9314)},\n",
       "      'min_samples_split': {'2': np.float64(0.9314),\n",
       "       '5': np.float64(0.9316714285714285),\n",
       "       '10': np.float64(0.9313571428571427)},\n",
       "      'min_samples_leaf': {'1': np.float64(0.9314),\n",
       "       '2': np.float64(0.9311),\n",
       "       '4': np.float64(0.9295571428571427)}},\n",
       "     'tuning_order': ['max_depth',\n",
       "      'min_samples_leaf',\n",
       "      'min_samples_split',\n",
       "      'n_estimators']},\n",
       "    'cv5_subs10_size0.7': {'method': 'importance',\n",
       "     'cv': 5,\n",
       "     'n_subsamples': 10,\n",
       "     'subsample_size': 0.7,\n",
       "     'raw_importance_scores': {'n_estimators': np.float64(0.0003855544135430864),\n",
       "      'max_depth': np.float64(0.00184541911005238),\n",
       "      'min_samples_split': np.float64(0.0005510688188654001),\n",
       "      'min_samples_leaf': np.float64(0.000631926510913425)},\n",
       "     'normalized_importance': {'n_estimators': np.float64(0.112934367623774),\n",
       "      'max_depth': np.float64(0.5405494863341851),\n",
       "      'min_samples_split': np.float64(0.16141588940412738),\n",
       "      'min_samples_leaf': np.float64(0.1851002566379136)},\n",
       "     'sorted_importance': {'max_depth': np.float64(0.5405494863341851),\n",
       "      'min_samples_leaf': np.float64(0.1851002566379136),\n",
       "      'min_samples_split': np.float64(0.16141588940412738),\n",
       "      'n_estimators': np.float64(0.112934367623774)},\n",
       "     'param_variations': {'n_estimators': [np.float64(0.0005772300505525771),\n",
       "       np.float64(0.00034694022002712717),\n",
       "       np.float64(0.0005855153431458604),\n",
       "       np.float64(0.0005356380323924873),\n",
       "       np.float64(0.00044109189508745534),\n",
       "       np.float64(0.00019236089298866528),\n",
       "       np.float64(0.0003848200169723277),\n",
       "       np.float64(0.0002547016573943085),\n",
       "       np.float64(9.605763897327817e-05),\n",
       "       np.float64(0.00044118838789677765)],\n",
       "      'max_depth': [np.float64(0.002191314591455147),\n",
       "       np.float64(0.0018273670609944114),\n",
       "       np.float64(0.0010152619244174377),\n",
       "       np.float64(0.0012367397947619179),\n",
       "       np.float64(0.002186835099806154),\n",
       "       np.float64(0.001034387333319927),\n",
       "       np.float64(0.0018338081441755794),\n",
       "       np.float64(0.002800281889097196),\n",
       "       np.float64(0.002118164480685722),\n",
       "       np.float64(0.002210030781810304)],\n",
       "      'min_samples_split': [np.float64(0.0005768860914754056),\n",
       "       np.float64(0.0003845744301045948),\n",
       "       np.float64(9.625417618801556e-05),\n",
       "       np.float64(0.0006007764631417828),\n",
       "       np.float64(0.000673406981040449),\n",
       "       np.float64(0.0012024026696620207),\n",
       "       np.float64(0.0002543117369973207),\n",
       "       np.float64(0.0009474645213238474),\n",
       "       np.float64(0.0003335192236330235),\n",
       "       np.float64(0.000441091895087541)],\n",
       "      'min_samples_leaf': [np.float64(0.00019270488959082082),\n",
       "       np.float64(0.001040807012064346),\n",
       "       np.float64(4.2834309634648094e-07),\n",
       "       np.float64(0.00044109204833694027),\n",
       "       np.float64(0.0008817012672793752),\n",
       "       np.float64(0.0003331788110620733),\n",
       "       np.float64(0.0010712935883009254),\n",
       "       np.float64(0.0007512215449720283),\n",
       "       np.float64(0.0007514668882551915),\n",
       "       np.float64(0.0008553707161762015)]},\n",
       "     'performance_data': {'n_estimators': {'50': np.float64(0.9344359300410664),\n",
       "       '100': np.float64(0.9344764545246086),\n",
       "       '200': np.float64(0.9344970919930791)},\n",
       "      'max_depth': {'None': np.float64(0.9344359300410664),\n",
       "       '10': np.float64(0.9302923849825937),\n",
       "       '20': np.float64(0.9344153968022347),\n",
       "       '30': np.float64(0.9344155218778012)},\n",
       "      'min_samples_split': {'2': np.float64(0.9344359300410664),\n",
       "       '5': np.float64(0.9344768714431637),\n",
       "       '10': np.float64(0.933701111087949)},\n",
       "      'min_samples_leaf': {'1': np.float64(0.9344359300410664),\n",
       "       '2': np.float64(0.933844134998228),\n",
       "       '4': np.float64(0.9331704363052677)}},\n",
       "     'tuning_order': ['max_depth',\n",
       "      'min_samples_leaf',\n",
       "      'min_samples_split',\n",
       "      'n_estimators']}},\n",
       "   'all_results': [{'method': 'importance',\n",
       "     'cv': 5,\n",
       "     'n_subsamples': 20,\n",
       "     'subsample_size': 0.5,\n",
       "     'raw_importance_scores': {'n_estimators': np.float64(0.000700120560373446),\n",
       "      'max_depth': np.float64(0.001746169167903763),\n",
       "      'min_samples_split': np.float64(0.00090245829766938),\n",
       "      'min_samples_leaf': np.float64(0.0012448463606773044)},\n",
       "     'normalized_importance': {'n_estimators': np.float64(0.15241235978782322),\n",
       "      'max_depth': np.float64(0.38013133527601833),\n",
       "      'min_samples_split': np.float64(0.1964601620676941),\n",
       "      'min_samples_leaf': np.float64(0.2709961428684643)},\n",
       "     'sorted_importance': {'max_depth': np.float64(0.38013133527601833),\n",
       "      'min_samples_leaf': np.float64(0.2709961428684643),\n",
       "      'min_samples_split': np.float64(0.1964601620676941),\n",
       "      'n_estimators': np.float64(0.15241235978782322)},\n",
       "     'param_variations': {'n_estimators': [np.float64(0.0007126966450997297),\n",
       "       np.float64(0.0008192690730517255),\n",
       "       np.float64(0.0006734350297014818),\n",
       "       np.float64(0.0003563483225499094),\n",
       "       np.float64(0.0005870870479017735),\n",
       "       np.float64(0.0003563483225499094),\n",
       "       np.float64(0.0004856209060564136),\n",
       "       np.float64(0.0006172133998483682),\n",
       "       np.float64(0.0011507662831995195),\n",
       "       np.float64(0.0013669238185150237),\n",
       "       np.float64(0.00013468700594026497),\n",
       "       np.float64(0.000699854212223701),\n",
       "       np.float64(0.0005870870479018156),\n",
       "       np.float64(6.409875621278546e-17),\n",
       "       np.float64(0.00040406101782089964),\n",
       "       np.float64(0.0004856209060563846),\n",
       "       np.float64(0.0014061736247841883),\n",
       "       np.float64(0.0003563483225498698),\n",
       "       np.float64(0.0010519391444940701),\n",
       "       np.float64(0.001750931077223809)],\n",
       "      'max_depth': [np.float64(0.0014846149779162367),\n",
       "       np.float64(0.0019833490538449746),\n",
       "       np.float64(0.0018557687223951036),\n",
       "       np.float64(0.0024619554199448806),\n",
       "       np.float64(0.002075119863762012),\n",
       "       np.float64(0.0009476070829587105),\n",
       "       np.float64(0.002350640381700612),\n",
       "       np.float64(0.002254247691151427),\n",
       "       np.float64(0.0011605769149479973),\n",
       "       np.float64(0.0016536909861128784),\n",
       "       np.float64(0.0024774493137178005),\n",
       "       np.float64(0.00281395937194166),\n",
       "       np.float64(0.002188793349434954),\n",
       "       np.float64(0.0009897433186107924),\n",
       "       np.float64(0.0004285714285714541),\n",
       "       np.float64(0.0017540041654012584),\n",
       "       np.float64(0.0011134612334370334),\n",
       "       np.float64(0.0014051653980647677),\n",
       "       np.float64(0.00281395937194166),\n",
       "       np.float64(0.0007107053122190384)],\n",
       "      'min_samples_split': [np.float64(0.0011664236870397133),\n",
       "       np.float64(0.0007126966450999078),\n",
       "       np.float64(0.0005870870479018996),\n",
       "       np.float64(0.0010168645954315055),\n",
       "       np.float64(0.0013669238185149877),\n",
       "       np.float64(0.000538748023761217),\n",
       "       np.float64(0.0010690449676496391),\n",
       "       np.float64(0.0004665694748158309),\n",
       "       np.float64(0.0010774960475224077),\n",
       "       np.float64(0.001993185670138673),\n",
       "       np.float64(0.0008832017614757217),\n",
       "       np.float64(0.0005387480237611122),\n",
       "       np.float64(0.0007126966450998386),\n",
       "       np.float64(0.0010690449676496886),\n",
       "       np.float64(0.0007499055118105862),\n",
       "       np.float64(0.0004856209060563846),\n",
       "       np.float64(0.0010168645954315885),\n",
       "       np.float64(0.00023328473740796078),\n",
       "       np.float64(0.0008832017614757615),\n",
       "       np.float64(0.0014815570653431765)],\n",
       "      'min_samples_leaf': [np.float64(0.0013265131692557649),\n",
       "       np.float64(0.0009331389496316618),\n",
       "       np.float64(0.0010774960475224862),\n",
       "       np.float64(0.0015532863266952027),\n",
       "       np.float64(0.0013669238185149903),\n",
       "       np.float64(0.0010774960475223815),\n",
       "       np.float64(0.0024578072191549917),\n",
       "       np.float64(0.0008832017614757935),\n",
       "       np.float64(0.0006172133998483853),\n",
       "       np.float64(0.0011971242942834916),\n",
       "       np.float64(0.002138089935299397),\n",
       "       np.float64(0.0012988744473319352),\n",
       "       np.float64(0.0010774960475223815),\n",
       "       np.float64(0.000134687005940422),\n",
       "       np.float64(0.00023328473740787012),\n",
       "       np.float64(0.001425393290199608),\n",
       "       np.float64(0.0002693740118806346),\n",
       "       np.float64(0.0019931856701387207),\n",
       "       np.float64(0.001719568579549259),\n",
       "       np.float64(0.0021167724543707093)]},\n",
       "     'performance_data': {'n_estimators': {'50': np.float64(0.9314),\n",
       "       '100': np.float64(0.9324714285714286),\n",
       "       '200': np.float64(0.9324285714285713)},\n",
       "      'max_depth': {'None': np.float64(0.9314),\n",
       "       '10': np.float64(0.927414285714286),\n",
       "       '20': np.float64(0.931342857142857),\n",
       "       '30': np.float64(0.9314)},\n",
       "      'min_samples_split': {'2': np.float64(0.9314),\n",
       "       '5': np.float64(0.9316714285714285),\n",
       "       '10': np.float64(0.9313571428571427)},\n",
       "      'min_samples_leaf': {'1': np.float64(0.9314),\n",
       "       '2': np.float64(0.9311),\n",
       "       '4': np.float64(0.9295571428571427)}},\n",
       "     'tuning_order': ['max_depth',\n",
       "      'min_samples_leaf',\n",
       "      'min_samples_split',\n",
       "      'n_estimators']},\n",
       "    {'method': 'importance',\n",
       "     'cv': 5,\n",
       "     'n_subsamples': 10,\n",
       "     'subsample_size': 0.7,\n",
       "     'raw_importance_scores': {'n_estimators': np.float64(0.0003855544135430864),\n",
       "      'max_depth': np.float64(0.00184541911005238),\n",
       "      'min_samples_split': np.float64(0.0005510688188654001),\n",
       "      'min_samples_leaf': np.float64(0.000631926510913425)},\n",
       "     'normalized_importance': {'n_estimators': np.float64(0.112934367623774),\n",
       "      'max_depth': np.float64(0.5405494863341851),\n",
       "      'min_samples_split': np.float64(0.16141588940412738),\n",
       "      'min_samples_leaf': np.float64(0.1851002566379136)},\n",
       "     'sorted_importance': {'max_depth': np.float64(0.5405494863341851),\n",
       "      'min_samples_leaf': np.float64(0.1851002566379136),\n",
       "      'min_samples_split': np.float64(0.16141588940412738),\n",
       "      'n_estimators': np.float64(0.112934367623774)},\n",
       "     'param_variations': {'n_estimators': [np.float64(0.0005772300505525771),\n",
       "       np.float64(0.00034694022002712717),\n",
       "       np.float64(0.0005855153431458604),\n",
       "       np.float64(0.0005356380323924873),\n",
       "       np.float64(0.00044109189508745534),\n",
       "       np.float64(0.00019236089298866528),\n",
       "       np.float64(0.0003848200169723277),\n",
       "       np.float64(0.0002547016573943085),\n",
       "       np.float64(9.605763897327817e-05),\n",
       "       np.float64(0.00044118838789677765)],\n",
       "      'max_depth': [np.float64(0.002191314591455147),\n",
       "       np.float64(0.0018273670609944114),\n",
       "       np.float64(0.0010152619244174377),\n",
       "       np.float64(0.0012367397947619179),\n",
       "       np.float64(0.002186835099806154),\n",
       "       np.float64(0.001034387333319927),\n",
       "       np.float64(0.0018338081441755794),\n",
       "       np.float64(0.002800281889097196),\n",
       "       np.float64(0.002118164480685722),\n",
       "       np.float64(0.002210030781810304)],\n",
       "      'min_samples_split': [np.float64(0.0005768860914754056),\n",
       "       np.float64(0.0003845744301045948),\n",
       "       np.float64(9.625417618801556e-05),\n",
       "       np.float64(0.0006007764631417828),\n",
       "       np.float64(0.000673406981040449),\n",
       "       np.float64(0.0012024026696620207),\n",
       "       np.float64(0.0002543117369973207),\n",
       "       np.float64(0.0009474645213238474),\n",
       "       np.float64(0.0003335192236330235),\n",
       "       np.float64(0.000441091895087541)],\n",
       "      'min_samples_leaf': [np.float64(0.00019270488959082082),\n",
       "       np.float64(0.001040807012064346),\n",
       "       np.float64(4.2834309634648094e-07),\n",
       "       np.float64(0.00044109204833694027),\n",
       "       np.float64(0.0008817012672793752),\n",
       "       np.float64(0.0003331788110620733),\n",
       "       np.float64(0.0010712935883009254),\n",
       "       np.float64(0.0007512215449720283),\n",
       "       np.float64(0.0007514668882551915),\n",
       "       np.float64(0.0008553707161762015)]},\n",
       "     'performance_data': {'n_estimators': {'50': np.float64(0.9344359300410664),\n",
       "       '100': np.float64(0.9344764545246086),\n",
       "       '200': np.float64(0.9344970919930791)},\n",
       "      'max_depth': {'None': np.float64(0.9344359300410664),\n",
       "       '10': np.float64(0.9302923849825937),\n",
       "       '20': np.float64(0.9344153968022347),\n",
       "       '30': np.float64(0.9344155218778012)},\n",
       "      'min_samples_split': {'2': np.float64(0.9344359300410664),\n",
       "       '5': np.float64(0.9344768714431637),\n",
       "       '10': np.float64(0.933701111087949)},\n",
       "      'min_samples_leaf': {'1': np.float64(0.9344359300410664),\n",
       "       '2': np.float64(0.933844134998228),\n",
       "       '4': np.float64(0.9331704363052677)}},\n",
       "     'tuning_order': ['max_depth',\n",
       "      'min_samples_leaf',\n",
       "      'min_samples_split',\n",
       "      'n_estimators']}]},\n",
       "  'importance_scores': {'n_estimators': np.float64(0.1326733637057986),\n",
       "   'max_depth': np.float64(0.4603404108051017),\n",
       "   'min_samples_split': np.float64(0.17893802573591072),\n",
       "   'min_samples_leaf': np.float64(0.22804819975318896)},\n",
       "  'sorted_importance': {'max_depth': np.float64(0.4603404108051017),\n",
       "   'min_samples_leaf': np.float64(0.22804819975318896),\n",
       "   'min_samples_split': np.float64(0.17893802573591072),\n",
       "   'n_estimators': np.float64(0.1326733637057986)},\n",
       "  'tuning_order': ['max_depth',\n",
       "   'min_samples_leaf',\n",
       "   'min_samples_split',\n",
       "   'n_estimators']},\n",
       " 'alternative_models': {'DECISION_TREE': {'importance': {'by_config': {'cv5_subs20_size0.5': {'method': 'importance',\n",
       "      'cv': 5,\n",
       "      'n_subsamples': 20,\n",
       "      'subsample_size': 0.5,\n",
       "      'raw_importance_scores': {'ccp_alpha': np.float64(nan),\n",
       "       'max_depth': np.float64(nan),\n",
       "       'min_impurity_decrease': np.float64(nan),\n",
       "       'min_samples_leaf': np.float64(nan),\n",
       "       'min_samples_split': np.float64(nan),\n",
       "       'min_weight_fraction_leaf': np.float64(nan)},\n",
       "      'normalized_importance': {'ccp_alpha': np.float64(nan),\n",
       "       'max_depth': np.float64(nan),\n",
       "       'min_impurity_decrease': np.float64(nan),\n",
       "       'min_samples_leaf': np.float64(nan),\n",
       "       'min_samples_split': np.float64(nan),\n",
       "       'min_weight_fraction_leaf': np.float64(nan)},\n",
       "      'sorted_importance': {'ccp_alpha': np.float64(nan),\n",
       "       'max_depth': np.float64(nan),\n",
       "       'min_impurity_decrease': np.float64(nan),\n",
       "       'min_samples_leaf': np.float64(nan),\n",
       "       'min_samples_split': np.float64(nan),\n",
       "       'min_weight_fraction_leaf': np.float64(nan)},\n",
       "      'param_variations': {'ccp_alpha': [np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan)],\n",
       "       'max_depth': [np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan)],\n",
       "       'min_impurity_decrease': [np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan)],\n",
       "       'min_samples_leaf': [np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan)],\n",
       "       'min_samples_split': [np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan)],\n",
       "       'min_weight_fraction_leaf': [np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan)]},\n",
       "      'performance_data': {'ccp_alpha': {'0.0': np.float64(-inf)},\n",
       "       'max_depth': {'2': np.float64(-inf),\n",
       "        '5': np.float64(-inf),\n",
       "        '10': np.float64(-inf)},\n",
       "       'min_impurity_decrease': {'0.0': np.float64(-inf)},\n",
       "       'min_samples_leaf': {'1': np.float64(-inf), '2': np.float64(-inf)},\n",
       "       'min_samples_split': {'1': np.float64(-inf),\n",
       "        '2': np.float64(0.8829999999999998),\n",
       "        '4': np.float64(0.8829999999999998)},\n",
       "       'min_weight_fraction_leaf': {'0.0': np.float64(-inf)}},\n",
       "      'tuning_order': ['ccp_alpha',\n",
       "       'max_depth',\n",
       "       'min_impurity_decrease',\n",
       "       'min_samples_leaf',\n",
       "       'min_samples_split',\n",
       "       'min_weight_fraction_leaf']},\n",
       "     'cv5_subs10_size0.7': {'method': 'importance',\n",
       "      'cv': 5,\n",
       "      'n_subsamples': 10,\n",
       "      'subsample_size': 0.7,\n",
       "      'raw_importance_scores': {'ccp_alpha': np.float64(nan),\n",
       "       'max_depth': np.float64(nan),\n",
       "       'min_impurity_decrease': np.float64(nan),\n",
       "       'min_samples_leaf': np.float64(nan),\n",
       "       'min_samples_split': np.float64(nan),\n",
       "       'min_weight_fraction_leaf': np.float64(nan)},\n",
       "      'normalized_importance': {'ccp_alpha': np.float64(nan),\n",
       "       'max_depth': np.float64(nan),\n",
       "       'min_impurity_decrease': np.float64(nan),\n",
       "       'min_samples_leaf': np.float64(nan),\n",
       "       'min_samples_split': np.float64(nan),\n",
       "       'min_weight_fraction_leaf': np.float64(nan)},\n",
       "      'sorted_importance': {'ccp_alpha': np.float64(nan),\n",
       "       'max_depth': np.float64(nan),\n",
       "       'min_impurity_decrease': np.float64(nan),\n",
       "       'min_samples_leaf': np.float64(nan),\n",
       "       'min_samples_split': np.float64(nan),\n",
       "       'min_weight_fraction_leaf': np.float64(nan)},\n",
       "      'param_variations': {'ccp_alpha': [np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan)],\n",
       "       'max_depth': [np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan)],\n",
       "       'min_impurity_decrease': [np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan)],\n",
       "       'min_samples_leaf': [np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan)],\n",
       "       'min_samples_split': [np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan)],\n",
       "       'min_weight_fraction_leaf': [np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan)]},\n",
       "      'performance_data': {'ccp_alpha': {'0.0': np.float64(-inf)},\n",
       "       'max_depth': {'2': np.float64(-inf),\n",
       "        '5': np.float64(-inf),\n",
       "        '10': np.float64(-inf)},\n",
       "       'min_impurity_decrease': {'0.0': np.float64(-inf)},\n",
       "       'min_samples_leaf': {'1': np.float64(-inf), '2': np.float64(-inf)},\n",
       "       'min_samples_split': {'1': np.float64(-inf),\n",
       "        '2': np.float64(0.8839968731108379),\n",
       "        '4': np.float64(0.8839968731108379)},\n",
       "       'min_weight_fraction_leaf': {'0.0': np.float64(-inf)}},\n",
       "      'tuning_order': ['ccp_alpha',\n",
       "       'max_depth',\n",
       "       'min_impurity_decrease',\n",
       "       'min_samples_leaf',\n",
       "       'min_samples_split',\n",
       "       'min_weight_fraction_leaf']}},\n",
       "    'all_results': [{'method': 'importance',\n",
       "      'cv': 5,\n",
       "      'n_subsamples': 20,\n",
       "      'subsample_size': 0.5,\n",
       "      'raw_importance_scores': {'ccp_alpha': np.float64(nan),\n",
       "       'max_depth': np.float64(nan),\n",
       "       'min_impurity_decrease': np.float64(nan),\n",
       "       'min_samples_leaf': np.float64(nan),\n",
       "       'min_samples_split': np.float64(nan),\n",
       "       'min_weight_fraction_leaf': np.float64(nan)},\n",
       "      'normalized_importance': {'ccp_alpha': np.float64(nan),\n",
       "       'max_depth': np.float64(nan),\n",
       "       'min_impurity_decrease': np.float64(nan),\n",
       "       'min_samples_leaf': np.float64(nan),\n",
       "       'min_samples_split': np.float64(nan),\n",
       "       'min_weight_fraction_leaf': np.float64(nan)},\n",
       "      'sorted_importance': {'ccp_alpha': np.float64(nan),\n",
       "       'max_depth': np.float64(nan),\n",
       "       'min_impurity_decrease': np.float64(nan),\n",
       "       'min_samples_leaf': np.float64(nan),\n",
       "       'min_samples_split': np.float64(nan),\n",
       "       'min_weight_fraction_leaf': np.float64(nan)},\n",
       "      'param_variations': {'ccp_alpha': [np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan)],\n",
       "       'max_depth': [np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan)],\n",
       "       'min_impurity_decrease': [np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan)],\n",
       "       'min_samples_leaf': [np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan)],\n",
       "       'min_samples_split': [np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan)],\n",
       "       'min_weight_fraction_leaf': [np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan)]},\n",
       "      'performance_data': {'ccp_alpha': {'0.0': np.float64(-inf)},\n",
       "       'max_depth': {'2': np.float64(-inf),\n",
       "        '5': np.float64(-inf),\n",
       "        '10': np.float64(-inf)},\n",
       "       'min_impurity_decrease': {'0.0': np.float64(-inf)},\n",
       "       'min_samples_leaf': {'1': np.float64(-inf), '2': np.float64(-inf)},\n",
       "       'min_samples_split': {'1': np.float64(-inf),\n",
       "        '2': np.float64(0.8829999999999998),\n",
       "        '4': np.float64(0.8829999999999998)},\n",
       "       'min_weight_fraction_leaf': {'0.0': np.float64(-inf)}},\n",
       "      'tuning_order': ['ccp_alpha',\n",
       "       'max_depth',\n",
       "       'min_impurity_decrease',\n",
       "       'min_samples_leaf',\n",
       "       'min_samples_split',\n",
       "       'min_weight_fraction_leaf']},\n",
       "     {'method': 'importance',\n",
       "      'cv': 5,\n",
       "      'n_subsamples': 10,\n",
       "      'subsample_size': 0.7,\n",
       "      'raw_importance_scores': {'ccp_alpha': np.float64(nan),\n",
       "       'max_depth': np.float64(nan),\n",
       "       'min_impurity_decrease': np.float64(nan),\n",
       "       'min_samples_leaf': np.float64(nan),\n",
       "       'min_samples_split': np.float64(nan),\n",
       "       'min_weight_fraction_leaf': np.float64(nan)},\n",
       "      'normalized_importance': {'ccp_alpha': np.float64(nan),\n",
       "       'max_depth': np.float64(nan),\n",
       "       'min_impurity_decrease': np.float64(nan),\n",
       "       'min_samples_leaf': np.float64(nan),\n",
       "       'min_samples_split': np.float64(nan),\n",
       "       'min_weight_fraction_leaf': np.float64(nan)},\n",
       "      'sorted_importance': {'ccp_alpha': np.float64(nan),\n",
       "       'max_depth': np.float64(nan),\n",
       "       'min_impurity_decrease': np.float64(nan),\n",
       "       'min_samples_leaf': np.float64(nan),\n",
       "       'min_samples_split': np.float64(nan),\n",
       "       'min_weight_fraction_leaf': np.float64(nan)},\n",
       "      'param_variations': {'ccp_alpha': [np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan)],\n",
       "       'max_depth': [np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan)],\n",
       "       'min_impurity_decrease': [np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan)],\n",
       "       'min_samples_leaf': [np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan)],\n",
       "       'min_samples_split': [np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan)],\n",
       "       'min_weight_fraction_leaf': [np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan),\n",
       "        np.float64(nan)]},\n",
       "      'performance_data': {'ccp_alpha': {'0.0': np.float64(-inf)},\n",
       "       'max_depth': {'2': np.float64(-inf),\n",
       "        '5': np.float64(-inf),\n",
       "        '10': np.float64(-inf)},\n",
       "       'min_impurity_decrease': {'0.0': np.float64(-inf)},\n",
       "       'min_samples_leaf': {'1': np.float64(-inf), '2': np.float64(-inf)},\n",
       "       'min_samples_split': {'1': np.float64(-inf),\n",
       "        '2': np.float64(0.8839968731108379),\n",
       "        '4': np.float64(0.8839968731108379)},\n",
       "       'min_weight_fraction_leaf': {'0.0': np.float64(-inf)}},\n",
       "      'tuning_order': ['ccp_alpha',\n",
       "       'max_depth',\n",
       "       'min_impurity_decrease',\n",
       "       'min_samples_leaf',\n",
       "       'min_samples_split',\n",
       "       'min_weight_fraction_leaf']}]},\n",
       "   'importance_scores': {'ccp_alpha': np.float64(nan),\n",
       "    'max_depth': np.float64(nan),\n",
       "    'min_impurity_decrease': np.float64(nan),\n",
       "    'min_samples_leaf': np.float64(nan),\n",
       "    'min_samples_split': np.float64(nan),\n",
       "    'min_weight_fraction_leaf': np.float64(nan)},\n",
       "   'sorted_importance': {'ccp_alpha': np.float64(nan),\n",
       "    'max_depth': np.float64(nan),\n",
       "    'min_impurity_decrease': np.float64(nan),\n",
       "    'min_samples_leaf': np.float64(nan),\n",
       "    'min_samples_split': np.float64(nan),\n",
       "    'min_weight_fraction_leaf': np.float64(nan)},\n",
       "   'tuning_order': ['ccp_alpha',\n",
       "    'max_depth',\n",
       "    'min_impurity_decrease',\n",
       "    'min_samples_leaf',\n",
       "    'min_samples_split',\n",
       "    'min_weight_fraction_leaf']},\n",
       "  'LOGISTIC_REGRESSION': {'importance': {'by_config': {'cv5_subs20_size0.5': {'method': 'importance',\n",
       "      'cv': 5,\n",
       "      'n_subsamples': 20,\n",
       "      'subsample_size': 0.5,\n",
       "      'raw_importance_scores': {'C': np.float64(0.0015327949231779896),\n",
       "       'penalty': np.float64(0.001214285714285729),\n",
       "       'solver': np.float64(0.000757142857142848)},\n",
       "      'normalized_importance': {'C': np.float64(0.43741357408771175),\n",
       "       'penalty': np.float64(0.34652062465612277),\n",
       "       'solver': np.float64(0.21606580125616545)},\n",
       "      'sorted_importance': {'C': np.float64(0.43741357408771175),\n",
       "       'penalty': np.float64(0.34652062465612277),\n",
       "       'solver': np.float64(0.21606580125616545)},\n",
       "      'param_variations': {'C': [np.float64(0.0014846149779162367),\n",
       "        np.float64(0.0029623487647611225),\n",
       "        np.float64(0.0007659860924831525),\n",
       "        np.float64(0.001299528957047142),\n",
       "        np.float64(0.0019522357669594752),\n",
       "        np.float64(0.0017785570854269139),\n",
       "        np.float64(0.0010177004891982254),\n",
       "        np.float64(0.001131641394125272),\n",
       "        np.float64(0.001057046327639191),\n",
       "        np.float64(0.0021899585309651574),\n",
       "        np.float64(0.001406979685970916),\n",
       "        np.float64(0.0021128856368212547),\n",
       "        np.float64(0.001582751414725669),\n",
       "        np.float64(0.0007107053122190384),\n",
       "        np.float64(0.0017023393268304926),\n",
       "        np.float64(0.0019312151192280099),\n",
       "        np.float64(0.0007107053122189826),\n",
       "        np.float64(0.0012351154618421617),\n",
       "        np.float64(0.001696334583862549),\n",
       "        np.float64(0.0019272482233188319)],\n",
       "       'penalty': [np.float64(0.0014285714285713902),\n",
       "        np.float64(0.003000000000000058),\n",
       "        np.float64(0.0011428571428570566),\n",
       "        np.float64(0.0008571428571428896),\n",
       "        np.float64(0.0035714285714285587),\n",
       "        np.float64(0.0008571428571428896),\n",
       "        np.float64(0.0005714285714285561),\n",
       "        np.float64(0.00028571428571427804),\n",
       "        np.float64(0.001857142857142946),\n",
       "        np.float64(0.0012857142857143344),\n",
       "        np.float64(0.00014285714285716677),\n",
       "        np.float64(0.002571428571428558),\n",
       "        np.float64(0.0010000000000000009),\n",
       "        np.float64(0.0004285714285714448),\n",
       "        np.float64(0.0015714285714286125),\n",
       "        np.float64(0.0007142857142857229),\n",
       "        np.float64(0.0005714285714286116),\n",
       "        np.float64(0.0015714285714286125),\n",
       "        np.float64(0.0004285714285714448),\n",
       "        np.float64(0.0004285714285714448)],\n",
       "       'solver': [np.float64(0.0008571428571428341),\n",
       "        np.float64(0.0),\n",
       "        np.float64(0.0014285714285713347),\n",
       "        np.float64(0.0022857142857142243),\n",
       "        np.float64(0.0004285714285714448),\n",
       "        np.float64(0.00014285714285711126),\n",
       "        np.float64(0.0008571428571427786),\n",
       "        np.float64(0.0007142857142856673),\n",
       "        np.float64(0.00028571428571433355),\n",
       "        np.float64(0.0007142857142857229),\n",
       "        np.float64(0.0),\n",
       "        np.float64(1.1102230246251565e-16),\n",
       "        np.float64(0.0007142857142856673),\n",
       "        np.float64(0.0011428571428571677),\n",
       "        np.float64(0.0011428571428570566),\n",
       "        np.float64(0.00028571428571427804),\n",
       "        np.float64(0.0020000000000000573),\n",
       "        np.float64(0.00028571428571427804),\n",
       "        np.float64(0.0005714285714285561),\n",
       "        np.float64(0.0012857142857143344)]},\n",
       "      'performance_data': {'C': {'0.01': np.float64(0.8880285714285714),\n",
       "        '0.1': np.float64(0.8901857142857145),\n",
       "        '1.0': np.float64(0.8881),\n",
       "        '10.0': np.float64(0.8877428571428571)},\n",
       "       'penalty': {'l1': np.float64(0.8880285714285714),\n",
       "        'l2': np.float64(0.8897714285714287)},\n",
       "       'solver': {'liblinear': np.float64(0.8880285714285714),\n",
       "        'saga': np.float64(0.8866285714285714)}},\n",
       "      'tuning_order': ['C', 'penalty', 'solver']},\n",
       "     'cv5_subs10_size0.7': {'method': 'importance',\n",
       "      'cv': 5,\n",
       "      'n_subsamples': 10,\n",
       "      'subsample_size': 0.7,\n",
       "      'raw_importance_scores': {'C': np.float64(0.0010731730106657272),\n",
       "       'penalty': np.float64(0.0005715953388505835),\n",
       "       'solver': np.float64(0.0005103812720185341)},\n",
       "      'normalized_importance': {'C': np.float64(0.4979575431525908),\n",
       "       'penalty': np.float64(0.26522304212155223),\n",
       "       'solver': np.float64(0.23681941472585696)},\n",
       "      'sorted_importance': {'C': np.float64(0.4979575431525908),\n",
       "       'penalty': np.float64(0.26522304212155223),\n",
       "       'solver': np.float64(0.23681941472585696)},\n",
       "      'param_variations': {'C': [np.float64(0.001159149020504633),\n",
       "        np.float64(0.001193050781531965),\n",
       "        np.float64(0.0006203303021986531),\n",
       "        np.float64(0.0017963831310861835),\n",
       "        np.float64(0.0014432519476601355),\n",
       "        np.float64(0.0005838278120620712),\n",
       "        np.float64(0.0011684296103325242),\n",
       "        np.float64(0.0006675849269099669),\n",
       "        np.float64(0.0002652101140187852),\n",
       "        np.float64(0.0018345124603523534)],\n",
       "       'penalty': [np.float64(0.0005103083112714124),\n",
       "        np.float64(0.0006123491275979998),\n",
       "        np.float64(0.00010183235704896987),\n",
       "        np.float64(0.0005097871630777573),\n",
       "        np.float64(0.001122865898146752),\n",
       "        np.float64(0.0005104125409102211),\n",
       "        np.float64(0.00030664359717330614),\n",
       "        np.float64(0.00010224927560403829),\n",
       "        np.float64(0.0006123491275979442),\n",
       "        np.float64(0.0013271559900774332)],\n",
       "       'solver': [np.float64(0.0004083717245836338),\n",
       "        np.float64(1.0422963880873937e-07),\n",
       "        np.float64(0.0004083717245835783),\n",
       "        np.float64(0.0009187842654937994),\n",
       "        np.float64(0.0004079548060286764),\n",
       "        np.float64(0.00040826749494476955),\n",
       "        np.float64(0.0005107252298263698),\n",
       "        np.float64(0.0004083717245836893),\n",
       "        np.float64(0.00010224927560403829),\n",
       "        np.float64(0.0015306122448979775)]},\n",
       "      'performance_data': {'C': {'0.01': np.float64(0.8904676366971712),\n",
       "        '0.1': np.float64(0.8904675533134604),\n",
       "        '1.0': np.float64(0.8889571407725502),\n",
       "        '10.0': np.float64(0.8888143044756207)},\n",
       "       'penalty': {'l1': np.float64(0.8904676366971712),\n",
       "        'l2': np.float64(0.8902226970461319)},\n",
       "       'solver': {'liblinear': np.float64(0.8904676366971712),\n",
       "        'saga': np.float64(0.8894468741531341)}},\n",
       "      'tuning_order': ['C', 'penalty', 'solver']}},\n",
       "    'all_results': [{'method': 'importance',\n",
       "      'cv': 5,\n",
       "      'n_subsamples': 20,\n",
       "      'subsample_size': 0.5,\n",
       "      'raw_importance_scores': {'C': np.float64(0.0015327949231779896),\n",
       "       'penalty': np.float64(0.001214285714285729),\n",
       "       'solver': np.float64(0.000757142857142848)},\n",
       "      'normalized_importance': {'C': np.float64(0.43741357408771175),\n",
       "       'penalty': np.float64(0.34652062465612277),\n",
       "       'solver': np.float64(0.21606580125616545)},\n",
       "      'sorted_importance': {'C': np.float64(0.43741357408771175),\n",
       "       'penalty': np.float64(0.34652062465612277),\n",
       "       'solver': np.float64(0.21606580125616545)},\n",
       "      'param_variations': {'C': [np.float64(0.0014846149779162367),\n",
       "        np.float64(0.0029623487647611225),\n",
       "        np.float64(0.0007659860924831525),\n",
       "        np.float64(0.001299528957047142),\n",
       "        np.float64(0.0019522357669594752),\n",
       "        np.float64(0.0017785570854269139),\n",
       "        np.float64(0.0010177004891982254),\n",
       "        np.float64(0.001131641394125272),\n",
       "        np.float64(0.001057046327639191),\n",
       "        np.float64(0.0021899585309651574),\n",
       "        np.float64(0.001406979685970916),\n",
       "        np.float64(0.0021128856368212547),\n",
       "        np.float64(0.001582751414725669),\n",
       "        np.float64(0.0007107053122190384),\n",
       "        np.float64(0.0017023393268304926),\n",
       "        np.float64(0.0019312151192280099),\n",
       "        np.float64(0.0007107053122189826),\n",
       "        np.float64(0.0012351154618421617),\n",
       "        np.float64(0.001696334583862549),\n",
       "        np.float64(0.0019272482233188319)],\n",
       "       'penalty': [np.float64(0.0014285714285713902),\n",
       "        np.float64(0.003000000000000058),\n",
       "        np.float64(0.0011428571428570566),\n",
       "        np.float64(0.0008571428571428896),\n",
       "        np.float64(0.0035714285714285587),\n",
       "        np.float64(0.0008571428571428896),\n",
       "        np.float64(0.0005714285714285561),\n",
       "        np.float64(0.00028571428571427804),\n",
       "        np.float64(0.001857142857142946),\n",
       "        np.float64(0.0012857142857143344),\n",
       "        np.float64(0.00014285714285716677),\n",
       "        np.float64(0.002571428571428558),\n",
       "        np.float64(0.0010000000000000009),\n",
       "        np.float64(0.0004285714285714448),\n",
       "        np.float64(0.0015714285714286125),\n",
       "        np.float64(0.0007142857142857229),\n",
       "        np.float64(0.0005714285714286116),\n",
       "        np.float64(0.0015714285714286125),\n",
       "        np.float64(0.0004285714285714448),\n",
       "        np.float64(0.0004285714285714448)],\n",
       "       'solver': [np.float64(0.0008571428571428341),\n",
       "        np.float64(0.0),\n",
       "        np.float64(0.0014285714285713347),\n",
       "        np.float64(0.0022857142857142243),\n",
       "        np.float64(0.0004285714285714448),\n",
       "        np.float64(0.00014285714285711126),\n",
       "        np.float64(0.0008571428571427786),\n",
       "        np.float64(0.0007142857142856673),\n",
       "        np.float64(0.00028571428571433355),\n",
       "        np.float64(0.0007142857142857229),\n",
       "        np.float64(0.0),\n",
       "        np.float64(1.1102230246251565e-16),\n",
       "        np.float64(0.0007142857142856673),\n",
       "        np.float64(0.0011428571428571677),\n",
       "        np.float64(0.0011428571428570566),\n",
       "        np.float64(0.00028571428571427804),\n",
       "        np.float64(0.0020000000000000573),\n",
       "        np.float64(0.00028571428571427804),\n",
       "        np.float64(0.0005714285714285561),\n",
       "        np.float64(0.0012857142857143344)]},\n",
       "      'performance_data': {'C': {'0.01': np.float64(0.8880285714285714),\n",
       "        '0.1': np.float64(0.8901857142857145),\n",
       "        '1.0': np.float64(0.8881),\n",
       "        '10.0': np.float64(0.8877428571428571)},\n",
       "       'penalty': {'l1': np.float64(0.8880285714285714),\n",
       "        'l2': np.float64(0.8897714285714287)},\n",
       "       'solver': {'liblinear': np.float64(0.8880285714285714),\n",
       "        'saga': np.float64(0.8866285714285714)}},\n",
       "      'tuning_order': ['C', 'penalty', 'solver']},\n",
       "     {'method': 'importance',\n",
       "      'cv': 5,\n",
       "      'n_subsamples': 10,\n",
       "      'subsample_size': 0.7,\n",
       "      'raw_importance_scores': {'C': np.float64(0.0010731730106657272),\n",
       "       'penalty': np.float64(0.0005715953388505835),\n",
       "       'solver': np.float64(0.0005103812720185341)},\n",
       "      'normalized_importance': {'C': np.float64(0.4979575431525908),\n",
       "       'penalty': np.float64(0.26522304212155223),\n",
       "       'solver': np.float64(0.23681941472585696)},\n",
       "      'sorted_importance': {'C': np.float64(0.4979575431525908),\n",
       "       'penalty': np.float64(0.26522304212155223),\n",
       "       'solver': np.float64(0.23681941472585696)},\n",
       "      'param_variations': {'C': [np.float64(0.001159149020504633),\n",
       "        np.float64(0.001193050781531965),\n",
       "        np.float64(0.0006203303021986531),\n",
       "        np.float64(0.0017963831310861835),\n",
       "        np.float64(0.0014432519476601355),\n",
       "        np.float64(0.0005838278120620712),\n",
       "        np.float64(0.0011684296103325242),\n",
       "        np.float64(0.0006675849269099669),\n",
       "        np.float64(0.0002652101140187852),\n",
       "        np.float64(0.0018345124603523534)],\n",
       "       'penalty': [np.float64(0.0005103083112714124),\n",
       "        np.float64(0.0006123491275979998),\n",
       "        np.float64(0.00010183235704896987),\n",
       "        np.float64(0.0005097871630777573),\n",
       "        np.float64(0.001122865898146752),\n",
       "        np.float64(0.0005104125409102211),\n",
       "        np.float64(0.00030664359717330614),\n",
       "        np.float64(0.00010224927560403829),\n",
       "        np.float64(0.0006123491275979442),\n",
       "        np.float64(0.0013271559900774332)],\n",
       "       'solver': [np.float64(0.0004083717245836338),\n",
       "        np.float64(1.0422963880873937e-07),\n",
       "        np.float64(0.0004083717245835783),\n",
       "        np.float64(0.0009187842654937994),\n",
       "        np.float64(0.0004079548060286764),\n",
       "        np.float64(0.00040826749494476955),\n",
       "        np.float64(0.0005107252298263698),\n",
       "        np.float64(0.0004083717245836893),\n",
       "        np.float64(0.00010224927560403829),\n",
       "        np.float64(0.0015306122448979775)]},\n",
       "      'performance_data': {'C': {'0.01': np.float64(0.8904676366971712),\n",
       "        '0.1': np.float64(0.8904675533134604),\n",
       "        '1.0': np.float64(0.8889571407725502),\n",
       "        '10.0': np.float64(0.8888143044756207)},\n",
       "       'penalty': {'l1': np.float64(0.8904676366971712),\n",
       "        'l2': np.float64(0.8902226970461319)},\n",
       "       'solver': {'liblinear': np.float64(0.8904676366971712),\n",
       "        'saga': np.float64(0.8894468741531341)}},\n",
       "      'tuning_order': ['C', 'penalty', 'solver']}]},\n",
       "   'importance_scores': {'C': np.float64(0.46768555862015126),\n",
       "    'penalty': np.float64(0.3058718333888375),\n",
       "    'solver': np.float64(0.2264426079910112)},\n",
       "   'sorted_importance': {'C': np.float64(0.46768555862015126),\n",
       "    'penalty': np.float64(0.3058718333888375),\n",
       "    'solver': np.float64(0.2264426079910112)},\n",
       "   'tuning_order': ['C', 'penalty', 'solver']},\n",
       "  'GBM': {'importance': {'by_config': {'cv5_subs20_size0.5': {'method': 'importance',\n",
       "      'cv': 5,\n",
       "      'n_subsamples': 20,\n",
       "      'subsample_size': 0.5,\n",
       "      'raw_importance_scores': {'n_estimators': np.float64(0.00469749287392084),\n",
       "       'learning_rate': np.float64(0.008612373110241012),\n",
       "       'max_depth': np.float64(0.007815040221416755),\n",
       "       'min_samples_split': np.float64(6.734350297063209e-06)},\n",
       "      'normalized_importance': {'n_estimators': np.float64(0.22229664854935732),\n",
       "       'learning_rate': np.float64(0.40755818685579215),\n",
       "       'max_depth': np.float64(0.36982647895947557),\n",
       "       'min_samples_split': np.float64(0.00031868563537489834)},\n",
       "      'sorted_importance': {'learning_rate': np.float64(0.40755818685579215),\n",
       "       'max_depth': np.float64(0.36982647895947557),\n",
       "       'n_estimators': np.float64(0.22229664854935732),\n",
       "       'min_samples_split': np.float64(0.00031868563537489834)},\n",
       "      'param_variations': {'n_estimators': [np.float64(0.00388263183059805),\n",
       "        np.float64(0.0033886565475537327),\n",
       "        np.float64(0.004928513917308759),\n",
       "        np.float64(0.007863922039368722),\n",
       "        np.float64(0.004937707198786997),\n",
       "        np.float64(0.004201284761926268),\n",
       "        np.float64(0.007815328852925147),\n",
       "        np.float64(0.006786674952883673),\n",
       "        np.float64(0.002435564162389448),\n",
       "        np.float64(0.0024725247591898467),\n",
       "        np.float64(0.005994706659754804),\n",
       "        np.float64(0.007473611930214643),\n",
       "        np.float64(0.00013468700594029115),\n",
       "        np.float64(0.006065403172605938),\n",
       "        np.float64(0.004218520874352417),\n",
       "        np.float64(0.005016073936100433),\n",
       "        np.float64(0.0029996220472426173),\n",
       "        np.float64(0.0028981188675625555),\n",
       "        np.float64(0.0062871571215616096),\n",
       "        np.float64(0.004149146840150843)],\n",
       "       'learning_rate': [np.float64(0.008425207830322539),\n",
       "        np.float64(0.00833428565987012),\n",
       "        np.float64(0.007815328852925223),\n",
       "        np.float64(0.012525891552447417),\n",
       "        np.float64(0.008134916763452448),\n",
       "        np.float64(0.009036082870956554),\n",
       "        np.float64(0.012055051349477817),\n",
       "        np.float64(0.00970027000115131),\n",
       "        np.float64(0.006869037302955032),\n",
       "        np.float64(0.00877328453556303),\n",
       "        np.float64(0.009636476430964613),\n",
       "        np.float64(0.009903846111509065),\n",
       "        np.float64(0.004370588154508166),\n",
       "        np.float64(0.009501879513323307),\n",
       "        np.float64(0.008828936140820554),\n",
       "        np.float64(0.010185579597942872),\n",
       "        np.float64(0.006665305983589619),\n",
       "        np.float64(0.005331632381820419),\n",
       "        np.float64(0.010034859874378634),\n",
       "        np.float64(0.0061190012968415025)],\n",
       "       'max_depth': [np.float64(0.006599663291074443),\n",
       "        np.float64(0.008729754680404567),\n",
       "        np.float64(0.006217523331028379),\n",
       "        np.float64(0.011251807614920102),\n",
       "        np.float64(0.008379870059984364),\n",
       "        np.float64(0.00864098759787712),\n",
       "        np.float64(0.009797958971132708),\n",
       "        np.float64(0.007546079157920094),\n",
       "        np.float64(0.00511633372135751),\n",
       "        np.float64(0.007921382412163095),\n",
       "        np.float64(0.0067986926847903965),\n",
       "        np.float64(0.007733661733585418),\n",
       "        np.float64(0.009881841612310625),\n",
       "        np.float64(0.007508725083591221),\n",
       "        np.float64(0.00878155147217754),\n",
       "        np.float64(0.008565077011777906),\n",
       "        np.float64(0.006929512290888137),\n",
       "        np.float64(0.008591510865785893),\n",
       "        np.float64(0.007617857049836705),\n",
       "        np.float64(0.0036910137857288842)],\n",
       "       'min_samples_split': [np.float64(0.0),\n",
       "        np.float64(0.00013468700594026497),\n",
       "        np.float64(1.1102230246251565e-16),\n",
       "        np.float64(0.0),\n",
       "        np.float64(0.0),\n",
       "        np.float64(0.0),\n",
       "        np.float64(1.1102230246251565e-16),\n",
       "        np.float64(0.0),\n",
       "        np.float64(1.1102230246251565e-16),\n",
       "        np.float64(1.1102230246251565e-16),\n",
       "        np.float64(1.1102230246251565e-16),\n",
       "        np.float64(1.1102230246251565e-16),\n",
       "        np.float64(0.0),\n",
       "        np.float64(0.0),\n",
       "        np.float64(1.1102230246251565e-16),\n",
       "        np.float64(0.0),\n",
       "        np.float64(0.0),\n",
       "        np.float64(1.1102230246251565e-16),\n",
       "        np.float64(0.0),\n",
       "        np.float64(1.1102230246251565e-16)]},\n",
       "      'performance_data': {'n_estimators': {'50': np.float64(0.9125000000000002),\n",
       "        '100': np.float64(0.9187714285714286),\n",
       "        '200': np.float64(0.9237428571428573)},\n",
       "       'learning_rate': {'0.01': np.float64(0.9125000000000002),\n",
       "        '0.1': np.float64(0.9309428571428571),\n",
       "        '0.2': np.float64(0.9302285714285713)},\n",
       "       'max_depth': {'3': np.float64(0.9125000000000002),\n",
       "        '5': np.float64(0.9269285714285715),\n",
       "        '10': np.float64(0.9099142857142859)},\n",
       "       'min_samples_split': {'2': np.float64(0.9125000000000002),\n",
       "        '5': np.float64(0.9125000000000002),\n",
       "        '10': np.float64(0.9125142857142858)}},\n",
       "      'tuning_order': ['learning_rate',\n",
       "       'max_depth',\n",
       "       'n_estimators',\n",
       "       'min_samples_split']},\n",
       "     'cv5_subs10_size0.7': {'method': 'importance',\n",
       "      'cv': 5,\n",
       "      'n_subsamples': 10,\n",
       "      'subsample_size': 0.7,\n",
       "      'raw_importance_scores': {'n_estimators': np.float64(0.004460656872026009),\n",
       "       'learning_rate': np.float64(0.008620254890051835),\n",
       "       'max_depth': np.float64(0.0075570486052312326),\n",
       "       'min_samples_split': np.float64(4.4408920985006264e-17)},\n",
       "      'normalized_importance': {'n_estimators': np.float64(0.21613845518822514),\n",
       "       'learning_rate': np.float64(0.41768928404894434),\n",
       "       'max_depth': np.float64(0.3661722607628284),\n",
       "       'min_samples_split': np.float64(2.1518076493329615e-15)},\n",
       "      'sorted_importance': {'learning_rate': np.float64(0.41768928404894434),\n",
       "       'max_depth': np.float64(0.3661722607628284),\n",
       "       'n_estimators': np.float64(0.21613845518822514),\n",
       "       'min_samples_split': np.float64(2.1518076493329615e-15)},\n",
       "      'param_variations': {'n_estimators': [np.float64(0.005108439868507391),\n",
       "        np.float64(0.004447866194621434),\n",
       "        np.float64(0.0061383902502351395),\n",
       "        np.float64(0.004602227207851054),\n",
       "        np.float64(0.006251709867875152),\n",
       "        np.float64(0.003892291445777726),\n",
       "        np.float64(0.0036548151146874003),\n",
       "        np.float64(0.004282361654423517),\n",
       "        np.float64(0.002770307013786616),\n",
       "        np.float64(0.0034581601024946573)],\n",
       "       'learning_rate': [np.float64(0.00938335878901197),\n",
       "        np.float64(0.009723453029247542),\n",
       "        np.float64(0.009645828522503482),\n",
       "        np.float64(0.009768211031808308),\n",
       "        np.float64(0.008378339967661285),\n",
       "        np.float64(0.007757474172573033),\n",
       "        np.float64(0.008247745941494643),\n",
       "        np.float64(0.006988012524180032),\n",
       "        np.float64(0.0065951344888070815),\n",
       "        np.float64(0.009714990433230968)],\n",
       "       'max_depth': [np.float64(0.006499171700950014),\n",
       "        np.float64(0.00816620594973272),\n",
       "        np.float64(0.007239180271677193),\n",
       "        np.float64(0.010648087882285495),\n",
       "        np.float64(0.008194882086203165),\n",
       "        np.float64(0.00784779544580779),\n",
       "        np.float64(0.006307371619389702),\n",
       "        np.float64(0.006904191411805261),\n",
       "        np.float64(0.0062679791400358465),\n",
       "        np.float64(0.007495620544425137)],\n",
       "       'min_samples_split': [np.float64(0.0),\n",
       "        np.float64(1.1102230246251565e-16),\n",
       "        np.float64(0.0),\n",
       "        np.float64(0.0),\n",
       "        np.float64(1.1102230246251565e-16),\n",
       "        np.float64(0.0),\n",
       "        np.float64(0.0),\n",
       "        np.float64(0.0),\n",
       "        np.float64(1.1102230246251565e-16),\n",
       "        np.float64(1.1102230246251565e-16)]},\n",
       "      'performance_data': {'n_estimators': {'50': np.float64(0.9143294907339852),\n",
       "        '100': np.float64(0.9196985678847638),\n",
       "        '200': np.float64(0.9250258489504075)},\n",
       "       'learning_rate': {'0.01': np.float64(0.9143294907339852),\n",
       "        '0.1': np.float64(0.9325171457755725),\n",
       "        '0.2': np.float64(0.9326599612265744)},\n",
       "       'max_depth': {'3': np.float64(0.9143294907339852),\n",
       "        '5': np.float64(0.9306188530570554),\n",
       "        '10': np.float64(0.9153500239728171)},\n",
       "       'min_samples_split': {'2': np.float64(0.9143294907339852),\n",
       "        '5': np.float64(0.9143294907339852),\n",
       "        '10': np.float64(0.9143294907339852)}},\n",
       "      'tuning_order': ['learning_rate',\n",
       "       'max_depth',\n",
       "       'n_estimators',\n",
       "       'min_samples_split']}},\n",
       "    'all_results': [{'method': 'importance',\n",
       "      'cv': 5,\n",
       "      'n_subsamples': 20,\n",
       "      'subsample_size': 0.5,\n",
       "      'raw_importance_scores': {'n_estimators': np.float64(0.00469749287392084),\n",
       "       'learning_rate': np.float64(0.008612373110241012),\n",
       "       'max_depth': np.float64(0.007815040221416755),\n",
       "       'min_samples_split': np.float64(6.734350297063209e-06)},\n",
       "      'normalized_importance': {'n_estimators': np.float64(0.22229664854935732),\n",
       "       'learning_rate': np.float64(0.40755818685579215),\n",
       "       'max_depth': np.float64(0.36982647895947557),\n",
       "       'min_samples_split': np.float64(0.00031868563537489834)},\n",
       "      'sorted_importance': {'learning_rate': np.float64(0.40755818685579215),\n",
       "       'max_depth': np.float64(0.36982647895947557),\n",
       "       'n_estimators': np.float64(0.22229664854935732),\n",
       "       'min_samples_split': np.float64(0.00031868563537489834)},\n",
       "      'param_variations': {'n_estimators': [np.float64(0.00388263183059805),\n",
       "        np.float64(0.0033886565475537327),\n",
       "        np.float64(0.004928513917308759),\n",
       "        np.float64(0.007863922039368722),\n",
       "        np.float64(0.004937707198786997),\n",
       "        np.float64(0.004201284761926268),\n",
       "        np.float64(0.007815328852925147),\n",
       "        np.float64(0.006786674952883673),\n",
       "        np.float64(0.002435564162389448),\n",
       "        np.float64(0.0024725247591898467),\n",
       "        np.float64(0.005994706659754804),\n",
       "        np.float64(0.007473611930214643),\n",
       "        np.float64(0.00013468700594029115),\n",
       "        np.float64(0.006065403172605938),\n",
       "        np.float64(0.004218520874352417),\n",
       "        np.float64(0.005016073936100433),\n",
       "        np.float64(0.0029996220472426173),\n",
       "        np.float64(0.0028981188675625555),\n",
       "        np.float64(0.0062871571215616096),\n",
       "        np.float64(0.004149146840150843)],\n",
       "       'learning_rate': [np.float64(0.008425207830322539),\n",
       "        np.float64(0.00833428565987012),\n",
       "        np.float64(0.007815328852925223),\n",
       "        np.float64(0.012525891552447417),\n",
       "        np.float64(0.008134916763452448),\n",
       "        np.float64(0.009036082870956554),\n",
       "        np.float64(0.012055051349477817),\n",
       "        np.float64(0.00970027000115131),\n",
       "        np.float64(0.006869037302955032),\n",
       "        np.float64(0.00877328453556303),\n",
       "        np.float64(0.009636476430964613),\n",
       "        np.float64(0.009903846111509065),\n",
       "        np.float64(0.004370588154508166),\n",
       "        np.float64(0.009501879513323307),\n",
       "        np.float64(0.008828936140820554),\n",
       "        np.float64(0.010185579597942872),\n",
       "        np.float64(0.006665305983589619),\n",
       "        np.float64(0.005331632381820419),\n",
       "        np.float64(0.010034859874378634),\n",
       "        np.float64(0.0061190012968415025)],\n",
       "       'max_depth': [np.float64(0.006599663291074443),\n",
       "        np.float64(0.008729754680404567),\n",
       "        np.float64(0.006217523331028379),\n",
       "        np.float64(0.011251807614920102),\n",
       "        np.float64(0.008379870059984364),\n",
       "        np.float64(0.00864098759787712),\n",
       "        np.float64(0.009797958971132708),\n",
       "        np.float64(0.007546079157920094),\n",
       "        np.float64(0.00511633372135751),\n",
       "        np.float64(0.007921382412163095),\n",
       "        np.float64(0.0067986926847903965),\n",
       "        np.float64(0.007733661733585418),\n",
       "        np.float64(0.009881841612310625),\n",
       "        np.float64(0.007508725083591221),\n",
       "        np.float64(0.00878155147217754),\n",
       "        np.float64(0.008565077011777906),\n",
       "        np.float64(0.006929512290888137),\n",
       "        np.float64(0.008591510865785893),\n",
       "        np.float64(0.007617857049836705),\n",
       "        np.float64(0.0036910137857288842)],\n",
       "       'min_samples_split': [np.float64(0.0),\n",
       "        np.float64(0.00013468700594026497),\n",
       "        np.float64(1.1102230246251565e-16),\n",
       "        np.float64(0.0),\n",
       "        np.float64(0.0),\n",
       "        np.float64(0.0),\n",
       "        np.float64(1.1102230246251565e-16),\n",
       "        np.float64(0.0),\n",
       "        np.float64(1.1102230246251565e-16),\n",
       "        np.float64(1.1102230246251565e-16),\n",
       "        np.float64(1.1102230246251565e-16),\n",
       "        np.float64(1.1102230246251565e-16),\n",
       "        np.float64(0.0),\n",
       "        np.float64(0.0),\n",
       "        np.float64(1.1102230246251565e-16),\n",
       "        np.float64(0.0),\n",
       "        np.float64(0.0),\n",
       "        np.float64(1.1102230246251565e-16),\n",
       "        np.float64(0.0),\n",
       "        np.float64(1.1102230246251565e-16)]},\n",
       "      'performance_data': {'n_estimators': {'50': np.float64(0.9125000000000002),\n",
       "        '100': np.float64(0.9187714285714286),\n",
       "        '200': np.float64(0.9237428571428573)},\n",
       "       'learning_rate': {'0.01': np.float64(0.9125000000000002),\n",
       "        '0.1': np.float64(0.9309428571428571),\n",
       "        '0.2': np.float64(0.9302285714285713)},\n",
       "       'max_depth': {'3': np.float64(0.9125000000000002),\n",
       "        '5': np.float64(0.9269285714285715),\n",
       "        '10': np.float64(0.9099142857142859)},\n",
       "       'min_samples_split': {'2': np.float64(0.9125000000000002),\n",
       "        '5': np.float64(0.9125000000000002),\n",
       "        '10': np.float64(0.9125142857142858)}},\n",
       "      'tuning_order': ['learning_rate',\n",
       "       'max_depth',\n",
       "       'n_estimators',\n",
       "       'min_samples_split']},\n",
       "     {'method': 'importance',\n",
       "      'cv': 5,\n",
       "      'n_subsamples': 10,\n",
       "      'subsample_size': 0.7,\n",
       "      'raw_importance_scores': {'n_estimators': np.float64(0.004460656872026009),\n",
       "       'learning_rate': np.float64(0.008620254890051835),\n",
       "       'max_depth': np.float64(0.0075570486052312326),\n",
       "       'min_samples_split': np.float64(4.4408920985006264e-17)},\n",
       "      'normalized_importance': {'n_estimators': np.float64(0.21613845518822514),\n",
       "       'learning_rate': np.float64(0.41768928404894434),\n",
       "       'max_depth': np.float64(0.3661722607628284),\n",
       "       'min_samples_split': np.float64(2.1518076493329615e-15)},\n",
       "      'sorted_importance': {'learning_rate': np.float64(0.41768928404894434),\n",
       "       'max_depth': np.float64(0.3661722607628284),\n",
       "       'n_estimators': np.float64(0.21613845518822514),\n",
       "       'min_samples_split': np.float64(2.1518076493329615e-15)},\n",
       "      'param_variations': {'n_estimators': [np.float64(0.005108439868507391),\n",
       "        np.float64(0.004447866194621434),\n",
       "        np.float64(0.0061383902502351395),\n",
       "        np.float64(0.004602227207851054),\n",
       "        np.float64(0.006251709867875152),\n",
       "        np.float64(0.003892291445777726),\n",
       "        np.float64(0.0036548151146874003),\n",
       "        np.float64(0.004282361654423517),\n",
       "        np.float64(0.002770307013786616),\n",
       "        np.float64(0.0034581601024946573)],\n",
       "       'learning_rate': [np.float64(0.00938335878901197),\n",
       "        np.float64(0.009723453029247542),\n",
       "        np.float64(0.009645828522503482),\n",
       "        np.float64(0.009768211031808308),\n",
       "        np.float64(0.008378339967661285),\n",
       "        np.float64(0.007757474172573033),\n",
       "        np.float64(0.008247745941494643),\n",
       "        np.float64(0.006988012524180032),\n",
       "        np.float64(0.0065951344888070815),\n",
       "        np.float64(0.009714990433230968)],\n",
       "       'max_depth': [np.float64(0.006499171700950014),\n",
       "        np.float64(0.00816620594973272),\n",
       "        np.float64(0.007239180271677193),\n",
       "        np.float64(0.010648087882285495),\n",
       "        np.float64(0.008194882086203165),\n",
       "        np.float64(0.00784779544580779),\n",
       "        np.float64(0.006307371619389702),\n",
       "        np.float64(0.006904191411805261),\n",
       "        np.float64(0.0062679791400358465),\n",
       "        np.float64(0.007495620544425137)],\n",
       "       'min_samples_split': [np.float64(0.0),\n",
       "        np.float64(1.1102230246251565e-16),\n",
       "        np.float64(0.0),\n",
       "        np.float64(0.0),\n",
       "        np.float64(1.1102230246251565e-16),\n",
       "        np.float64(0.0),\n",
       "        np.float64(0.0),\n",
       "        np.float64(0.0),\n",
       "        np.float64(1.1102230246251565e-16),\n",
       "        np.float64(1.1102230246251565e-16)]},\n",
       "      'performance_data': {'n_estimators': {'50': np.float64(0.9143294907339852),\n",
       "        '100': np.float64(0.9196985678847638),\n",
       "        '200': np.float64(0.9250258489504075)},\n",
       "       'learning_rate': {'0.01': np.float64(0.9143294907339852),\n",
       "        '0.1': np.float64(0.9325171457755725),\n",
       "        '0.2': np.float64(0.9326599612265744)},\n",
       "       'max_depth': {'3': np.float64(0.9143294907339852),\n",
       "        '5': np.float64(0.9306188530570554),\n",
       "        '10': np.float64(0.9153500239728171)},\n",
       "       'min_samples_split': {'2': np.float64(0.9143294907339852),\n",
       "        '5': np.float64(0.9143294907339852),\n",
       "        '10': np.float64(0.9143294907339852)}},\n",
       "      'tuning_order': ['learning_rate',\n",
       "       'max_depth',\n",
       "       'n_estimators',\n",
       "       'min_samples_split']}]},\n",
       "   'importance_scores': {'n_estimators': np.float64(0.21921755186879124),\n",
       "    'learning_rate': np.float64(0.4126237354523683),\n",
       "    'max_depth': np.float64(0.36799936986115206),\n",
       "    'min_samples_split': np.float64(0.0001593428176885251)},\n",
       "   'sorted_importance': {'learning_rate': np.float64(0.4126237354523683),\n",
       "    'max_depth': np.float64(0.36799936986115206),\n",
       "    'n_estimators': np.float64(0.21921755186879124),\n",
       "    'min_samples_split': np.float64(0.0001593428176885251)},\n",
       "   'tuning_order': ['learning_rate',\n",
       "    'max_depth',\n",
       "    'n_estimators',\n",
       "    'min_samples_split']}}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['hyperparameters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Run robustness tests\n",
    "print(\"\\nRunning quick robustness tests...\")\n",
    "quick_results = run_robustness_tests(dataset, config_name=\"quick\", verbose=False)\n",
    "    \n",
    "print(\"\\nRunning full robustness tests...\")\n",
    "full_results = run_robustness_tests(dataset, config_name=\"full\", verbose=False)\n",
    "\n",
    "\n",
    "    # Run robustness tests\n",
    "print(\"\\nRunning quick robustness tests...\")\n",
    "quick_results = run_uncertainty_tests(dataset, config_name=\"quick\", verbose=False)\n",
    "    \n",
    "print(\"\\nRunning full robustness tests...\")\n",
    "full_results = run_uncertainty_tests(dataset, config_name=\"full\", verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertainty = UncertaintySuite(dataset, verbose=True)\n",
    "uncertainty.config('quick')\n",
    "results = uncertainty.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robustness_results = experiment.get_robustness_results()\n",
    "# Verifica se os resultados existem\n",
    "print(\"Visualizações disGuponíveis:\", list(experiment.get_robustness_visualizations().keys()))\n",
    "# Agora tente mostrar o gráfico\n",
    "comparison_plot = experiment.plot_robustness_comparison()\n",
    "if comparison_plot:\n",
    "    comparison_plot.show()\n",
    "else:\n",
    "    print(\"Visualização ainda não disponível\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.alternative_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Initialize the Experiment class\n",
    "experiment = Experiment(\n",
    "    dataset=dataset,\n",
    "    experiment_type=\"binary_classification\", \n",
    "    auto_fit=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comprehensive_results = experiment.get_comprehensive_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comprehensive_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obter e avaliar os modelos alternativos\n",
    "alternative_models = experiment.get_alternative_models()\n",
    "print(f\"Número de modelos alternativos criados: {len(alternative_models)}\")\n",
    "\n",
    "# Ver quais modelos foram criados\n",
    "for name, model in alternative_models.items():\n",
    "    print(f\"- {name}: {type(model).__name__}\")\n",
    "\n",
    "# Comparar o desempenho dos modelos\n",
    "comparison_results = experiment.evaluate_alternative_models(dataset='test')\n",
    "print(\"\\nComparação de desempenho dos modelos no conjunto de teste:\")\n",
    "print(comparison_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alternative_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(experiment.distillation_model.__class__.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import matplotlib as plt\n",
    "\n",
    "# Filtrar os avisos relacionados a feature names\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, \n",
    "                       message=\"X does not have valid feature names\")\n",
    "\n",
    "# # Criar suite de robustez e configurar\n",
    "# print(\"\\nExecutando testes de robustez...\")\n",
    "# suite = RobustnessSuite(dataset, verbose=True)\n",
    "\n",
    "# # Método 1: Configurar e executar\n",
    "# results_quick = suite.config('quick').run()\n",
    "# print(f\"Pontuação de robustez (quick): {results_quick['robustness_scores']['overall_score']:.3f}\")\n",
    "\n",
    "# # Método 2: Configurar para teste completo\n",
    "# results_full = suite.config('full').run()\n",
    "# print(f\"Pontuação de robustez (full): {results_full['robustness_scores']['overall_score']:.3f}\")\n",
    "\n",
    "# # Usuários avançados ainda podem personalizar completamente os testes\n",
    "# custom_config = {\n",
    "#     'feature_perturbation': [\n",
    "#         {'type': 'noise', 'params': {'feature_name': 'mean radius', 'level': 0.3}}\n",
    "#     ],\n",
    "#     'outlier_robustness': [\n",
    "#         {'type': 'isolation_forest', 'params': {'contamination': 0.15}}\n",
    "#     ]\n",
    "# }\n",
    "\n",
    "# # Executar com configuração personalizada\n",
    "# results_custom = suite.run_custom_test(custom_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepbridge.validation.wrappers.robustness_suite import RobustnessSuite\n",
    "\n",
    "# Inicializar com um conjunto de dados\n",
    "suite = RobustnessSuite(dataset, verbose=True)\n",
    "\n",
    "# Usar configuração 'full' padrão\n",
    "results_full = suite.config('full').run()\n",
    "\n",
    "# Salvar relatório HTML\n",
    "suite.save_report(\"robustness_report_full.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suite = RobustnessSuite(dataset, verbose=True)\n",
    "results_full = suite.config('full').run()\n",
    "\n",
    "\n",
    "\n",
    "suite.save_report(\"report_quick.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_full\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suite.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "suite.save_report(\"report1.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suite.config('quick')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acessar resultados organizados\n",
    "robustness_results = results_full['results']\n",
    "\n",
    "# Acessar visualizações\n",
    "visualizations = robustness_results['visualizations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.genmod.families import Binomial\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Configurar semente para reprodutibilidade\n",
    "np.random.seed(42)\n",
    "\n",
    "# Gerar dados sintéticos para classificação\n",
    "def gerar_dados_classificacao(n_amostras=1000, n_features=2):\n",
    "    \"\"\"\n",
    "    Gera conjunto de dados sintéticos para classificação binária.\n",
    "    \"\"\"\n",
    "    # Gerar features com alguma correlação\n",
    "    covariancia = np.array([[1.0, 0.5], [0.5, 1.0]])\n",
    "    X = np.random.multivariate_normal(mean=[0, 0], cov=covariancia, size=n_amostras)\n",
    "    \n",
    "    # Adicionar mais features independentes se necessário\n",
    "    if n_features > 2:\n",
    "        X_extra = np.random.normal(size=(n_amostras, n_features-2))\n",
    "        X = np.hstack((X, X_extra))\n",
    "    \n",
    "    # Gerar coeficientes reais\n",
    "    beta = np.random.uniform(-1, 1, size=n_features)\n",
    "    intercept = 0.5\n",
    "    \n",
    "    # Calcular log-odds\n",
    "    log_odds = intercept + np.dot(X, beta)\n",
    "    \n",
    "    # Transformar em probabilidades\n",
    "    p = 1 / (1 + np.exp(-log_odds))\n",
    "    \n",
    "    # Gerar rótulos binários\n",
    "    y = np.random.binomial(1, p)\n",
    "    \n",
    "    return X, y, np.append(intercept, beta)\n",
    "\n",
    "# Gerar dados\n",
    "X, y, coef_verdadeiros = gerar_dados_classificacao(n_amostras=1000, n_features=3)\n",
    "\n",
    "# Dividir em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Padronizar os dados para o modelo sklearn\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# ======================================================\n",
    "# 1. MODELO GLM USANDO STATSMODELS\n",
    "# ======================================================\n",
    "print(\"=\"*50)\n",
    "print(\"1. MODELO GLM PARA CLASSIFICAÇÃO (STATSMODELS)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Adicionar constante para o intercepto\n",
    "X_train_sm = sm.add_constant(X_train)\n",
    "X_test_sm = sm.add_constant(X_test)\n",
    "\n",
    "# Ajustar GLM com família binomial e função de ligação logit\n",
    "glm_model = sm.GLM(y_train, X_train_sm, family=Binomial())\n",
    "glm_results = glm_model.fit()\n",
    "\n",
    "# Resumo do modelo\n",
    "print(glm_results.summary())\n",
    "\n",
    "# Fazer previsões (probabilidades)\n",
    "y_pred_proba_glm = glm_results.predict(X_test_sm)\n",
    "\n",
    "# Converter probabilidades para classes (0 ou 1)\n",
    "y_pred_glm = (y_pred_proba_glm >= 0.5).astype(int)\n",
    "\n",
    "# Avaliar o modelo GLM\n",
    "accuracy_glm = accuracy_score(y_test, y_pred_glm)\n",
    "print(f\"\\nAcurácia do modelo GLM: {accuracy_glm:.4f}\")\n",
    "\n",
    "# Matriz de confusão\n",
    "conf_matrix_glm = confusion_matrix(y_test, y_pred_glm)\n",
    "print(\"\\nMatriz de Confusão (GLM):\")\n",
    "print(conf_matrix_glm)\n",
    "\n",
    "# Relatório de classificação\n",
    "print(\"\\nRelatório de Classificação (GLM):\")\n",
    "print(classification_report(y_test, y_pred_glm))\n",
    "\n",
    "# ======================================================\n",
    "# 2. REGRESSÃO LOGÍSTICA USANDO SCIKIT-LEARN\n",
    "# ======================================================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"2. REGRESSÃO LOGÍSTICA (SCIKIT-LEARN)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Ajustar modelo de regressão logística\n",
    "logreg_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "logreg_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Fazer previsões (probabilidades)\n",
    "y_pred_proba_logreg = logreg_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Converter probabilidades para classes (0 ou 1)\n",
    "y_pred_logreg = (y_pred_proba_logreg >= 0.5).astype(int)\n",
    "\n",
    "# Avaliar o modelo de regressão logística\n",
    "accuracy_logreg = accuracy_score(y_test, y_pred_logreg)\n",
    "print(f\"\\nAcurácia da Regressão Logística: {accuracy_logreg:.4f}\")\n",
    "\n",
    "# Matriz de confusão\n",
    "conf_matrix_logreg = confusion_matrix(y_test, y_pred_logreg)\n",
    "print(\"\\nMatriz de Confusão (Regressão Logística):\")\n",
    "print(conf_matrix_logreg)\n",
    "\n",
    "# Relatório de classificação\n",
    "print(\"\\nRelatório de Classificação (Regressão Logística):\")\n",
    "print(classification_report(y_test, y_pred_logreg))\n",
    "\n",
    "# ======================================================\n",
    "# 3. COMPARAÇÃO DOS MODELOS\n",
    "# ======================================================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"3. COMPARAÇÃO DOS MODELOS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Comparar coeficientes\n",
    "print(\"\\nCoeficientes verdadeiros:\", coef_verdadeiros)\n",
    "print(\"Coeficientes GLM:\", glm_results.params)\n",
    "print(\"Coeficientes Regressão Logística:\", \n",
    "      np.append(logreg_model.intercept_[0], logreg_model.coef_[0]))\n",
    "\n",
    "# Calcular o ROC AUC para ambos os modelos\n",
    "fpr_glm, tpr_glm, _ = roc_curve(y_test, y_pred_proba_glm)\n",
    "roc_auc_glm = auc(fpr_glm, tpr_glm)\n",
    "\n",
    "fpr_logreg, tpr_logreg, _ = roc_curve(y_test, y_pred_proba_logreg)\n",
    "roc_auc_logreg = auc(fpr_logreg, tpr_logreg)\n",
    "\n",
    "print(f\"\\nROC AUC (GLM): {roc_auc_glm:.4f}\")\n",
    "print(f\"ROC AUC (Regressão Logística): {roc_auc_logreg:.4f}\")\n",
    "\n",
    "# ======================================================\n",
    "# 4. VISUALIZAÇÃO\n",
    "# ======================================================\n",
    "\n",
    "# Plotar curvas ROC\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(fpr_glm, tpr_glm, 'b-', linewidth=2, label=f'GLM (AUC = {roc_auc_glm:.3f})')\n",
    "plt.plot(fpr_logreg, tpr_logreg, 'r--', linewidth=2, label=f'Regressão Logística (AUC = {roc_auc_logreg:.3f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=1)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Taxa de Falso Positivo')\n",
    "plt.ylabel('Taxa de Verdadeiro Positivo')\n",
    "plt.title('Curva ROC - Comparação dos Modelos')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('comparacao_roc_curve.png')\n",
    "\n",
    "# Visualizar as probabilidades preditas\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(y_pred_proba_glm, y_pred_proba_logreg, alpha=0.5)\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=1)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('Probabilidades GLM')\n",
    "plt.ylabel('Probabilidades Regressão Logística')\n",
    "plt.title('Comparação das Probabilidades Preditas pelos Modelos')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('comparacao_probabilidades.png')\n",
    "\n",
    "# Exemplo de aplicação: Fazer previsão para uma nova observação\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"5. EXEMPLO DE APLICAÇÃO\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Criar exemplo de nova observação\n",
    "nova_obs = np.array([[0.5, -0.3, 0.8]])\n",
    "nova_obs_scaled = scaler.transform(nova_obs)\n",
    "\n",
    "# Adicionar constante para o GLM\n",
    "nova_obs_sm = sm.add_constant(nova_obs)\n",
    "\n",
    "# Fazer previsões\n",
    "prob_glm = glm_results.predict(nova_obs_sm)[0]\n",
    "prob_logreg = logreg_model.predict_proba(nova_obs_scaled)[0, 1]\n",
    "\n",
    "print(f\"\\nNova observação: {nova_obs[0]}\")\n",
    "print(f\"Probabilidade predita pelo GLM: {prob_glm:.4f}\")\n",
    "print(f\"Probabilidade predita pela Regressão Logística: {prob_logreg:.4f}\")\n",
    "print(f\"Classe predita pelo GLM: {1 if prob_glm >= 0.5 else 0}\")\n",
    "print(f\"Classe predita pela Regressão Logística: {1 if prob_logreg >= 0.5 else 0}\")\n",
    "\n",
    "# ======================================================\n",
    "# FUNÇÕES PARA USO PRÁTICO DOS MODELOS\n",
    "# ======================================================\n",
    "\n",
    "def prever_probabilidade_glm(modelo, nova_obs, adicionar_constante=True):\n",
    "    \"\"\"\n",
    "    Faz previsão de probabilidade usando o modelo GLM.\n",
    "    \n",
    "    Args:\n",
    "        modelo: Modelo GLM treinado\n",
    "        nova_obs: Array numpy com features da nova observação\n",
    "        adicionar_constante: Se True, adiciona coluna de 1's para o intercepto\n",
    "        \n",
    "    Returns:\n",
    "        Probabilidade de pertencer à classe positiva\n",
    "    \"\"\"\n",
    "    if adicionar_constante:\n",
    "        nova_obs = sm.add_constant(nova_obs)\n",
    "    return modelo.predict(nova_obs)\n",
    "\n",
    "def prever_probabilidade_logreg(modelo, nova_obs, scaler=None):\n",
    "    \"\"\"\n",
    "    Faz previsão de probabilidade usando o modelo de Regressão Logística.\n",
    "    \n",
    "    Args:\n",
    "        modelo: Modelo de regressão logística treinado\n",
    "        nova_obs: Array numpy com features da nova observação\n",
    "        scaler: Scaler usado para padronizar os dados, se aplicável\n",
    "        \n",
    "    Returns:\n",
    "        Probabilidade de pertencer à classe positiva\n",
    "    \"\"\"\n",
    "    if scaler is not None:\n",
    "        nova_obs = scaler.transform(nova_obs)\n",
    "    return modelo.predict_proba(nova_obs)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifique primeiro se a visualização existe\n",
    "if 'feature_importance' in visualizations:\n",
    "    with open('feature_importance.html', 'w') as f:\n",
    "        f.write(visualizations['feature_importance'])\n",
    "else:\n",
    "    print(\"Visualização 'feature_importance' não disponível.\")\n",
    "\n",
    "    \n",
    "# Exemplo: Exibir uma visualização específica em um notebook\n",
    "from IPython.display import HTML\n",
    "HTML(visualizations['robustness_summary'])\n",
    "\n",
    "# Exemplo: Salvar uma visualização em um arquivo HTML\n",
    "with open('feature_importance.html', 'w') as f:\n",
    "    f.write(visualizations['feature_importance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_df = Synthesize(\n",
    "    dataset=dataset,\n",
    "    method='gaussian',\n",
    "    num_samples=1000,  \n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepbridge.synthetic.metrics.similarity import calculate_similarity\n",
    "\n",
    "# Acesse os dados originais e os dados sintéticos\n",
    "original_data = synthetic_df.original_data\n",
    "synthetic_data = synthetic_df.data\n",
    "\n",
    "# Calcule a similaridade\n",
    "similarity_scores = calculate_similarity(\n",
    "    original_data=original_data,\n",
    "    synthetic_data=synthetic_data,\n",
    "    # Parâmetros opcionais:\n",
    "    metric='euclidean',         # Métrica de distância a ser usada\n",
    "    n_neighbors=5,              # Número de vizinhos a considerar\n",
    "    sample_size=10000,          # Tamanho máximo da amostra a usar\n",
    "    random_state=42,            # Seed para reprodutibilidade\n",
    "    verbose=True                # Mostrar informações de progresso\n",
    ")\n",
    "\n",
    "# similarity_scores é um pandas.Series com um score para cada amostra sintética\n",
    "# Valores mais próximos de 1 indicam maior similaridade (mais parecidos)\n",
    "# Valores mais próximos de 0 indicam menor similaridade (mais diferentes)\n",
    "\n",
    "# Estatísticas de similaridade\n",
    "print(f\"Similaridade média: {similarity_scores.mean():.4f}\")\n",
    "print(f\"Similaridade mínima: {similarity_scores.min():.4f}\")\n",
    "print(f\"Similaridade máxima: {similarity_scores.max():.4f}\")\n",
    "\n",
    "# Você também pode visualizar a distribuição dos scores\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(similarity_scores, bins=50)\n",
    "plt.title('Distribuição dos Scores de Similaridade')\n",
    "plt.xlabel('Score de Similaridade')\n",
    "plt.ylabel('Frequência')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepbridge.synthetic.metrics.similarity import filter_by_similarity\n",
    "\n",
    "# Filtra dados com similaridade acima de um limiar\n",
    "filtered_data = filter_by_similarity(\n",
    "    original_data=original_data,\n",
    "    synthetic_data=synthetic_data,\n",
    "    threshold=0.9,              # Remove samples com similaridade >= 0.9\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"Amostras originais: {len(synthetic_data)}\")\n",
    "print(f\"Amostras após filtragem: {len(filtered_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliação da diversidade dos dados sintéticos\n",
    "from deepbridge.synthetic.metrics.similarity import calculate_diversity\n",
    "\n",
    "diversity_metrics = calculate_diversity(\n",
    "    synthetic_data=synthetic_df.data,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Avaliação das diferenças de correlação entre variáveis numéricas\n",
    "from deepbridge.synthetic.metrics.similarity import evaluate_pairwise_correlations\n",
    "\n",
    "correlation_analysis = evaluate_pairwise_correlations(\n",
    "    original_data=original_data,\n",
    "    synthetic_data=synthetic_data\n",
    ")\n",
    "\n",
    "# Mostrar pares de colunas com maiores diferenças de correlação\n",
    "print(correlation_analysis.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from deepbridge.synthetic.metrics.similarity import plot_distribution_comparison\n",
    "    \n",
    "    fig = plot_distribution_comparison(\n",
    "        original_data=original_data,\n",
    "        synthetic_data=synthetic_data\n",
    "    )\n",
    "    plt.show()\n",
    "except ImportError:\n",
    "    print(\"Módulo de visualização não disponível\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando um relatório HTML\n",
    "report_path = synthetic_df.save_report(\"relatorio_dados_sinteticos.html\")\n",
    "print(f\"Relatório gerado e salvo em: {report_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = synthetic_df.data.drop('target', axis=1)\n",
    "y = synthetic_df.data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 6. Avaliação do modelo\n",
    "# accuracy = accuracy_score(y, y_pred)\n",
    "# report = classification_report(y, y_pred)\n",
    "\n",
    "# print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String de conexão (sem senha): mysql+mysqlconnector://root:***@127.0.0.1:3306/gevao\n",
      "Conexão com o banco de dados 'gevao' estabelecida com sucesso!\n",
      "Lendo o arquivo CSV: /home/guhaase/projetos/DeepBridge/examples/Synthetic/EST_MOD_ANA_MON.csv\n",
      "Arquivo CSV lido com sucesso. Shape: (40, 28)\n",
      "Removendo colunas 'Unnamed': ['Unnamed: 0']\n",
      "Colunas removidas. Novo shape: (40, 27)\n",
      "Enviando dados para a tabela 'EST_MOD_ANA_MON' no MySQL...\n",
      "Dados enviados com sucesso para a tabela 'EST_MOD_ANA_MON'.\n",
      "Verificação: A tabela 'EST_MOD_ANA_MON' contém 40 linhas.\n",
      "Conexão com o banco de dados fechada.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "import sys # Para sair em caso de erro crítico\n",
    "\n",
    "# --- 1. Configurações ---\n",
    "DB_HOST = '127.0.0.1'\n",
    "DB_PORT = 3306 # Porta geralmente é um inteiro\n",
    "DB_USER = 'root'\n",
    "DB_PASSWORD = 'rootpass'\n",
    "DB_NAME = 'gevao'\n",
    "CSV_FILE_PATH = '/home/guhaase/projetos/DeepBridge/examples/Synthetic/EST_MOD_ANA_MON.csv'\n",
    "TABLE_NAME = 'EST_MOD_ANA_MON' # Nome da tabela no MySQL\n",
    "\n",
    "# --- 2. Montar a String de Conexão SQLAlchemy ---\n",
    "# Formato: mysql+mysqlconnector://user:password@host:port/database\n",
    "try:\n",
    "    db_connection_str = f'mysql+mysqlconnector://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}'\n",
    "    print(f\"String de conexão (sem senha): mysql+mysqlconnector://{DB_USER}:***@{DB_HOST}:{DB_PORT}/{DB_NAME}\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao formatar a string de conexão: {e}\")\n",
    "    sys.exit(1) # Sai do script se não conseguir nem formatar a string\n",
    "\n",
    "# --- 3. Criar o Engine de Conexão ---\n",
    "engine = None # Inicializa engine como None\n",
    "try:\n",
    "    engine = create_engine(db_connection_str)\n",
    "    # Tenta conectar para verificar as credenciais e a disponibilidade do DB\n",
    "    with engine.connect() as connection:\n",
    "        print(f\"Conexão com o banco de dados '{DB_NAME}' estabelecida com sucesso!\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao conectar ao banco de dados MySQL: {e}\")\n",
    "    print(\"Verifique se o servidor MySQL está rodando, as credenciais estão corretas e o banco de dados existe.\")\n",
    "    sys.exit(1) # Sai do script se a conexão falhar\n",
    "\n",
    "# --- 4. Ler o arquivo CSV ---\n",
    "try:\n",
    "    print(f\"Lendo o arquivo CSV: {CSV_FILE_PATH}\")\n",
    "    df = pd.read_csv(CSV_FILE_PATH)\n",
    "    print(f\"Arquivo CSV lido com sucesso. Shape: {df.shape}\")\n",
    "\n",
    "    # Pré-tratamento: Remover colunas \"Unnamed\" se existirem (opcional, mas boa prática)\n",
    "    unnamed_cols = [col for col in df.columns if col.startswith('Unnamed')]\n",
    "    if unnamed_cols:\n",
    "        print(f\"Removendo colunas 'Unnamed': {unnamed_cols}\")\n",
    "        df = df.drop(columns=unnamed_cols)\n",
    "        print(f\"Colunas removidas. Novo shape: {df.shape}\")\n",
    "\n",
    "    # Opcional: Limpar nomes de colunas para serem compatíveis com SQL (ex: remover espaços, caracteres especiais)\n",
    "    # df.columns = df.columns.str.replace(' ', '_', regex=False).str.replace('[^A-Za-z0-9_]+', '', regex=True)\n",
    "    # print(\"Nomes das colunas após limpeza básica:\", df.columns.tolist())\n",
    "\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Erro: Arquivo CSV não encontrado em '{CSV_FILE_PATH}'\")\n",
    "    if engine:\n",
    "        engine.dispose() # Libera recursos do engine se ele foi criado\n",
    "    sys.exit(1)\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao ler ou pré-processar o arquivo CSV: {e}\")\n",
    "    if engine:\n",
    "        engine.dispose()\n",
    "    sys.exit(1)\n",
    "\n",
    "# --- 5. Enviar o DataFrame para o MySQL ---\n",
    "try:\n",
    "    print(f\"Enviando dados para a tabela '{TABLE_NAME}' no MySQL...\")\n",
    "    # Usando 'replace': Se a tabela existir, ela será excluída e recriada.\n",
    "    # Use 'append' se quiser adicionar os dados a uma tabela existente.\n",
    "    # Use 'fail' (padrão) se não quiser sobrescrever e gerar erro se a tabela existir.\n",
    "    df.to_sql(name=TABLE_NAME, con=engine, if_exists='replace', index=False, chunksize=1000)\n",
    "    # chunksize=1000 ajuda a enviar dados em lotes, útil para tabelas grandes\n",
    "\n",
    "    print(f\"Dados enviados com sucesso para a tabela '{TABLE_NAME}'.\")\n",
    "\n",
    "    # Verifica quantas linhas foram inseridas (opcional)\n",
    "    with engine.connect() as connection:\n",
    "        result = connection.execute(text(f\"SELECT COUNT(*) FROM {TABLE_NAME}\"))\n",
    "        count = result.scalar()\n",
    "        print(f\"Verificação: A tabela '{TABLE_NAME}' contém {count} linhas.\")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao enviar dados para o MySQL: {e}\")\n",
    "    print(\"Verifique permissões do usuário, tipos de dados incompatíveis ou outros problemas no DB.\")\n",
    "\n",
    "finally:\n",
    "    # --- 6. Fechar a Conexão (liberar recursos) ---\n",
    "    if engine:\n",
    "        engine.dispose()\n",
    "        print(\"Conexão com o banco de dados fechada.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepbridge_homol",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
