"""
Exemplo Completo: An√°lise de Fairness End-to-End
=================================================

Este exemplo demonstra o fluxo completo de an√°lise de fairness no DeepBridge,
desde a prepara√ß√£o dos dados at√© a gera√ß√£o de relat√≥rios HTML interativos.

Cen√°rio: Modelo de Aprova√ß√£o de Cr√©dito
- Dataset sint√©tico com vi√©s demogr√°fico
- Atributos sens√≠veis: gender, race, age_group
- Objetivo: Detectar e quantificar vi√©s no modelo

Autor: DeepBridge Team
Data: 2025-11-03
"""

import numpy as np
import pandas as pd
from pathlib import Path
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split

# Imports DeepBridge
from deepbridge.core.db_data import DBDataset
from deepbridge.core.experiment.experiment import Experiment
from deepbridge.validation.wrappers import FairnessSuite
from deepbridge.validation.fairness import FairnessVisualizer

# ============================================================================
# PARTE 1: PREPARA√á√ÉO DOS DADOS
# ============================================================================

print("=" * 80)
print("EXEMPLO COMPLETO: AN√ÅLISE DE FAIRNESS NO DEEPBRIDGE")
print("=" * 80)

print("\nüìä PARTE 1: Prepara√ß√£o dos Dados")
print("-" * 80)

# Configurar seed para reprodutibilidade
np.random.seed(42)
n_samples = 2000

# Gerar features num√©ricas
print("\n1. Gerando features num√©ricas...")
income = np.random.lognormal(10.5, 0.5, n_samples)  # Renda anual
credit_score = np.random.normal(700, 100, n_samples)  # Score de cr√©dito
debt_ratio = np.random.beta(2, 5, n_samples)  # Raz√£o d√≠vida/renda
employment_years = np.random.gamma(2, 3, n_samples)  # Anos de emprego
savings = np.random.exponential(10000, n_samples)  # Poupan√ßa

# Gerar atributos protegidos/sens√≠veis
print("2. Gerando atributos protegidos...")
gender = np.random.choice(['Male', 'Female'], n_samples, p=[0.55, 0.45])
race = np.random.choice(
    ['White', 'Black', 'Hispanic', 'Asian'],
    n_samples,
    p=[0.60, 0.20, 0.15, 0.05]
)
age = np.random.normal(40, 15, n_samples)
age_group = pd.cut(
    age,
    bins=[0, 25, 40, 60, 100],
    labels=['Young', 'Adult', 'Middle-Aged', 'Senior']
).astype(str)

# Criar target com VI√âS INTENCIONAL (para demonstra√ß√£o)
print("3. Gerando target com vi√©s demogr√°fico...")
print("   ‚ö†Ô∏è  Vi√©s intencional para demonstra√ß√£o:")
print("   - Homens: +12% probabilidade de aprova√ß√£o")
print("   - Brancos: +10% probabilidade de aprova√ß√£o")
print("   - Jovens: -8% probabilidade de aprova√ß√£o")

y = np.zeros(n_samples)
for i in range(n_samples):
    # Probabilidade base (features financeiras)
    base_prob = (
        0.3 +
        (credit_score[i] - 600) / 200 * 0.3 +
        (1 - debt_ratio[i]) * 0.2 +
        min(employment_years[i] / 10, 1) * 0.1
    )

    # Adicionar VI√âS demogr√°fico (N√ÉO deve ser feito na pr√°tica!)
    bias = 0
    if gender[i] == 'Male':
        bias += 0.12  # Vi√©s de g√™nero
    if race[i] == 'White':
        bias += 0.10  # Vi√©s racial
    if age_group[i] == 'Young':
        bias -= 0.08  # Vi√©s et√°rio

    final_prob = np.clip(base_prob + bias, 0, 1)
    y[i] = 1 if np.random.rand() < final_prob else 0

# Criar DataFrame
df = pd.DataFrame({
    'income': income,
    'credit_score': credit_score,
    'debt_ratio': debt_ratio,
    'employment_years': employment_years,
    'savings': savings,
    'gender': gender,
    'race': race,
    'age_group': age_group,
    'approved': y
})

print(f"\n‚úì Dataset criado: {df.shape}")
print(f"  - Features num√©ricas: {['income', 'credit_score', 'debt_ratio', 'employment_years', 'savings']}")
print(f"  - Atributos protegidos: {['gender', 'race', 'age_group']}")
print(f"  - Taxa de aprova√ß√£o: {y.mean():.1%}")
print(f"  - Taxa por g√™nero:")
for g in df['gender'].unique():
    rate = df[df['gender'] == g]['approved'].mean()
    print(f"    {g}: {rate:.1%}")

# ============================================================================
# PARTE 2: TREINAMENTO DO MODELO
# ============================================================================

print("\n" + "=" * 80)
print("ü§ñ PARTE 2: Treinamento do Modelo")
print("-" * 80)

# Separar features (SEM atributos protegidos) e target
feature_cols = ['income', 'credit_score', 'debt_ratio', 'employment_years', 'savings']
X = df[feature_cols]
y = df['approved']

print(f"\n1. Separando train/test (80/20)...")
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print(f"   Train: {X_train.shape[0]} samples")
print(f"   Test: {X_test.shape[0]} samples")

# Treinar modelo
print("\n2. Treinando Random Forest...")
model = RandomForestClassifier(
    n_estimators=100,
    max_depth=10,
    random_state=42,
    class_weight='balanced'
)
model.fit(X_train, y_train)

# Avaliar performance
train_acc = model.score(X_train, y_train)
test_acc = model.score(X_test, y_test)

print(f"   ‚úì Acur√°cia (train): {train_acc:.3f}")
print(f"   ‚úì Acur√°cia (test): {test_acc:.3f}")

# ============================================================================
# PARTE 3: CRIAR DBDATASET
# ============================================================================

print("\n" + "=" * 80)
print("üì¶ PARTE 3: Cria√ß√£o do DBDataset")
print("-" * 80)

print("\n1. Criando DBDataset com dados completos...")
dataset = DBDataset(
    data=df,
    target_column='approved',
    model=model
)

print(f"   ‚úì Dataset shape: {df.shape}")
print(f"   ‚úì Model type: {type(model).__name__}")
print(f"   ‚úì Target: approved")

# ============================================================================
# PARTE 4: AN√ÅLISE DE FAIRNESS COM EXPERIMENT (RECOMENDADO)
# ============================================================================

print("\n" + "=" * 80)
print("üîç PARTE 4: An√°lise de Fairness via Experiment (M√©todo Recomendado)")
print("-" * 80)

# M√©todo 4.1: Com protected_attributes EXPL√çCITOS (RECOMENDADO PARA PRODU√á√ÉO)
print("\n4.1 - Com protected_attributes expl√≠citos:")
print("      (Recomendado para produ√ß√£o)")

experiment = Experiment(
    dataset=dataset,
    experiment_type="binary_classification",
    tests=["fairness"],
    protected_attributes=['gender', 'race', 'age_group'],  # Expl√≠cito
    test_size=0.2,
    random_state=42
)

print(f"   ‚úì Experiment criado")
print(f"   ‚úì Protected attributes: {experiment.protected_attributes}")

# Executar testes de fairness (config 'full' = 15 m√©tricas + threshold analysis)
print("\n   Executando testes (config='full')...")
fairness_result = experiment.run_fairness_tests(config='full')

print(f"   ‚úì Testes conclu√≠dos")
print(f"\n   üìä RESULTADOS:")
print(f"      Overall Fairness Score: {fairness_result.overall_fairness_score:.3f}")
print(f"      Critical Issues: {len(fairness_result.critical_issues)}")
print(f"      Warnings: {len(fairness_result.warnings)}")
print(f"      Protected Attributes: {fairness_result.protected_attributes}")

# Exibir issues
if fairness_result.critical_issues:
    print(f"\n   ‚ö†Ô∏è  CRITICAL ISSUES:")
    for issue in fairness_result.critical_issues[:3]:  # Primeiros 3
        print(f"      - {issue}")

if fairness_result.warnings:
    print(f"\n   ‚ö†Ô∏è  WARNINGS:")
    for warning in fairness_result.warnings[:3]:  # Primeiros 3
        print(f"      - {warning}")

# Gerar relat√≥rio HTML
output_dir = Path('./fairness_example_output')
output_dir.mkdir(exist_ok=True)

print(f"\n   Gerando relat√≥rio HTML...")
report_path = fairness_result.save_html(
    file_path=str(output_dir / 'fairness_report_experiment.html'),
    model_name='Credit Approval Model v1.0',
    report_type='interactive'  # Formato interativo como outros m√≥dulos
)

print(f"   ‚úì Relat√≥rio gerado: {report_path}")
print(f"   üìÅ Tamanho: {Path(report_path).stat().st_size / 1024:.1f} KB")

# M√©todo 4.2: Com AUTO-DETEC√á√ÉO (PARA EXPLORA√á√ÉO R√ÅPIDA)
print("\n4.2 - Com auto-detec√ß√£o:")
print("      (√ötil para explora√ß√£o r√°pida)")

experiment_auto = Experiment(
    dataset=dataset,
    experiment_type="binary_classification",
    tests=["fairness"],  # SEM protected_attributes
    test_size=0.2,
    random_state=42
)

print(f"   ‚úì Auto-detectado: {experiment_auto.protected_attributes}")
print(f"   ‚ö†Ô∏è  Para produ√ß√£o, sempre especifique explicitamente!")

# ============================================================================
# PARTE 5: AN√ÅLISE DE FAIRNESS COM FAIRNESSSUITE (AVAN√áADO)
# ============================================================================

print("\n" + "=" * 80)
print("üî¨ PARTE 5: An√°lise Avan√ßada com FairnessSuite")
print("-" * 80)

# Comparar diferentes configura√ß√µes
print("\n5.1 - Comparando configura√ß√µes (quick/medium/full):")

configs = {
    'quick': 'R√°pido (2 m√©tricas)',
    'medium': 'M√©dio (5 m√©tricas + pr√©-treino)',
    'full': 'Completo (15 m√©tricas + threshold)'
}

suite_results = {}

for config_name, description in configs.items():
    print(f"\n   Executando config '{config_name}': {description}...")

    fairness_suite = FairnessSuite(
        dataset=dataset,
        protected_attributes=['gender', 'race', 'age_group']
    )

    results = fairness_suite.config(config_name).run()
    suite_results[config_name] = results

    score = results.get('overall_fairness_score', 0)
    print(f"   ‚úì Score: {score:.3f}")

    # Gerar relat√≥rio para cada config
    from deepbridge.core.experiment.report.report_manager import ReportManager
    report_manager = ReportManager()

    report_path = report_manager.generate_report(
        test_type='fairness',
        results=results,
        file_path=str(output_dir / f'fairness_report_{config_name}.html'),
        model_name=f'Credit Model ({config_name})'
    )

    print(f"   ‚úì Relat√≥rio: {Path(report_path).name}")

# ============================================================================
# PARTE 6: VISUALIZA√á√ïES EST√ÅTICAS
# ============================================================================

print("\n" + "=" * 80)
print("üìä PARTE 6: Gerando Visualiza√ß√µes Est√°ticas")
print("-" * 80)

print("\n6.1 - Distribui√ß√£o por grupo (gender):")
viz_path = FairnessVisualizer.plot_distribution_by_group(
    df=df,
    target_col='approved',
    sensitive_feature='gender',
    output_path=str(output_dir / 'distribution_gender.png')
)
print(f"   ‚úì Salvo: {Path(viz_path).name}")

print("\n6.2 - Distribui√ß√£o por grupo (race):")
viz_path = FairnessVisualizer.plot_distribution_by_group(
    df=df,
    target_col='approved',
    sensitive_feature='race',
    output_path=str(output_dir / 'distribution_race.png')
)
print(f"   ‚úì Salvo: {Path(viz_path).name}")

print("\n6.3 - Compara√ß√£o de m√©tricas:")
viz_path = FairnessVisualizer.plot_metrics_comparison(
    metrics_results=suite_results['full']['posttrain_metrics'],
    protected_attrs=['gender', 'race', 'age_group'],
    output_path=str(output_dir / 'metrics_comparison.png')
)
print(f"   ‚úì Salvo: {Path(viz_path).name}")

print("\n6.4 - Radar de fairness:")
viz_path = FairnessVisualizer.plot_fairness_radar(
    metrics_summary=suite_results['full']['posttrain_metrics'],
    output_path=str(output_dir / 'fairness_radar.png')
)
print(f"   ‚úì Salvo: {Path(viz_path).name}")

# ============================================================================
# PARTE 7: RECOMENDA√á√ïES BASEADAS NOS RESULTADOS
# ============================================================================

print("\n" + "=" * 80)
print("üí° PARTE 7: Recomenda√ß√µes e Pr√≥ximos Passos")
print("-" * 80)

score = fairness_result.overall_fairness_score
critical_count = len(fairness_result.critical_issues)
warning_count = len(fairness_result.warnings)

print(f"\nüìä RESUMO DA AN√ÅLISE:")
print(f"   Overall Fairness Score: {score:.3f}")
print(f"   Critical Issues: {critical_count}")
print(f"   Warnings: {warning_count}")

print(f"\nüí° RECOMENDA√á√ïES:")

if score >= 0.9:
    print("   ‚úÖ EXCELENTE - Modelo apresenta fairness muito boa")
    print("      - Considerar deploy em produ√ß√£o")
    print("      - Monitorar m√©tricas continuamente")
elif score >= 0.8:
    print("   ‚úì BOA - Modelo apresenta fairness aceit√°vel")
    print("      - Revisar warnings antes do deploy")
    print("      - Considerar melhorias nas √°reas identificadas")
elif score >= 0.7:
    print("   ‚ö†Ô∏è  MODERADA - Modelo apresenta problemas de fairness")
    print("      - Recomenda-se retreinar com t√©cnicas de mitiga√ß√£o de vi√©s")
    print("      - Considerar re-balanceamento de dados")
    print("      - Avaliar threshold de decis√£o")
else:
    print("   ‚ùå CR√çTICA - Modelo apresenta vi√©s significativo")
    print("      - N√ÉO recomendado para deploy")
    print("      - Investigar fontes de vi√©s nos dados")
    print("      - Aplicar t√©cnicas de fairness-aware learning")

print(f"\nüîß T√âCNICAS DE MITIGA√á√ÉO:")
print("   1. Pr√©-processamento:")
print("      - Re-balanceamento de classes por grupo")
print("      - Remo√ß√£o de features correlacionadas com atributos protegidos")
print("   2. Durante o treinamento:")
print("      - Adversarial debiasing")
print("      - Fairness constraints")
print("   3. P√≥s-processamento:")
print("      - Ajuste de thresholds por grupo")
print("      - Calibra√ß√£o de probabilidades")

# ============================================================================
# RESUMO FINAL
# ============================================================================

print("\n" + "=" * 80)
print("üìÅ RESUMO FINAL - ARQUIVOS GERADOS")
print("=" * 80)

print(f"\nüìÇ Diret√≥rio: {output_dir.absolute()}")

generated_files = sorted(output_dir.glob('*'))
total_size = sum(f.stat().st_size for f in generated_files if f.is_file())

print(f"\nüìä ESTAT√çSTICAS:")
print(f"   - Total de arquivos: {len(generated_files)}")
print(f"   - Tamanho total: {total_size / 1024:.1f} KB")

print(f"\nüìÅ ARQUIVOS:")
for f in generated_files:
    if f.is_file():
        size_kb = f.stat().st_size / 1024
        icon = "üåê" if f.suffix == '.html' else "üìä"
        print(f"   {icon} {f.name} ({size_kb:.1f} KB)")

print(f"\nüí° PR√ìXIMOS PASSOS:")
print(f"   1. Abrir relat√≥rios HTML em um navegador:")
print(f"      file://{output_dir.absolute()}/fairness_report_experiment.html")
print(f"   2. Revisar visualiza√ß√µes est√°ticas")
print(f"   3. Analisar m√©tricas detalhadas por atributo")
print(f"   4. Implementar mitiga√ß√µes se necess√°rio")
print(f"   5. Re-executar an√°lise ap√≥s mudan√ßas")

print("\n" + "=" * 80)
print("‚úÖ EXEMPLO COMPLETO EXECUTADO COM SUCESSO!")
print("=" * 80)
