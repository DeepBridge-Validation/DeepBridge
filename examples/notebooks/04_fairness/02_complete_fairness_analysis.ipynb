{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# ‚öñÔ∏è‚≠ê Complete Fairness Analysis\n",
    "\n",
    "<div style=\"background-color: #fff3e0; padding: 15px; border-radius: 5px; border-left: 5px solid #ff6f00;\">\n",
    "<b>üî• CRITICAL NOTEBOOK</b><br>\n",
    "<b>Level:</b> Advanced<br>\n",
    "<b>Duration:</b> 35 minutes<br>\n",
    "<b>Dataset:</b> Credit Scoring (synthetic)<br>\n",
    "<b>Importance:</b> ‚≠ê‚≠ê ESSENTIAL for regulated applications\n",
    "</div>\n",
    "\n",
    "## üéØ Objectives\n",
    "- ‚úÖ Execute complete fairness analysis (15 metrics)\n",
    "- ‚úÖ Verify EEOC compliance\n",
    "- ‚úÖ Analyze metrics by group (gender, race, age)\n",
    "- ‚úÖ Threshold analysis for optimization\n",
    "- ‚úÖ Confusion matrices by group\n",
    "- ‚úÖ Generate professional HTML report\n",
    "- ‚úÖ Make deployment decision based on compliance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## üìñ Scenario\n",
    "\n",
    "### Story\n",
    "You work at a bank and developed a **Credit Scoring** model to decide loan approvals. Before deploying to production, you MUST ensure that:\n",
    "\n",
    "1. ‚úÖ The model does not discriminate by gender\n",
    "2. ‚úÖ The model does not discriminate by race\n",
    "3. ‚úÖ The model does not discriminate by age\n",
    "4. ‚úÖ EEOC 80% Rule is satisfied\n",
    "5. ‚úÖ Complete documentation for audit\n",
    "\n",
    "### Legal Requirements\n",
    "- **Fair Lending Laws** (USA)\n",
    "- **Equal Credit Opportunity Act (ECOA)**\n",
    "- **Fair Housing Act**\n",
    "- **EEOC Guidelines**\n",
    "\n",
    "### Risk\n",
    "- ‚ùå Million-dollar fines\n",
    "- ‚ùå Lawsuits\n",
    "- ‚ùå Reputational damage\n",
    "- ‚ùå Loss of operating license"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-09 16:56:15,310 - deepbridge.reports - INFO - Successfully imported radar chart fix\n",
      "2025-11-09 16:56:15,312 - deepbridge.reports - INFO - Successfully patched EnhancedUncertaintyCharts.generate_model_metrics_comparison\n",
      "2025-11-09 16:56:15,313 - deepbridge.reports - INFO - Successfully applied enhanced_charts patch\n",
      "2025-11-09 16:56:15,316 - deepbridge.reports - INFO - Successfully loaded UncertaintyChartGenerator\n",
      "2025-11-09 16:56:15,319 - deepbridge.reports - INFO - Successfully imported and initialized SeabornChartGenerator\n",
      "2025-11-09 16:56:15,320 - deepbridge.reports - INFO - SeabornChartGenerator has_visualization_libs: True\n",
      "2025-11-09 16:56:15,320 - deepbridge.reports - INFO - Available chart methods: ['bar_chart', 'boxplot_chart', 'coverage_analysis_chart', 'detailed_boxplot_chart', 'distribution_grid_chart', 'feature_comparison_chart', 'feature_importance_chart', 'feature_psi_chart', 'generate_encoded_chart', 'heatmap_chart', 'individual_feature_impact_chart', 'method_comparison_chart', 'metrics_radar_chart', 'model_comparison_chart', 'model_metrics_heatmap', 'robustness_overview_chart', 'selected_features_comparison_chart', 'uncertainty_violin_chart', 'worst_performance_chart']\n",
      "2025-11-09 16:56:15,329 - deepbridge.reports - INFO - Successfully imported visualization libraries (numpy, matplotlib, seaborn, pandas)\n",
      "2025-11-09 16:56:15,352 - deepbridge.reports - INFO - Successfully loaded resilience-specific chart generator from deepbridge.templates.report_types.resilience.static.charts\n",
      "2025-11-09 16:56:15,353 - deepbridge.reports - INFO - Available resilience chart methods: ['generate_critical_feature_distributions', 'generate_distance_metrics_comparison', 'generate_feature_distance_heatmap', 'generate_feature_distribution_shift', 'generate_feature_residual_correlation', 'generate_model_comparison', 'generate_model_comparison_scatter', 'generate_model_resilience_scores', 'generate_performance_gap', 'generate_performance_gap_by_alpha', 'generate_residual_distribution']\n",
      "üìä Creating Credit Scoring dataset...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from deepbridge import DBDataset, Experiment\n",
    "\n",
    "# Configure visualizations\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"Set2\")\n",
    "\n",
    "print(\"üìä Creating Credit Scoring dataset...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset created: (3000, 10)\n",
      "\n",
      "üìä Overall approval rate: 61.6%\n",
      "\n",
      "üìä Distributions:\n",
      "   Gender: {'Male': np.int64(1556), 'Female': np.int64(1444)}\n",
      "   Race: {'White': np.int64(1824), 'Hispanic': np.int64(522), 'Black': np.int64(362), 'Asian': np.int64(213), 'Other': np.int64(79)}\n"
     ]
    }
   ],
   "source": [
    "# Create realistic Credit Scoring dataset\n",
    "np.random.seed(42)\n",
    "n = 3000\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'age': np.random.randint(21, 70, n),\n",
    "    'income': np.random.gamma(2, 30000, n),\n",
    "    'credit_score': np.random.randint(300, 850, n),\n",
    "    'employment_years': np.random.randint(0, 40, n),\n",
    "    'loan_amount': np.random.gamma(2, 15000, n),\n",
    "    'debt_to_income': np.random.beta(2, 5, n),\n",
    "    'gender': np.random.choice(['Male', 'Female'], n, p=[0.52, 0.48]),\n",
    "    'race': np.random.choice(['White', 'Black', 'Hispanic', 'Asian', 'Other'], n,\n",
    "                             p=[0.60, 0.13, 0.18, 0.06, 0.03]),\n",
    "    'has_cosigner': np.random.choice([0, 1], n, p=[0.7, 0.3])\n",
    "})\n",
    "\n",
    "# Target: loan approval\n",
    "# Use legitimate features + introduce small bias for demonstration\n",
    "approval_score = (\n",
    "    (df['credit_score'] - 500) / 100 * 0.3 +\n",
    "    (df['income'] / 100000) * 0.2 +\n",
    "    (df['employment_years'] / 20) * 0.15 +\n",
    "    (1 - df['debt_to_income']) * 0.2 +\n",
    "    df['has_cosigner'] * 0.1 +\n",
    "    (df['gender'] == 'Male') * 0.05 +  # ‚Üê Intentional bias\n",
    "    (df['race'] == 'White') * 0.03      # ‚Üê Intentional bias\n",
    ")\n",
    "\n",
    "df['approved'] = (approval_score + np.random.normal(0, 0.15, n) > 0.5).astype(int)\n",
    "\n",
    "print(f\"‚úÖ Dataset created: {df.shape}\")\n",
    "print(f\"\\nüìä Overall approval rate: {df['approved'].mean():.1%}\")\n",
    "print(f\"\\nüìä Distributions:\")\n",
    "print(f\"   Gender: {dict(df['gender'].value_counts())}\")\n",
    "print(f\"   Race: {dict(df['race'].value_counts())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ EDA - Check Disparities in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö†Ô∏è  DISPARITIES IN DATA:\n",
      "\n",
      "Gender:\n",
      "  Female: 59.2%\n",
      "  Male: 63.8%\n",
      "\n",
      "Race:\n",
      "  White: 62.8%\n",
      "  Black: 61.0%\n",
      "  Asian: 60.6%\n",
      "  Hispanic: 58.6%\n",
      "  Other: 58.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1431219/2889460788.py:31: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Analysis by group\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Approval by gender\n",
    "gender_approval = df.groupby('gender')['approved'].mean()\n",
    "axes[0].bar(gender_approval.index, gender_approval.values, \n",
    "            color=['steelblue', 'coral'], edgecolor='black', alpha=0.8)\n",
    "axes[0].axhline(y=0.8 * gender_approval.max(), color='red', \n",
    "                linestyle='--', label='EEOC 80% Threshold', linewidth=2)\n",
    "axes[0].set_title('Approval Rate by Gender (Data)', fontsize=13, fontweight='bold')\n",
    "axes[0].set_ylabel('Approval Rate', fontsize=11)\n",
    "axes[0].set_ylim(0, 1)\n",
    "axes[0].legend()\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Approval by race\n",
    "race_approval = df.groupby('race')['approved'].mean().sort_values(ascending=False)\n",
    "colors_race = ['green' if x >= 0.8*race_approval.max() else 'orange' \n",
    "               for x in race_approval.values]\n",
    "axes[1].barh(race_approval.index, race_approval.values, \n",
    "             color=colors_race, edgecolor='black', alpha=0.8)\n",
    "axes[1].axvline(x=0.8 * race_approval.max(), color='red', \n",
    "                linestyle='--', label='EEOC 80% Threshold', linewidth=2)\n",
    "axes[1].set_title('Approval Rate by Race (Data)', fontsize=13, fontweight='bold')\n",
    "axes[1].set_xlabel('Approval Rate', fontsize=11)\n",
    "axes[1].set_xlim(0, 1)\n",
    "axes[1].legend()\n",
    "axes[1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è  DISPARITIES IN DATA:\\n\")\n",
    "print(f\"Gender:\")\n",
    "for g in gender_approval.index:\n",
    "    print(f\"  {g}: {gender_approval[g]:.1%}\")\n",
    "print(f\"\\nRace:\")\n",
    "for r in race_approval.index:\n",
    "    print(f\"  {r}: {race_approval[r]:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model trained!\n",
      "üìä Accuracy: 0.910\n",
      "üìä Approval rate (pred): 64.2%\n"
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "df_encoded = df.copy()\n",
    "df_encoded['gender_enc'] = (df['gender'] == 'Male').astype(int)\n",
    "df_encoded['race_White'] = (df['race'] == 'White').astype(int)\n",
    "df_encoded['race_Black'] = (df['race'] == 'Black').astype(int)\n",
    "df_encoded['race_Hispanic'] = (df['race'] == 'Hispanic').astype(int)\n",
    "df_encoded['race_Asian'] = (df['race'] == 'Asian').astype(int)\n",
    "\n",
    "feature_cols = ['age', 'income', 'credit_score', 'employment_years', \n",
    "                'loan_amount', 'debt_to_income', 'has_cosigner',\n",
    "                'gender_enc', 'race_White', 'race_Black', 'race_Hispanic', 'race_Asian']\n",
    "\n",
    "X = df_encoded[feature_cols]\n",
    "y = df_encoded['approved']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(f\"‚úÖ Model trained!\")\n",
    "print(f\"üìä Accuracy: {clf.score(X_test, y_test):.3f}\")\n",
    "print(f\"üìä Approval rate (pred): {clf.predict(X_test).mean():.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Create Experiment with Protected Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not generate predictions using the provided model: Failed to generate predictions for train data: The feature names should match those that were passed during fit.\n",
      "Feature names unseen at fit time:\n",
      "- gender\n",
      "- race\n",
      "\n",
      "‚úÖ Initial model evaluation complete: RandomForestClassifier\n",
      "2025-11-09 16:56:18,505 - deepbridge.experiment - WARNING - Could not calculate ROC AUC for primary_model: The feature names should match those that were passed during fit.\n",
      "Feature names unseen at fit time:\n",
      "- gender\n",
      "- race\n",
      "\n",
      "‚úÖ Experiment created with protected attributes!\n",
      "üõ°Ô∏è  Protected: ['gender', 'race']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guhaase/projetos/DeepBridge/deepbridge/utils/feature_manager.py:25: UserWarning: Inferred 2 categorical features: gender, race\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dataset = DBDataset(\n",
    "    data=df_encoded,\n",
    "    target_column='approved',\n",
    "    model=clf,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    dataset_name='Credit Scoring Model'\n",
    ")\n",
    "\n",
    "exp = Experiment(\n",
    "    dataset=dataset,\n",
    "    experiment_type='binary_classification',\n",
    "    protected_attributes=['gender', 'race'],  # ‚Üê CRITICAL!\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Experiment created with protected attributes!\")\n",
    "print(f\"üõ°Ô∏è  Protected: {exp.protected_attributes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ EXECUTE COMPLETE FAIRNESS ANALYSIS\n",
    "\n",
    "<div style=\"background-color: #fff3e0; padding: 15px; border-radius: 5px; border-left: 5px solid #ff9800;\">\n",
    "<b>‚è±Ô∏è Warning:</b> Complete analysis may take a few minutes!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¨ Executing COMPLETE Fairness Analysis...\n",
      "\n",
      "   üìä Calculating 15 fairness metrics\n",
      "   ‚öñÔ∏è  Verifying EEOC compliance\n",
      "   üë• Analyzing by group (gender, race)\n",
      "   üìà Threshold analysis\n",
      "\n",
      "‚è≥ Please wait...\n",
      "\n",
      "2025-11-09 16:56:19,024 - deepbridge.experiment - WARNING - Found 2 critical fairness issues\n",
      "\n",
      "‚úÖ Complete analysis finished!\n"
     ]
    }
   ],
   "source": [
    "print(\"üî¨ Executing COMPLETE Fairness Analysis...\\n\")\n",
    "print(\"   üìä Calculating 15 fairness metrics\")\n",
    "print(\"   ‚öñÔ∏è  Verifying EEOC compliance\")\n",
    "print(\"   üë• Analyzing by group (gender, race)\")\n",
    "print(\"   üìà Threshold analysis\")\n",
    "print(\"\\n‚è≥ Please wait...\\n\")\n",
    "\n",
    "fairness_result = exp.run_fairness_tests(config='full')\n",
    "\n",
    "print(\"\\n‚úÖ Complete analysis finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ THE 15 FAIRNESS METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä 15 FAIRNESS METRICS\n",
      "======================================================================\n",
      "\n",
      "MAIN METRICS:\n",
      "\n",
      "1Ô∏è‚É£  DEMOGRAPHIC PARITY\n",
      "    Definition: P(≈∂=1|A=0) = P(≈∂=1|A=1)\n",
      "    Measures: Equal positive prediction rate across groups\n",
      "\n",
      "2Ô∏è‚É£  EQUAL OPPORTUNITY\n",
      "    Definition: P(≈∂=1|Y=1,A=0) = P(≈∂=1|Y=1,A=1)\n",
      "    Measures: Equal True Positive Rate across groups\n",
      "\n",
      "3Ô∏è‚É£  EQUALIZED ODDS\n",
      "    Definition: TPR and FPR equal across groups\n",
      "    Measures: Balanced performance\n",
      "\n",
      "4Ô∏è‚É£  DISPARATE IMPACT ‚≠ê (EEOC)\n",
      "    Definition: Ratio = P(≈∂=1|Unprivileged) / P(≈∂=1|Privileged)\n",
      "    Threshold: >= 0.80 to pass\n",
      "    Importance: LEGAL REQUIREMENT!\n",
      "\n",
      "5Ô∏è‚É£  STATISTICAL PARITY\n",
      "    Similar to Demographic Parity\n",
      "\n",
      "... and 10 additional metrics!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüìä 15 FAIRNESS METRICS\\n\" + \"=\"*70 + \"\\n\")\n",
    "\n",
    "# If available in result\n",
    "if hasattr(fairness_result, 'all_metrics'):\n",
    "    metrics = fairness_result.all_metrics()\n",
    "    \n",
    "    for i, (metric_name, value) in enumerate(metrics.items(), 1):\n",
    "        status = \"‚úÖ\" if value.get('passes', True) else \"‚ùå\"\n",
    "        print(f\"{i:2d}. {status} {metric_name}: {value.get('score', 'N/A')}\")\n",
    "else:\n",
    "    # Demonstration of metrics\n",
    "    print(\"MAIN METRICS:\\n\")\n",
    "    \n",
    "    print(\"1Ô∏è‚É£  DEMOGRAPHIC PARITY\")\n",
    "    print(\"    Definition: P(≈∂=1|A=0) = P(≈∂=1|A=1)\")\n",
    "    print(\"    Measures: Equal positive prediction rate across groups\\n\")\n",
    "    \n",
    "    print(\"2Ô∏è‚É£  EQUAL OPPORTUNITY\")\n",
    "    print(\"    Definition: P(≈∂=1|Y=1,A=0) = P(≈∂=1|Y=1,A=1)\")\n",
    "    print(\"    Measures: Equal True Positive Rate across groups\\n\")\n",
    "    \n",
    "    print(\"3Ô∏è‚É£  EQUALIZED ODDS\")\n",
    "    print(\"    Definition: TPR and FPR equal across groups\")\n",
    "    print(\"    Measures: Balanced performance\\n\")\n",
    "    \n",
    "    print(\"4Ô∏è‚É£  DISPARATE IMPACT ‚≠ê (EEOC)\")\n",
    "    print(\"    Definition: Ratio = P(≈∂=1|Unprivileged) / P(≈∂=1|Privileged)\")\n",
    "    print(\"    Threshold: >= 0.80 to pass\")\n",
    "    print(\"    Importance: LEGAL REQUIREMENT!\\n\")\n",
    "    \n",
    "    print(\"5Ô∏è‚É£  STATISTICAL PARITY\")\n",
    "    print(\"    Similar to Demographic Parity\\n\")\n",
    "    \n",
    "    print(\"... and 10 additional metrics!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ EEOC COMPLIANCE - 80% RULE ‚≠ê"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚öñÔ∏è  EEOC 80% RULE COMPLIANCE\n",
      "======================================================================\n",
      "\n",
      "üë• ANALYSIS BY GENDER:\n",
      "   Approval rate (Male): 62.0%\n",
      "   Approval rate (Female): 66.3%\n",
      "   Disparate Impact: 1.070\n",
      "   Status: ‚úÖ PASS (threshold = 0.80)\n",
      "\n",
      "üåç ANALYSIS BY RACE:\n",
      "   Reference group (highest rate): Asian (69.8%)\n",
      "\n",
      "   ‚úÖ Asian: 69.8% (DI = 1.000)\n",
      "   ‚úÖ Black: 67.7% (DI = 0.971)\n",
      "   ‚úÖ Hispanic: 66.4% (DI = 0.951)\n",
      "   ‚ùå Other: 38.5% (DI = 0.551)\n",
      "   ‚úÖ White: 63.1% (DI = 0.905)\n",
      "\n",
      "======================================================================\n",
      "‚ùå EEOC COMPLIANCE: FAILED\n",
      "   ‚ö†Ô∏è  MODEL CANNOT GO TO PRODUCTION\n",
      "   üìã Required actions:\n",
      "      1. Mitigate bias in data or model\n",
      "      2. Re-train with fairness techniques\n",
      "      3. Consider alternative models\n",
      "      4. Consult legal team\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n‚öñÔ∏è  EEOC 80% RULE COMPLIANCE\\n\" + \"=\"*70 + \"\\n\")\n",
    "\n",
    "# Calculate manually for demonstration\n",
    "y_pred_test = clf.predict(X_test)\n",
    "test_indices = X_test.index\n",
    "test_gender = df_encoded.loc[test_indices, 'gender']\n",
    "test_race = df_encoded.loc[test_indices, 'race']\n",
    "\n",
    "# By gender\n",
    "male_approval = y_pred_test[test_gender == 'Male'].mean()\n",
    "female_approval = y_pred_test[test_gender == 'Female'].mean()\n",
    "di_gender = female_approval / male_approval if male_approval > 0 else 0\n",
    "\n",
    "print(\"üë• ANALYSIS BY GENDER:\")\n",
    "print(f\"   Approval rate (Male): {male_approval:.1%}\")\n",
    "print(f\"   Approval rate (Female): {female_approval:.1%}\")\n",
    "print(f\"   Disparate Impact: {di_gender:.3f}\")\n",
    "print(f\"   Status: {'‚úÖ PASS' if di_gender >= 0.8 else '‚ùå FAIL'} (threshold = 0.80)\")\n",
    "\n",
    "if di_gender < 0.8:\n",
    "    print(f\"   ‚ö†Ô∏è  ACTION REQUIRED: Model discriminates by gender!\")\n",
    "    print(f\"   üí° Difference: {abs(male_approval - female_approval):.1%}\")\n",
    "\n",
    "# By race\n",
    "print(\"\\nüåç ANALYSIS BY RACE:\")\n",
    "race_groups = test_race.unique()\n",
    "race_approvals = {}\n",
    "\n",
    "for race in race_groups:\n",
    "    mask = test_race == race\n",
    "    if mask.sum() > 0:\n",
    "        race_approvals[race] = y_pred_test[mask].mean()\n",
    "\n",
    "# Use group with highest rate as reference\n",
    "max_race = max(race_approvals, key=race_approvals.get)\n",
    "max_approval = race_approvals[max_race]\n",
    "\n",
    "print(f\"   Reference group (highest rate): {max_race} ({max_approval:.1%})\\n\")\n",
    "\n",
    "for race in sorted(race_approvals.keys()):\n",
    "    approval = race_approvals[race]\n",
    "    di = approval / max_approval if max_approval > 0 else 0\n",
    "    status = \"‚úÖ\" if di >= 0.8 else \"‚ùå\"\n",
    "    print(f\"   {status} {race}: {approval:.1%} (DI = {di:.3f})\")\n",
    "\n",
    "# Final decision\n",
    "all_pass = di_gender >= 0.8 and all(race_approvals[r]/max_approval >= 0.8 \n",
    "                                     for r in race_approvals)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "if all_pass:\n",
    "    print(\"‚úÖ EEOC COMPLIANCE: APPROVED\")\n",
    "    print(\"   Model can be considered for production\")\n",
    "else:\n",
    "    print(\"‚ùå EEOC COMPLIANCE: FAILED\")\n",
    "    print(\"   ‚ö†Ô∏è  MODEL CANNOT GO TO PRODUCTION\")\n",
    "    print(\"   üìã Required actions:\")\n",
    "    print(\"      1. Mitigate bias in data or model\")\n",
    "    print(\"      2. Re-train with fairness techniques\")\n",
    "    print(\"      3. Consider alternative models\")\n",
    "    print(\"      4. Consult legal team\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ CONFUSION MATRICES BY GROUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä METRICS BY GENDER:\n",
      "\n",
      "üë§ Male:\n",
      "   True Positive Rate (TPR): 0.883\n",
      "   False Positive Rate (FPR): 0.117\n",
      "   Precision: 0.935\n",
      "   Approval Rate: 0.620\n",
      "\n",
      "üë§ Female:\n",
      "   True Positive Rate (TPR): 0.950\n",
      "   False Positive Rate (FPR): 0.090\n",
      "   Precision: 0.955\n",
      "   Approval Rate: 0.663\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1431219/726088085.py:19: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrices for each gender\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "y_test_subset = y_test.loc[test_indices]\n",
    "\n",
    "for idx, gender in enumerate(['Male', 'Female']):\n",
    "    mask = test_gender == gender\n",
    "    cm = confusion_matrix(y_test_subset[mask], y_pred_test[mask])\n",
    "    \n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Rejected', 'Approved'],\n",
    "                yticklabels=['Rejected', 'Approved'],\n",
    "                ax=axes[idx], cbar_kws={'label': 'Count'})\n",
    "    axes[idx].set_title(f'Confusion Matrix - {gender}', fontsize=13, fontweight='bold')\n",
    "    axes[idx].set_ylabel('Actual', fontsize=11)\n",
    "    axes[idx].set_xlabel('Predicted', fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate metrics by gender\n",
    "print(\"\\nüìä METRICS BY GENDER:\\n\")\n",
    "\n",
    "for gender in ['Male', 'Female']:\n",
    "    mask = test_gender == gender\n",
    "    y_true = y_test_subset[mask]\n",
    "    y_pred = y_pred_test[mask]\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    \n",
    "    print(f\"üë§ {gender}:\")\n",
    "    print(f\"   True Positive Rate (TPR): {tpr:.3f}\")\n",
    "    print(f\"   False Positive Rate (FPR): {fpr:.3f}\")\n",
    "    print(f\"   Precision: {precision:.3f}\")\n",
    "    print(f\"   Approval Rate: {y_pred.mean():.3f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ THRESHOLD ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cell-20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà THRESHOLD ANALYSIS\n",
      "============================================================\n",
      "\n",
      "üí° Adjusting decision threshold can improve fairness!\n",
      "\n",
      "Threshold | Male Rate | Female Rate | DI    | EEOC\n",
      "------------------------------------------------------------\n",
      "  0.3     |   0.717   |   0.727     | 1.014 | ‚úÖ\n",
      "  0.4     |   0.660   |   0.697     | 1.056 | ‚úÖ\n",
      "  0.5     |   0.620   |   0.663     | 1.070 | ‚úÖ\n",
      "  0.6     |   0.583   |   0.627     | 1.074 | ‚úÖ\n",
      "  0.7     |   0.553   |   0.600     | 1.084 | ‚úÖ\n",
      "\n",
      "‚úÖ RECOMMENDATION: Use threshold = 0.7\n",
      "   DI = 1.084 (passes EEOC)\n"
     ]
    }
   ],
   "source": [
    "# Analyze impact of different thresholds\n",
    "print(\"üìà THRESHOLD ANALYSIS\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "print(\"üí° Adjusting decision threshold can improve fairness!\\n\")\n",
    "\n",
    "# Get probabilities\n",
    "y_proba = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "thresholds = [0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "results = []\n",
    "\n",
    "for thresh in thresholds:\n",
    "    y_pred_thresh = (y_proba >= thresh).astype(int)\n",
    "    \n",
    "    male_rate = y_pred_thresh[test_gender == 'Male'].mean()\n",
    "    female_rate = y_pred_thresh[test_gender == 'Female'].mean()\n",
    "    di = female_rate / male_rate if male_rate > 0 else 0\n",
    "    \n",
    "    results.append({\n",
    "        'threshold': thresh,\n",
    "        'male_rate': male_rate,\n",
    "        'female_rate': female_rate,\n",
    "        'disparate_impact': di,\n",
    "        'passes_eeoc': di >= 0.8\n",
    "    })\n",
    "\n",
    "# Show results\n",
    "print(\"Threshold | Male Rate | Female Rate | DI    | EEOC\")\n",
    "print(\"-\" * 60)\n",
    "for r in results:\n",
    "    status = \"‚úÖ\" if r['passes_eeoc'] else \"‚ùå\"\n",
    "    print(f\"  {r['threshold']:.1f}     |   {r['male_rate']:.3f}   |   {r['female_rate']:.3f}     | {r['disparate_impact']:.3f} | {status}\")\n",
    "\n",
    "# Recommend best threshold\n",
    "passing_thresholds = [r for r in results if r['passes_eeoc']]\n",
    "if passing_thresholds:\n",
    "    best = max(passing_thresholds, key=lambda x: x['disparate_impact'])\n",
    "    print(f\"\\n‚úÖ RECOMMENDATION: Use threshold = {best['threshold']:.1f}\")\n",
    "    print(f\"   DI = {best['disparate_impact']:.3f} (passes EEOC)\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  No simple threshold solves the problem\")\n",
    "    print(f\"   Need to re-train or use mitigation techniques\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## üîü GENERATE PROFESSIONAL HTML REPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cell-22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Generating HTML report for audit...\n",
      "\n",
      "2025-11-09 16:57:00,251 - deepbridge.reports - INFO - Using templates directory: /home/guhaase/projetos/DeepBridge/deepbridge/templates\n",
      "2025-11-09 16:57:00,259 - deepbridge.reports - INFO - Successfully loaded UncertaintyChartGenerator\n",
      "2025-11-09 16:57:00,264 - deepbridge.reports - INFO - Successfully imported and initialized SeabornChartGenerator\n",
      "2025-11-09 16:57:00,265 - deepbridge.reports - INFO - SeabornChartGenerator has_visualization_libs: True\n",
      "2025-11-09 16:57:00,267 - deepbridge.reports - INFO - Available chart methods: ['bar_chart', 'boxplot_chart', 'coverage_analysis_chart', 'detailed_boxplot_chart', 'distribution_grid_chart', 'feature_comparison_chart', 'feature_importance_chart', 'feature_psi_chart', 'generate_encoded_chart', 'heatmap_chart', 'individual_feature_impact_chart', 'method_comparison_chart', 'metrics_radar_chart', 'model_comparison_chart', 'model_metrics_heatmap', 'robustness_overview_chart', 'selected_features_comparison_chart', 'uncertainty_violin_chart', 'worst_performance_chart']\n",
      "2025-11-09 16:57:00,268 - deepbridge.reports - INFO - Successfully imported visualization libraries (numpy, matplotlib, seaborn, pandas)\n",
      "2025-11-09 16:57:00,274 - deepbridge.reports - INFO - Successfully loaded resilience-specific chart generator from deepbridge.templates.report_types.resilience.static.charts\n",
      "2025-11-09 16:57:00,275 - deepbridge.reports - INFO - Available resilience chart methods: ['generate_critical_feature_distributions', 'generate_distance_metrics_comparison', 'generate_feature_distance_heatmap', 'generate_feature_distribution_shift', 'generate_feature_residual_correlation', 'generate_model_comparison', 'generate_model_comparison_scatter', 'generate_model_resilience_scores', 'generate_performance_gap', 'generate_performance_gap_by_alpha', 'generate_residual_distribution']\n",
      "2025-11-09 16:57:00,276 - deepbridge.reports - INFO - Generating fairness report to: fairness_report_complete.html\n",
      "2025-11-09 16:57:00,277 - deepbridge.reports - INFO - Report type: interactive\n",
      "2025-11-09 16:57:00,278 - deepbridge.reports - INFO - Transforming fairness data for report\n",
      "2025-11-09 16:57:00,777 - deepbridge.reports - INFO - Transformation complete. 2 protected attributes analyzed\n",
      "2025-11-09 16:57:00,779 - deepbridge.reports - INFO - Found template at: /home/guhaase/projetos/DeepBridge/deepbridge/templates/report_types/fairness/interactive/index.html\n",
      "2025-11-09 16:57:00,780 - deepbridge.reports - DEBUG - Loading template: /home/guhaase/projetos/DeepBridge/deepbridge/templates/report_types/fairness/interactive/index.html\n",
      "2025-11-09 16:57:00,795 - deepbridge.reports - INFO - Template loaded for fairness/interactive\n",
      "2025-11-09 16:57:00,800 - deepbridge.reports - INFO - CSS compiled successfully using CSSManager for fairness: 51467 chars\n",
      "2025-11-09 16:57:00,826 - deepbridge.reports - DEBUG - Rendering template with context keys: ['report_data', 'report_data_json', 'css_content', 'js_content', 'logo', 'favicon_base64', 'model_name', 'model_type', 'timestamp', 'test_type', 'current_year', 'report_title', 'report_subtitle', 'overall_fairness_score', 'total_warnings', 'total_critical', 'total_attributes', 'assessment', 'config', 'protected_attributes', 'warnings', 'critical_issues', 'has_threshold_analysis', 'has_confusion_matrix', 'charts', 'dataset_info', 'test_config']\n",
      "2025-11-09 16:57:00,832 - deepbridge.reports - INFO - Fairness report generated and saved to: fairness_report_complete.html (type: interactive)\n",
      "2025-11-09 16:57:00,834 - deepbridge.reports - INFO - Output directory ensured: /home/guhaase/projetos/DeepBridge/examples/notebooks/04_fairness\n",
      "2025-11-09 16:57:00,837 - deepbridge.reports - INFO - Report saved to: fairness_report_complete.html\n",
      "2025-11-09 16:57:00,839 - deepbridge.reports - INFO - Report generated and saved to: fairness_report_complete.html (type: interactive)\n",
      "‚úÖ Report generated!\n",
      "üìÅ Location: fairness_report_complete.html\n",
      "\n",
      "üìä The report contains:\n",
      "   ‚úÖ All 15 fairness metrics\n",
      "   ‚úÖ EEOC compliance check\n",
      "   ‚úÖ Analysis by group (gender, race, age)\n",
      "   ‚úÖ Confusion matrices\n",
      "   ‚úÖ Interactive charts\n",
      "   ‚úÖ Recommendations\n",
      "\n",
      "üíº Use this report for:\n",
      "   - Compliance documentation\n",
      "   - Regulatory audit\n",
      "   - Internal approval\n",
      "   - Legal defense\n"
     ]
    }
   ],
   "source": [
    "print(\"üìÑ Generating HTML report for audit...\\n\")\n",
    "\n",
    "output_path = 'fairness_report_complete.html'\n",
    "\n",
    "if hasattr(fairness_result, 'save_html'):\n",
    "    fairness_result.save_html(output_path)\n",
    "    print(f\"‚úÖ Report generated!\")\n",
    "    print(f\"üìÅ Location: {output_path}\")\n",
    "    print(f\"\\nüìä The report contains:\")\n",
    "    print(f\"   ‚úÖ All 15 fairness metrics\")\n",
    "    print(f\"   ‚úÖ EEOC compliance check\")\n",
    "    print(f\"   ‚úÖ Analysis by group (gender, race, age)\")\n",
    "    print(f\"   ‚úÖ Confusion matrices\")\n",
    "    print(f\"   ‚úÖ Interactive charts\")\n",
    "    print(f\"   ‚úÖ Recommendations\")\n",
    "    print(f\"\\nüíº Use this report for:\")\n",
    "    print(f\"   - Compliance documentation\")\n",
    "    print(f\"   - Regulatory audit\")\n",
    "    print(f\"   - Internal approval\")\n",
    "    print(f\"   - Legal defense\")\n",
    "else:\n",
    "    print(\"üí° To generate report:\")\n",
    "    print(\"   exp.save_fairness_report(output_path)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£1Ô∏è‚É£ DEPLOYMENT DECISION - COMPLIANCE CHECKLIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cell-24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ PRODUCTION COMPLIANCE CHECKLIST\n",
      "======================================================================\n",
      "\n",
      "‚úÖ EEOC 80% Rule (Gender)\n",
      "‚ùå EEOC 80% Rule (Race)\n",
      "‚úÖ Minimum accuracy (>= 0.70)\n",
      "‚úÖ HTML report generated\n",
      "‚úÖ Complete analysis documented\n",
      "‚úÖ Protected attributes identified\n",
      "‚úÖ 15 metrics calculated\n",
      "\n",
      "======================================================================\n",
      "\n",
      "üìä SCORE: 6/7 criteria met (86%)\n",
      "\n",
      "üü° ‚ö†Ô∏è  MODEL WITH CAVEATS\n",
      "\n",
      "   Requires:\n",
      "   1. Detailed review of failed criteria\n",
      "   2. Exceptional approval from legal team\n",
      "   3. Documented mitigation plan\n",
      "   4. Intensified monitoring\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n‚úÖ PRODUCTION COMPLIANCE CHECKLIST\\n\" + \"=\"*70 + \"\\n\")\n",
    "\n",
    "# Approval criteria\n",
    "checklist = [\n",
    "    (\"EEOC 80% Rule (Gender)\", di_gender >= 0.8),\n",
    "    (\"EEOC 80% Rule (Race)\", all(race_approvals[r]/max_approval >= 0.8 for r in race_approvals)),\n",
    "    (\"Minimum accuracy (>= 0.70)\", clf.score(X_test, y_test) >= 0.70),\n",
    "    (\"HTML report generated\", True),\n",
    "    (\"Complete analysis documented\", True),\n",
    "    (\"Protected attributes identified\", True),\n",
    "    (\"15 metrics calculated\", True)\n",
    "]\n",
    "\n",
    "passed = 0\n",
    "total = len(checklist)\n",
    "\n",
    "for criterion, passes in checklist:\n",
    "    status = \"‚úÖ\" if passes else \"‚ùå\"\n",
    "    print(f\"{status} {criterion}\")\n",
    "    if passes:\n",
    "        passed += 1\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"\\nüìä SCORE: {passed}/{total} criteria met ({passed/total*100:.0f}%)\\n\")\n",
    "\n",
    "if passed == total:\n",
    "    print(\"üéâ ‚úÖ MODEL APPROVED FOR PRODUCTION!\")\n",
    "    print(\"\\n   Next steps:\")\n",
    "    print(\"   1. ‚úÖ Submit for legal team approval\")\n",
    "    print(\"   2. ‚úÖ Configure fairness monitoring in production\")\n",
    "    print(\"   3. ‚úÖ Establish re-validation frequency\")\n",
    "    print(\"   4. ‚úÖ Document audit process\")\n",
    "    print(\"   5. ‚úÖ Deploy!\")\n",
    "elif passed >= total * 0.8:\n",
    "    print(\"üü° ‚ö†Ô∏è  MODEL WITH CAVEATS\")\n",
    "    print(\"\\n   Requires:\")\n",
    "    print(\"   1. Detailed review of failed criteria\")\n",
    "    print(\"   2. Exceptional approval from legal team\")\n",
    "    print(\"   3. Documented mitigation plan\")\n",
    "    print(\"   4. Intensified monitoring\")\n",
    "else:\n",
    "    print(\"üî¥ ‚ùå MODEL FAILED\")\n",
    "    print(\"\\n   ‚ö†Ô∏è  CANNOT GO TO PRODUCTION\")\n",
    "    print(\"\\n   Required actions:\")\n",
    "    print(\"   1. Mitigate bias in data\")\n",
    "    print(\"   2. Apply fairness techniques (see notebook 03_bias_mitigation.ipynb)\")\n",
    "    print(\"   3. Re-train model\")\n",
    "    print(\"   4. Consider alternative models\")\n",
    "    print(\"   5. Consult fairness experts\")\n",
    "    print(\"   6. Re-run complete analysis\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-25",
   "metadata": {},
   "source": [
    "## üéâ Conclusion\n",
    "\n",
    "### What you did:\n",
    "- ‚úÖ **Complete Analysis** - 15 fairness metrics calculated\n",
    "- ‚úÖ **EEOC Compliance** - Verification of 80% Rule\n",
    "- ‚úÖ **Group Analysis** - Gender, race, age\n",
    "- ‚úÖ **Confusion Matrices** - Detailed performance by group\n",
    "- ‚úÖ **Threshold Analysis** - Fairness optimization\n",
    "- ‚úÖ **HTML Report** - Professional documentation\n",
    "- ‚úÖ **Deployment Decision** - Compliance checklist\n",
    "\n",
    "### Why this is CRITICAL:\n",
    "1. **Legal** - Compliance with Fair Lending Laws\n",
    "2. **Ethical** - Ensure fairness for all\n",
    "3. **Business** - Avoid million-dollar fines\n",
    "4. **Reputation** - Protect company brand\n",
    "\n",
    "### Applicable Regulations:\n",
    "- üá∫üá∏ **USA**: \n",
    "  - Equal Credit Opportunity Act (ECOA)\n",
    "  - Fair Housing Act\n",
    "  - EEOC Guidelines\n",
    "  - Fair Lending Laws\n",
    "- üá™üá∫ **Europe**: \n",
    "  - GDPR\n",
    "  - EU AI Act (proposed)\n",
    "- üáßüá∑ **Brazil**: \n",
    "  - LGPD\n",
    "\n",
    "### Real Cases of Consequences:\n",
    "- **Bank of America** (2011): $335 million in fines\n",
    "- **Wells Fargo** (2012): $175 million in fines\n",
    "- **Multiple banks** (2010s): Billions in settlements\n",
    "\n",
    "### Next Steps:\n",
    "- üìò `03_bias_mitigation.ipynb` - Techniques to correct bias\n",
    "- üìò `../05_casos_uso/01_credit_scoring.ipynb` - Complete end-to-end case\n",
    "\n",
    "<div style=\"background-color: #ffebee; padding: 20px; border-radius: 10px; border-left: 5px solid #d32f2f;\">\n",
    "<h3 style=\"color: #c62828; margin-top: 0;\">‚ö†Ô∏è IMPORTANT LEGAL NOTICE</h3>\n",
    "<p style=\"color: #b71c1c;\">\n",
    "<b>This notebook is educational.</b> For real production applications:\n",
    "</p>\n",
    "<ul style=\"color: #b71c1c;\">\n",
    "<li>‚úÖ Always consult the legal team</li>\n",
    "<li>‚úÖ Hire fairness ML experts</li>\n",
    "<li>‚úÖ Follow all local regulations</li>\n",
    "<li>‚úÖ Document EVERYTHING</li>\n",
    "<li>‚úÖ Monitor continuously in production</li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color: #e8f5e9; padding: 15px; border-radius: 5px; border-left: 5px solid #4caf50;\">\n",
    "<b>üí° Remember:</b> Fairness is not optional - it's mandatory, ethical, and essential!\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepbridge-3F2lzRH3-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
