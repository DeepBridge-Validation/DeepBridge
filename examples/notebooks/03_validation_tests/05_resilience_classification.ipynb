{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üõ°Ô∏è Resilience Testing - Classification\n",
        "\n",
        "<div style=\"background-color: #e3f2fd; padding: 15px; border-radius: 5px; border-left: 5px solid #2196F3;\">\n",
        "<b>üìì Information</b><br>\n",
        "<b>Level:</b> Intermediate/Advanced<br>\n",
        "<b>Time:</b> 20 minutes<br>\n",
        "<b>Dataset:</b> Breast Cancer (sklearn)<br>\n",
        "<b>Prerequisite:</b> Basic understanding of ML models\n",
        "</div>\n",
        "\n",
        "## üéØ Objectives\n",
        "- ‚úÖ Resilience testing for **classification** problems\n",
        "- ‚úÖ Generate **interactive HTML report**\n",
        "- ‚úÖ Export results to **JSON format**\n",
        "- ‚úÖ Analyze **data drift and concept drift**\n",
        "- ‚úÖ Evaluate **model stability** under distribution shifts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìö Why Resilience Testing?\n",
        "\n",
        "### Critical Contexts\n",
        "\n",
        "#### üè• Medicine - Disease Diagnosis\n",
        "- **Problem**: Model trained on Hospital A data, deployed in Hospital B\n",
        "- **Challenge**: Different patient demographics, equipment, protocols\n",
        "- **Impact**: Model performance may degrade silently\n",
        "- **Solution**: Resilience testing detects distribution shifts early\n",
        "\n",
        "#### üí≥ Finance - Credit Scoring\n",
        "- **Problem**: Model trained on pre-pandemic data\n",
        "- **Challenge**: Economic conditions changed dramatically\n",
        "- **Impact**: Credit risk patterns shifted significantly\n",
        "- **Solution**: Monitor resilience to detect when retraining is needed\n",
        "\n",
        "#### üîí Security - Fraud Detection\n",
        "- **Problem**: Fraudsters constantly evolve their tactics\n",
        "- **Challenge**: New fraud patterns emerge continuously\n",
        "- **Impact**: Model becomes less effective over time\n",
        "- **Solution**: Resilience metrics trigger retraining workflows\n",
        "\n",
        "### Types of Drift\n",
        "\n",
        "1. **Data Drift** (Covariate Shift)\n",
        "   - Feature distributions change\n",
        "   - Example: Age distribution shifts from 20-40 to 40-60\n",
        "\n",
        "2. **Concept Drift**\n",
        "   - Relationship between features and target changes\n",
        "   - Example: What constitutes \"fraud\" evolves over time\n",
        "\n",
        "3. **Performance Degradation**\n",
        "   - Model accuracy decreases on new data\n",
        "   - May be caused by data or concept drift"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1Ô∏è‚É£ Setup - Binary Classification Problem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-11-12 22:40:24,481 - deepbridge.reports - DEBUG - Using refactored FairnessDataTransformer\n",
            "2025-11-12 22:40:24,488 - deepbridge.reports - INFO - Successfully imported radar chart fix\n",
            "2025-11-12 22:40:24,489 - deepbridge.reports - INFO - Successfully patched EnhancedUncertaintyCharts.generate_model_metrics_comparison\n",
            "2025-11-12 22:40:24,489 - deepbridge.reports - INFO - Successfully applied enhanced_charts patch\n",
            "2025-11-12 22:40:24,491 - deepbridge.reports - INFO - Successfully loaded UncertaintyChartGenerator\n",
            "2025-11-12 22:40:24,493 - deepbridge.reports - INFO - Successfully imported and initialized SeabornChartGenerator\n",
            "2025-11-12 22:40:24,494 - deepbridge.reports - INFO - SeabornChartGenerator has_visualization_libs: True\n",
            "2025-11-12 22:40:24,495 - deepbridge.reports - INFO - Available chart methods: ['bar_chart', 'boxplot_chart', 'coverage_analysis_chart', 'detailed_boxplot_chart', 'distribution_grid_chart', 'feature_comparison_chart', 'feature_importance_chart', 'feature_psi_chart', 'generate_encoded_chart', 'heatmap_chart', 'individual_feature_impact_chart', 'method_comparison_chart', 'metrics_radar_chart', 'model_comparison_chart', 'model_metrics_heatmap', 'robustness_overview_chart', 'selected_features_comparison_chart', 'uncertainty_violin_chart', 'worst_performance_chart']\n",
            "2025-11-12 22:40:24,498 - deepbridge.reports - INFO - Successfully imported visualization libraries (numpy, matplotlib, seaborn, pandas)\n",
            "2025-11-12 22:40:24,503 - deepbridge.reports - INFO - Successfully loaded resilience-specific chart generator from deepbridge.templates.report_types.resilience.static.charts\n",
            "2025-11-12 22:40:24,504 - deepbridge.reports - INFO - Available resilience chart methods: ['generate_critical_feature_distributions', 'generate_distance_metrics_comparison', 'generate_feature_distance_heatmap', 'generate_feature_distribution_shift', 'generate_feature_residual_correlation', 'generate_model_comparison', 'generate_model_comparison_scatter', 'generate_model_resilience_scores', 'generate_performance_gap', 'generate_performance_gap_by_alpha', 'generate_residual_distribution']\n",
            "üìä Dataset: (569, 31)\n",
            "üè• Target: Cancer diagnosis (0=malignant, 1=benign)\n",
            "\n",
            "üìà Class distribution:\n",
            "target\n",
            "1    357\n",
            "0    212\n",
            "Name: count, dtype: int64\n",
            "\n",
            "üìä Class balance:\n",
            "target\n",
            "1    0.627417\n",
            "0    0.372583\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
        "from deepbridge import DBDataset, Experiment\n",
        "import os\n",
        "\n",
        "# Configure visualizations\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Load Breast Cancer dataset\n",
        "cancer = load_breast_cancer()\n",
        "df = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
        "df['target'] = cancer.target  # 0 = malignant, 1 = benign\n",
        "\n",
        "print(f\"üìä Dataset: {df.shape}\")\n",
        "print(f\"üè• Target: Cancer diagnosis (0=malignant, 1=benign)\")\n",
        "print(f\"\\nüìà Class distribution:\")\n",
        "print(df['target'].value_counts())\n",
        "print(f\"\\nüìä Class balance:\")\n",
        "print(df['target'].value_counts(normalize=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2Ô∏è‚É£ Train Classification Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Model trained!\n",
            "üìä Accuracy: 95.61%\n",
            "üìä ROC-AUC: 0.994\n",
            "\n",
            "üìã Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Malignant       0.95      0.93      0.94        42\n",
            "      Benign       0.96      0.97      0.97        72\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.96      0.95      0.95       114\n",
            "weighted avg       0.96      0.96      0.96       114\n",
            "\n"
          ]
        }
      ],
      "source": [
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Train RandomForest Classifier\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "y_proba = model.predict_proba(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "auc = roc_auc_score(y_test, y_proba[:, 1])\n",
        "\n",
        "print(f\"‚úÖ Model trained!\")\n",
        "print(f\"üìä Accuracy: {accuracy*100:.2f}%\")\n",
        "print(f\"üìä ROC-AUC: {auc:.3f}\")\n",
        "print(f\"\\nüìã Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=['Malignant', 'Benign']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3Ô∏è‚É£ Create Experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Initial model evaluation complete: RandomForestClassifier\n",
            "‚úÖ Experiment created!\n"
          ]
        }
      ],
      "source": [
        "dataset = DBDataset(\n",
        "    data=df,\n",
        "    target_column='target',\n",
        "    model=model,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    dataset_name='Breast Cancer Classification'\n",
        ")\n",
        "\n",
        "exp = Experiment(\n",
        "    dataset=dataset,\n",
        "    experiment_type='binary_classification',\n",
        "    tests=['resilience'],  # Specify resilience test\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Experiment created!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4Ô∏è‚É£ Run Resilience Test\n",
        "\n",
        "<div style=\"background-color: #fff3e0; padding: 15px; border-radius: 5px; border-left: 5px solid #ff9800;\">\n",
        "<b>‚ÑπÔ∏è Configuration:</b> Using 'full' config for comprehensive resilience analysis with multiple drift detection methods.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üß™ Running resilience test...\n",
            "\n",
            "‚úÖ Resilience Tests Finished!\n",
            "üéâ Test completed successfully: resilience\n",
            "\n",
            "‚úÖ Resilience test completed!\n",
            "\n",
            "üìä Result type: <class 'deepbridge.core.experiment.results.ExperimentResult'>\n",
            "üìä Resilience result type: <class 'dict'>\n"
          ]
        }
      ],
      "source": [
        "print(\"üß™ Running resilience test...\\n\")\n",
        "\n",
        "# Use run_tests() to store results internally for save_html() and save_json()\n",
        "experiment_result = exp.run_tests(config_name='full')\n",
        "\n",
        "print(\"\\n‚úÖ Resilience test completed!\")\n",
        "print(f\"\\nüìä Result type: {type(experiment_result)}\")\n",
        "\n",
        "# Access the resilience result\n",
        "resilience_result = experiment_result.get_result('resilience')\n",
        "print(f\"üìä Resilience result type: {type(resilience_result)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5Ô∏è‚É£ Generate Interactive HTML Report\n",
        "\n",
        "### Export comprehensive interactive report with:\n",
        "- üìä **Performance Analysis**: Model stability metrics\n",
        "- üìà **Drift Detection**: Data and concept drift analysis\n",
        "- üéØ **Feature Impact**: Features most affected by distribution shifts\n",
        "- üìâ **Resilience Scores**: Overall model robustness metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìù Generating interactive HTML report...\n",
            "\n",
            "2025-11-12 22:40:26,973 - deepbridge.reports - INFO - Generating SIMPLE resilience report to: /home/guhaase/projetos/DeepBridge/examples/notebooks/03_validation_tests/outputs/resilience_classification/resilience_classification_interactive.html\n",
            "2025-11-12 22:40:26,974 - deepbridge.reports - INFO - Report type: interactive\n",
            "2025-11-12 22:40:26,974 - deepbridge.reports - INFO - ================================================================================\n",
            "2025-11-12 22:40:26,975 - deepbridge.reports - INFO - TRANSFORMING RESILIENCE DATA FOR REPORT (SIMPLE)\n",
            "2025-11-12 22:40:26,975 - deepbridge.reports - INFO - ================================================================================\n",
            "2025-11-12 22:40:26,976 - deepbridge.reports - INFO - Top-level keys in results: ['primary_model', 'alternative_models', 'initial_results', 'initial_model_evaluation', 'config', 'experiment_type', 'model_type']\n",
            "2025-11-12 22:40:26,977 - deepbridge.reports - INFO - Using flat format: results['primary_model']\n",
            "2025-11-12 22:40:26,978 - deepbridge.reports - INFO - primary_model keys: ['distribution_shift', 'worst_sample', 'worst_cluster', 'outer_sample', 'hard_sample', 'resilience_score', 'test_scores', 'alphas', 'distance_metrics', 'metrics', 'model_type']\n",
            "2025-11-12 22:40:26,979 - deepbridge.reports - INFO - initial_eval keys: ['config', 'models', 'test_configs']\n",
            "2025-11-12 22:40:26,980 - deepbridge.reports - INFO - ======================================================================\n",
            "2025-11-12 22:40:26,980 - deepbridge.reports - INFO - TRANSFORMING SCENARIOS FOR OVERVIEW CHART\n",
            "2025-11-12 22:40:26,981 - deepbridge.reports - INFO - Raw scenarios from distribution_shift.all_results: 9\n",
            "2025-11-12 22:40:26,981 - deepbridge.reports - INFO - Raw scenario 1: {'method': 'distribution_shift', 'alpha': 0.1, 'metric': 'auc', 'distance_metric': 'PSI', 'worst_metric': np.float64(1.0), 'remaining_metric': np.float64(1.0), 'performance_gap': np.float64(0.0), 'feature_distances': {'distance_metric': 'PSI', 'all_feature_distances': {'mean radius': np.float64(2.3894829189215883), 'mean texture': np.float64(0.310839210540975), 'mean perimeter': np.float64(4.067110193766382), 'mean area': np.float64(2.4789416100261596), 'mean smoothness': np.float64(0.9511570481957651), 'mean compactness': np.float64(0.4455713291476787), 'mean concavity': np.float64(2.5895992807585877), 'mean concave points': np.float64(9.23073692035359), 'mean symmetry': np.float64(1.2524634817729559), 'mean fractal dimension': np.float64(0.5254501884443914), 'radius error': np.float64(0.30639068527586377), 'texture error': np.float64(0.2998410451380271), 'perimeter error': np.float64(0.3088670149449014), 'area error': np.float64(1.2236523087350515), 'smoothness error': np.float64(1.2496313108147266), 'compactness error': np.float64(0.25661249455078217), 'concavity error': np.float64(1.0191456647212034), 'concave points error': np.float64(0.8835496305642814), 'symmetry error': np.float64(0.5357321690256008), 'fractal dimension error': np.float64(0.7627108880106327), 'worst radius': np.float64(4.735444160052765), 'worst texture': np.float64(0.2935908215287698), 'worst perimeter': np.float64(4.592804357626489), 'worst area': np.float64(2.8924379464247862), 'worst smoothness': np.float64(1.523080203073358), 'worst compactness': np.float64(0.8107792819516635), 'worst concavity': np.float64(0.6129825450183315), 'worst concave points': np.float64(1.347926988439272), 'worst symmetry': np.float64(1.2387956421205957), 'worst fractal dimension': np.float64(0.834539423255618)}, 'top_features': {'mean concave points': np.float64(9.23073692035359), 'worst radius': np.float64(4.735444160052765), 'worst perimeter': np.float64(4.592804357626489), 'mean perimeter': np.float64(4.067110193766382), 'worst area': np.float64(2.8924379464247862), 'mean concavity': np.float64(2.5895992807585877), 'mean area': np.float64(2.4789416100261596), 'mean radius': np.float64(2.3894829189215883), 'worst smoothness': np.float64(1.523080203073358), 'worst concave points': np.float64(1.347926988439272)}}, 'worst_sample_count': 45, 'remaining_sample_count': 410}\n",
            "2025-11-12 22:40:26,982 - deepbridge.reports - INFO - Transformed scenario 1: is_valid=True, gap=0.0, metric=PSI, alpha=0.1\n",
            "2025-11-12 22:40:26,982 - deepbridge.reports - INFO - Raw scenario 2: {'method': 'distribution_shift', 'alpha': 0.2, 'metric': 'auc', 'distance_metric': 'PSI', 'worst_metric': np.float64(1.0), 'remaining_metric': np.float64(1.0), 'performance_gap': np.float64(0.0), 'feature_distances': {'distance_metric': 'PSI', 'all_feature_distances': {'mean radius': np.float64(3.076999359840647), 'mean texture': np.float64(0.44190552502039965), 'mean perimeter': np.float64(2.5147566313722685), 'mean area': np.float64(3.154399249942336), 'mean smoothness': np.float64(0.8864708725171488), 'mean compactness': np.float64(0.6019614641699295), 'mean concavity': np.float64(0.8243066401163321), 'mean concave points': np.float64(2.2738369505083544), 'mean symmetry': np.float64(1.2438695163816038), 'mean fractal dimension': np.float64(1.10941223480896), 'radius error': np.float64(0.5431157380683479), 'texture error': np.float64(0.2984717830267041), 'perimeter error': np.float64(0.5519359858029487), 'area error': np.float64(1.401254120957802), 'smoothness error': np.float64(0.6208621997584081), 'compactness error': np.float64(0.2368950811905482), 'concavity error': np.float64(0.5848559902798853), 'concave points error': np.float64(0.5686135076333974), 'symmetry error': np.float64(0.18291777954695093), 'fractal dimension error': np.float64(0.429153899097412), 'worst radius': np.float64(3.6956703271071225), 'worst texture': np.float64(0.33348238975049094), 'worst perimeter': np.float64(4.857991263802467), 'worst area': np.float64(2.9405339462942925), 'worst smoothness': np.float64(1.230489636292978), 'worst compactness': np.float64(0.4559923155404126), 'worst concavity': np.float64(0.5859454755518527), 'worst concave points': np.float64(1.6307679032885343), 'worst symmetry': np.float64(0.7011403875218685), 'worst fractal dimension': np.float64(0.5181065612907171)}, 'top_features': {'worst perimeter': np.float64(4.857991263802467), 'worst radius': np.float64(3.6956703271071225), 'mean area': np.float64(3.154399249942336), 'mean radius': np.float64(3.076999359840647), 'worst area': np.float64(2.9405339462942925), 'mean perimeter': np.float64(2.5147566313722685), 'mean concave points': np.float64(2.2738369505083544), 'worst concave points': np.float64(1.6307679032885343), 'area error': np.float64(1.401254120957802), 'mean symmetry': np.float64(1.2438695163816038)}}, 'worst_sample_count': 91, 'remaining_sample_count': 364}\n",
            "2025-11-12 22:40:26,983 - deepbridge.reports - INFO - Transformed scenario 2: is_valid=True, gap=0.0, metric=PSI, alpha=0.2\n",
            "2025-11-12 22:40:26,984 - deepbridge.reports - INFO - Raw scenario 3: {'method': 'distribution_shift', 'alpha': 0.3, 'metric': 'auc', 'distance_metric': 'PSI', 'worst_metric': np.float64(1.0), 'remaining_metric': np.float64(1.0), 'performance_gap': np.float64(0.0), 'feature_distances': {'distance_metric': 'PSI', 'all_feature_distances': {'mean radius': np.float64(1.3712802054917677), 'mean texture': np.float64(0.4718275511749656), 'mean perimeter': np.float64(1.288058196916187), 'mean area': np.float64(1.5192832391931619), 'mean smoothness': np.float64(0.8032987035186415), 'mean compactness': np.float64(0.41277088897276115), 'mean concavity': np.float64(0.662890780999605), 'mean concave points': np.float64(2.356846644817519), 'mean symmetry': np.float64(0.03842152969612964), 'mean fractal dimension': np.float64(1.2352475644791745), 'radius error': np.float64(0.28592728685885405), 'texture error': np.float64(0.343384397503603), 'perimeter error': np.float64(0.45699479312731267), 'area error': np.float64(0.5403957011468286), 'smoothness error': np.float64(0.5128361587805498), 'compactness error': np.float64(0.323460116570256), 'concavity error': np.float64(0.40584084423078787), 'concave points error': np.float64(0.4940817866282793), 'symmetry error': np.float64(0.2425648350847542), 'fractal dimension error': np.float64(0.359138678060567), 'worst radius': np.float64(2.336847849275482), 'worst texture': np.float64(0.37171470520787603), 'worst perimeter': np.float64(2.292138645541036), 'worst area': np.float64(1.3286971091715207), 'worst smoothness': np.float64(1.0143853522226067), 'worst compactness': np.float64(0.9397928353214188), 'worst concavity': np.float64(0.57163683727167), 'worst concave points': np.float64(0.9424167433459241), 'worst symmetry': np.float64(0.466729028492946), 'worst fractal dimension': np.float64(0.671987576260843)}, 'top_features': {'mean concave points': np.float64(2.356846644817519), 'worst radius': np.float64(2.336847849275482), 'worst perimeter': np.float64(2.292138645541036), 'mean area': np.float64(1.5192832391931619), 'mean radius': np.float64(1.3712802054917677), 'worst area': np.float64(1.3286971091715207), 'mean perimeter': np.float64(1.288058196916187), 'mean fractal dimension': np.float64(1.2352475644791745), 'worst smoothness': np.float64(1.0143853522226067), 'worst concave points': np.float64(0.9424167433459241)}}, 'worst_sample_count': 136, 'remaining_sample_count': 319}\n",
            "2025-11-12 22:40:26,985 - deepbridge.reports - INFO - Transformed scenario 3: is_valid=True, gap=0.0, metric=PSI, alpha=0.3\n",
            "2025-11-12 22:40:26,985 - deepbridge.reports - INFO - Raw scenario 4: {'method': 'distribution_shift', 'alpha': 0.1, 'metric': 'auc', 'distance_metric': 'WD1', 'worst_metric': np.float64(1.0), 'remaining_metric': np.float64(1.0), 'performance_gap': np.float64(0.0), 'feature_distances': {'distance_metric': 'WD1', 'all_feature_distances': {'mean radius': np.float64(1.5063474254742548), 'mean texture': np.float64(0.43687804878048797), 'mean perimeter': np.float64(11.484428184281844), 'mean area': np.float64(148.60563685636856), 'mean smoothness': np.float64(0.0018559566395663948), 'mean compactness': np.float64(0.009530455284552847), 'mean concavity': np.float64(0.022112478238482385), 'mean concave points': np.float64(0.018398693224932247), 'mean symmetry': np.float64(0.004864417344173438), 'mean fractal dimension': np.float64(0.002393661246612465), 'radius error': np.float64(0.04755531165311652), 'texture error': np.float64(0.08823682926829265), 'perimeter error': np.float64(0.3664914092140922), 'area error': np.float64(12.498735772357726), 'smoothness error': np.float64(0.001196521138211382), 'compactness error': np.float64(0.0050201626016260145), 'concavity error': np.float64(0.0179955050406504), 'concave points error': np.float64(0.002377486991869919), 'symmetry error': np.float64(0.0023479460704607037), 'fractal dimension error': np.float64(0.0008932740108401085), 'worst radius': np.float64(2.5788314363143634), 'worst texture': np.float64(0.7825013550135506), 'worst perimeter': np.float64(19.607146341463416), 'worst area': np.float64(279.1091869918699), 'worst smoothness': np.float64(0.00542820596205962), 'worst compactness': np.float64(0.0571680081300813), 'worst concavity': np.float64(0.09179097208672087), 'worst concave points': np.float64(0.02967718997289973), 'worst symmetry': np.float64(0.021005338753387528), 'worst fractal dimension': np.float64(0.006529850948509486)}, 'top_features': {'worst area': np.float64(279.1091869918699), 'mean area': np.float64(148.60563685636856), 'worst perimeter': np.float64(19.607146341463416), 'area error': np.float64(12.498735772357726), 'mean perimeter': np.float64(11.484428184281844), 'worst radius': np.float64(2.5788314363143634), 'mean radius': np.float64(1.5063474254742548), 'worst texture': np.float64(0.7825013550135506), 'mean texture': np.float64(0.43687804878048797), 'perimeter error': np.float64(0.3664914092140922)}}, 'worst_sample_count': 45, 'remaining_sample_count': 410}\n",
            "2025-11-12 22:40:26,986 - deepbridge.reports - INFO - Transformed scenario 4: is_valid=True, gap=0.0, metric=WD1, alpha=0.1\n",
            "2025-11-12 22:40:26,986 - deepbridge.reports - INFO - Raw scenario 5: {'method': 'distribution_shift', 'alpha': 0.2, 'metric': 'auc', 'distance_metric': 'WD1', 'worst_metric': np.float64(1.0), 'remaining_metric': np.float64(1.0), 'performance_gap': np.float64(0.0), 'feature_distances': {'distance_metric': 'WD1', 'all_feature_distances': {'mean radius': np.float64(1.6860576923076924), 'mean texture': np.float64(0.6814285714285713), 'mean perimeter': np.float64(12.470082417582416), 'mean area': np.float64(162.7425824175824), 'mean smoothness': np.float64(0.0016054395604395617), 'mean compactness': np.float64(0.016213736263736265), 'mean concavity': np.float64(0.024593429395604393), 'mean concave points': np.float64(0.018443329670329675), 'mean symmetry': np.float64(0.0025684065934065926), 'mean fractal dimension': np.float64(0.002328021978021978), 'radius error': np.float64(0.05855714285714278), 'texture error': np.float64(0.0637862637362637), 'perimeter error': np.float64(0.5211832417582412), 'area error': np.float64(14.258837912087902), 'smoothness error': np.float64(0.0006977390109890109), 'compactness error': np.float64(0.006888403846153846), 'concavity error': np.float64(0.01697721263736264), 'concave points error': np.float64(0.0028628681318681316), 'symmetry error': np.float64(0.0017541840659340661), 'fractal dimension error': np.float64(0.0010369695054945058), 'worst radius': np.float64(2.6574725274725277), 'worst texture': np.float64(0.8156868131868131), 'worst perimeter': np.float64(19.645906593406597), 'worst area': np.float64(286.6637362637363), 'worst smoothness': np.float64(0.005089478021978021), 'worst compactness': np.float64(0.049816208791208794), 'worst concavity': np.float64(0.07992410164835162), 'worst concave points': np.float64(0.03217343131868132), 'worst symmetry': np.float64(0.009355769230769232), 'worst fractal dimension': np.float64(0.005590714285714284)}, 'top_features': {'worst area': np.float64(286.6637362637363), 'mean area': np.float64(162.7425824175824), 'worst perimeter': np.float64(19.645906593406597), 'area error': np.float64(14.258837912087902), 'mean perimeter': np.float64(12.470082417582416), 'worst radius': np.float64(2.6574725274725277), 'mean radius': np.float64(1.6860576923076924), 'worst texture': np.float64(0.8156868131868131), 'mean texture': np.float64(0.6814285714285713), 'perimeter error': np.float64(0.5211832417582412)}}, 'worst_sample_count': 91, 'remaining_sample_count': 364}\n",
            "2025-11-12 22:40:26,987 - deepbridge.reports - INFO - Transformed scenario 5: is_valid=True, gap=0.0, metric=WD1, alpha=0.2\n",
            "2025-11-12 22:40:26,988 - deepbridge.reports - INFO - Raw scenario 6: {'method': 'distribution_shift', 'alpha': 0.3, 'metric': 'auc', 'distance_metric': 'WD1', 'worst_metric': np.float64(1.0), 'remaining_metric': np.float64(1.0), 'performance_gap': np.float64(0.0), 'feature_distances': {'distance_metric': 'WD1', 'all_feature_distances': {'mean radius': np.float64(1.4960918080398304), 'mean texture': np.float64(0.6152074497510605), 'mean perimeter': np.float64(11.027182371381155), 'mean area': np.float64(148.70689194172965), 'mean smoothness': np.float64(0.0022402028397565913), 'mean compactness': np.float64(0.015289454637654434), 'mean concavity': np.float64(0.02348699056795131), 'mean concave points': np.float64(0.01709038094689286), 'mean symmetry': np.float64(0.004159715563341322), 'mean fractal dimension': np.float64(0.002527744560206527), 'radius error': np.float64(0.0567219527936566), 'texture error': np.float64(0.09645540752351098), 'perimeter error': np.float64(0.40973751152498583), 'area error': np.float64(12.856185782777057), 'smoothness error': np.float64(0.0004569581643002023), 'compactness error': np.float64(0.006982835192697767), 'concavity error': np.float64(0.015019355151668808), 'concave points error': np.float64(0.002692145468375437), 'symmetry error': np.float64(0.0016794911257606482), 'fractal dimension error': np.float64(0.0008672260649087212), 'worst radius': np.float64(2.4223179974184035), 'worst texture': np.float64(1.0802431772081875), 'worst perimeter': np.float64(17.420476903927714), 'worst area': np.float64(271.4762078185507), 'worst smoothness': np.float64(0.003465754656094413), 'worst compactness': np.float64(0.05842959962198045), 'worst concavity': np.float64(0.08115963910658305), 'worst concave points': np.float64(0.02955723294302047), 'worst symmetry': np.float64(0.019103641895629724), 'worst fractal dimension': np.float64(0.0070903950765259065)}, 'top_features': {'worst area': np.float64(271.4762078185507), 'mean area': np.float64(148.70689194172965), 'worst perimeter': np.float64(17.420476903927714), 'area error': np.float64(12.856185782777057), 'mean perimeter': np.float64(11.027182371381155), 'worst radius': np.float64(2.4223179974184035), 'mean radius': np.float64(1.4960918080398304), 'worst texture': np.float64(1.0802431772081875), 'mean texture': np.float64(0.6152074497510605), 'perimeter error': np.float64(0.40973751152498583)}}, 'worst_sample_count': 136, 'remaining_sample_count': 319}\n",
            "2025-11-12 22:40:26,988 - deepbridge.reports - INFO - Transformed scenario 6: is_valid=True, gap=0.0, metric=WD1, alpha=0.3\n",
            "2025-11-12 22:40:26,989 - deepbridge.reports - INFO - Raw scenario 7: {'method': 'distribution_shift', 'alpha': 0.1, 'metric': 'auc', 'distance_metric': 'KS', 'worst_metric': np.float64(1.0), 'remaining_metric': np.float64(1.0), 'performance_gap': np.float64(0.0), 'feature_distances': {'distance_metric': 'KS', 'all_feature_distances': {'mean radius': np.float64(0.2062330623306233), 'mean texture': np.float64(0.07208672086720867), 'mean perimeter': np.float64(0.23441734417344173), 'mean area': np.float64(0.21734417344173443), 'mean smoothness': np.float64(0.06829268292682927), 'mean compactness': np.float64(0.14092140921409213), 'mean concavity': np.float64(0.2861788617886179), 'mean concave points': np.float64(0.36260162601626017), 'mean symmetry': np.float64(0.1016260162601626), 'mean fractal dimension': np.float64(0.14905149051490515), 'radius error': np.float64(0.12168021680216802), 'texture error': np.float64(0.1046070460704607), 'perimeter error': np.float64(0.0983739837398374), 'area error': np.float64(0.18997289972899728), 'smoothness error': np.float64(0.17615176151761516), 'compactness error': np.float64(0.11002710027100271), 'concavity error': np.float64(0.18997289972899728), 'concave points error': np.float64(0.1802168021680217), 'symmetry error': np.float64(0.22764227642276422), 'fractal dimension error': np.float64(0.16910569105691056), 'worst radius': np.float64(0.2975609756097561), 'worst texture': np.float64(0.08536585365853659), 'worst perimeter': np.float64(0.32818428184281845), 'worst area': np.float64(0.27940379403794036), 'worst smoothness': np.float64(0.10650406504065041), 'worst compactness': np.float64(0.25094850948509484), 'worst concavity': np.float64(0.2693766937669377), 'worst concave points': np.float64(0.34119241192411925), 'worst symmetry': np.float64(0.1021680216802168), 'worst fractal dimension': np.float64(0.16775067750677508)}, 'top_features': {'mean concave points': np.float64(0.36260162601626017), 'worst concave points': np.float64(0.34119241192411925), 'worst perimeter': np.float64(0.32818428184281845), 'worst radius': np.float64(0.2975609756097561), 'mean concavity': np.float64(0.2861788617886179), 'worst area': np.float64(0.27940379403794036), 'worst concavity': np.float64(0.2693766937669377), 'worst compactness': np.float64(0.25094850948509484), 'mean perimeter': np.float64(0.23441734417344173), 'symmetry error': np.float64(0.22764227642276422)}}, 'worst_sample_count': 45, 'remaining_sample_count': 410}\n",
            "2025-11-12 22:40:26,989 - deepbridge.reports - INFO - Transformed scenario 7: is_valid=True, gap=0.0, metric=KS, alpha=0.1\n",
            "2025-11-12 22:40:26,991 - deepbridge.reports - INFO - Raw scenario 8: {'method': 'distribution_shift', 'alpha': 0.2, 'metric': 'auc', 'distance_metric': 'KS', 'worst_metric': np.float64(1.0), 'remaining_metric': np.float64(1.0), 'performance_gap': np.float64(0.0), 'feature_distances': {'distance_metric': 'KS', 'all_feature_distances': {'mean radius': np.float64(0.30494505494505497), 'mean texture': np.float64(0.13736263736263737), 'mean perimeter': np.float64(0.32142857142857145), 'mean area': np.float64(0.29120879120879123), 'mean smoothness': np.float64(0.06868131868131869), 'mean compactness': np.float64(0.2087912087912088), 'mean concavity': np.float64(0.3159340659340659), 'mean concave points': np.float64(0.37362637362637363), 'mean symmetry': np.float64(0.06043956043956044), 'mean fractal dimension': np.float64(0.14285714285714285), 'radius error': np.float64(0.08241758241758242), 'texture error': np.float64(0.08791208791208792), 'perimeter error': np.float64(0.12912087912087913), 'area error': np.float64(0.1565934065934066), 'smoothness error': np.float64(0.14835164835164835), 'compactness error': np.float64(0.17857142857142858), 'concavity error': np.float64(0.18406593406593408), 'concave points error': np.float64(0.22802197802197802), 'symmetry error': np.float64(0.1620879120879121), 'fractal dimension error': np.float64(0.1620879120879121), 'worst radius': np.float64(0.36538461538461536), 'worst texture': np.float64(0.0989010989010989), 'worst perimeter': np.float64(0.3598901098901099), 'worst area': np.float64(0.33791208791208793), 'worst smoothness': np.float64(0.11538461538461539), 'worst compactness': np.float64(0.23351648351648352), 'worst concavity': np.float64(0.3131868131868132), 'worst concave points': np.float64(0.35714285714285715), 'worst symmetry': np.float64(0.06043956043956044), 'worst fractal dimension': np.float64(0.15384615384615385)}, 'top_features': {'mean concave points': np.float64(0.37362637362637363), 'worst radius': np.float64(0.36538461538461536), 'worst perimeter': np.float64(0.3598901098901099), 'worst concave points': np.float64(0.35714285714285715), 'worst area': np.float64(0.33791208791208793), 'mean perimeter': np.float64(0.32142857142857145), 'mean concavity': np.float64(0.3159340659340659), 'worst concavity': np.float64(0.3131868131868132), 'mean radius': np.float64(0.30494505494505497), 'mean area': np.float64(0.29120879120879123)}}, 'worst_sample_count': 91, 'remaining_sample_count': 364}\n",
            "2025-11-12 22:40:26,991 - deepbridge.reports - INFO - Transformed scenario 8: is_valid=True, gap=0.0, metric=KS, alpha=0.2\n",
            "2025-11-12 22:40:26,992 - deepbridge.reports - INFO - Raw scenario 9: {'method': 'distribution_shift', 'alpha': 0.3, 'metric': 'auc', 'distance_metric': 'KS', 'worst_metric': np.float64(1.0), 'remaining_metric': np.float64(1.0), 'performance_gap': np.float64(0.0), 'feature_distances': {'distance_metric': 'KS', 'all_feature_distances': {'mean radius': np.float64(0.21514844182186982), 'mean texture': np.float64(0.10981006822791813), 'mean perimeter': np.float64(0.25059929928084085), 'mean area': np.float64(0.21936658676009588), 'mean smoothness': np.float64(0.0818043518347778), 'mean compactness': np.float64(0.19587866494560208), 'mean concavity': np.float64(0.31774386870735755), 'mean concave points': np.float64(0.34727088327494005), 'mean symmetry': np.float64(0.09434353678775585), 'mean fractal dimension': np.float64(0.13811543426147888), 'radius error': np.float64(0.09950673059192329), 'texture error': np.float64(0.10141987829614604), 'perimeter error': np.float64(0.0927761386686336), 'area error': np.float64(0.16510695187165775), 'smoothness error': np.float64(0.11720910934906878), 'compactness error': np.float64(0.18167988198414162), 'concavity error': np.float64(0.20226350728379125), 'concave points error': np.float64(0.24774110271067676), 'symmetry error': np.float64(0.08551539738152314), 'fractal dimension error': np.float64(0.1295177945786465), 'worst radius': np.float64(0.2870182555780933), 'worst texture': np.float64(0.10547667342799188), 'worst perimeter': np.float64(0.28810160427807485), 'worst area': np.float64(0.26917757698690764), 'worst smoothness': np.float64(0.08761294486446616), 'worst compactness': np.float64(0.2075650009219989), 'worst concavity': np.float64(0.31546192144569424), 'worst concave points': np.float64(0.30919232896920523), 'worst symmetry': np.float64(0.11070901714917943), 'worst fractal dimension': np.float64(0.15293656647612022)}, 'top_features': {'mean concave points': np.float64(0.34727088327494005), 'mean concavity': np.float64(0.31774386870735755), 'worst concavity': np.float64(0.31546192144569424), 'worst concave points': np.float64(0.30919232896920523), 'worst perimeter': np.float64(0.28810160427807485), 'worst radius': np.float64(0.2870182555780933), 'worst area': np.float64(0.26917757698690764), 'mean perimeter': np.float64(0.25059929928084085), 'concave points error': np.float64(0.24774110271067676), 'mean area': np.float64(0.21936658676009588)}}, 'worst_sample_count': 136, 'remaining_sample_count': 319}\n",
            "2025-11-12 22:40:26,992 - deepbridge.reports - INFO - Transformed scenario 9: is_valid=True, gap=0.0, metric=KS, alpha=0.3\n",
            "2025-11-12 22:40:26,993 - deepbridge.reports - INFO - Total valid scenarios: 9\n",
            "2025-11-12 22:40:26,993 - deepbridge.reports - INFO - ======================================================================\n",
            "2025-11-12 22:40:26,994 - deepbridge.reports - INFO - ================================================================================\n",
            "2025-11-12 22:40:26,994 - deepbridge.reports - INFO - PREPARING FEATURES TABLE DATA\n",
            "2025-11-12 22:40:26,995 - deepbridge.reports - INFO - ================================================================================\n",
            "2025-11-12 22:40:26,995 - deepbridge.reports - INFO - Prepared 30 features for table\n",
            "2025-11-12 22:40:26,996 - deepbridge.reports - INFO - Sample: {'name': 'worst area', 'missing_impact': 0.0, 'importance': 0.14001598566310833}\n",
            "2025-11-12 22:40:26,996 - deepbridge.reports - INFO - ================================================================================\n",
            "2025-11-12 22:40:26,996 - deepbridge.reports - INFO - ================================================================================\n",
            "2025-11-12 22:40:26,997 - deepbridge.reports - INFO - PREPARING CHARTS FOR RESILIENCE REPORT\n",
            "2025-11-12 22:40:26,997 - deepbridge.reports - INFO - ================================================================================\n",
            "2025-11-12 22:40:26,998 - deepbridge.reports - INFO - Checking for missing data information in primary_model...\n",
            "2025-11-12 22:40:26,998 - deepbridge.reports - INFO - Keys in primary_model: ['distribution_shift', 'worst_sample', 'worst_cluster', 'outer_sample', 'hard_sample', 'resilience_score', 'test_scores', 'alphas', 'distance_metrics', 'metrics', 'model_type']\n",
            "2025-11-12 22:40:26,999 - deepbridge.reports - WARNING - ‚úó 'missing_data' NOT found in primary_model\n",
            "2025-11-12 22:40:26,999 - deepbridge.reports - WARNING - ‚úó 'by_level' NOT found in primary_model\n",
            "2025-11-12 22:40:26,999 - deepbridge.reports - INFO - ======================================================================\n",
            "2025-11-12 22:40:27,002 - deepbridge.reports - INFO - TRANSFORMING SCENARIOS FOR OVERVIEW CHART\n",
            "2025-11-12 22:40:27,003 - deepbridge.reports - INFO - Raw scenarios from distribution_shift.all_results: 9\n",
            "2025-11-12 22:40:27,003 - deepbridge.reports - INFO - Raw scenario 1: {'method': 'distribution_shift', 'alpha': 0.1, 'metric': 'auc', 'distance_metric': 'PSI', 'worst_metric': np.float64(1.0), 'remaining_metric': np.float64(1.0), 'performance_gap': np.float64(0.0), 'feature_distances': {'distance_metric': 'PSI', 'all_feature_distances': {'mean radius': np.float64(2.3894829189215883), 'mean texture': np.float64(0.310839210540975), 'mean perimeter': np.float64(4.067110193766382), 'mean area': np.float64(2.4789416100261596), 'mean smoothness': np.float64(0.9511570481957651), 'mean compactness': np.float64(0.4455713291476787), 'mean concavity': np.float64(2.5895992807585877), 'mean concave points': np.float64(9.23073692035359), 'mean symmetry': np.float64(1.2524634817729559), 'mean fractal dimension': np.float64(0.5254501884443914), 'radius error': np.float64(0.30639068527586377), 'texture error': np.float64(0.2998410451380271), 'perimeter error': np.float64(0.3088670149449014), 'area error': np.float64(1.2236523087350515), 'smoothness error': np.float64(1.2496313108147266), 'compactness error': np.float64(0.25661249455078217), 'concavity error': np.float64(1.0191456647212034), 'concave points error': np.float64(0.8835496305642814), 'symmetry error': np.float64(0.5357321690256008), 'fractal dimension error': np.float64(0.7627108880106327), 'worst radius': np.float64(4.735444160052765), 'worst texture': np.float64(0.2935908215287698), 'worst perimeter': np.float64(4.592804357626489), 'worst area': np.float64(2.8924379464247862), 'worst smoothness': np.float64(1.523080203073358), 'worst compactness': np.float64(0.8107792819516635), 'worst concavity': np.float64(0.6129825450183315), 'worst concave points': np.float64(1.347926988439272), 'worst symmetry': np.float64(1.2387956421205957), 'worst fractal dimension': np.float64(0.834539423255618)}, 'top_features': {'mean concave points': np.float64(9.23073692035359), 'worst radius': np.float64(4.735444160052765), 'worst perimeter': np.float64(4.592804357626489), 'mean perimeter': np.float64(4.067110193766382), 'worst area': np.float64(2.8924379464247862), 'mean concavity': np.float64(2.5895992807585877), 'mean area': np.float64(2.4789416100261596), 'mean radius': np.float64(2.3894829189215883), 'worst smoothness': np.float64(1.523080203073358), 'worst concave points': np.float64(1.347926988439272)}}, 'worst_sample_count': 45, 'remaining_sample_count': 410}\n",
            "2025-11-12 22:40:27,004 - deepbridge.reports - INFO - Transformed scenario 1: is_valid=True, gap=0.0, metric=PSI, alpha=0.1\n",
            "2025-11-12 22:40:27,007 - deepbridge.reports - INFO - Raw scenario 2: {'method': 'distribution_shift', 'alpha': 0.2, 'metric': 'auc', 'distance_metric': 'PSI', 'worst_metric': np.float64(1.0), 'remaining_metric': np.float64(1.0), 'performance_gap': np.float64(0.0), 'feature_distances': {'distance_metric': 'PSI', 'all_feature_distances': {'mean radius': np.float64(3.076999359840647), 'mean texture': np.float64(0.44190552502039965), 'mean perimeter': np.float64(2.5147566313722685), 'mean area': np.float64(3.154399249942336), 'mean smoothness': np.float64(0.8864708725171488), 'mean compactness': np.float64(0.6019614641699295), 'mean concavity': np.float64(0.8243066401163321), 'mean concave points': np.float64(2.2738369505083544), 'mean symmetry': np.float64(1.2438695163816038), 'mean fractal dimension': np.float64(1.10941223480896), 'radius error': np.float64(0.5431157380683479), 'texture error': np.float64(0.2984717830267041), 'perimeter error': np.float64(0.5519359858029487), 'area error': np.float64(1.401254120957802), 'smoothness error': np.float64(0.6208621997584081), 'compactness error': np.float64(0.2368950811905482), 'concavity error': np.float64(0.5848559902798853), 'concave points error': np.float64(0.5686135076333974), 'symmetry error': np.float64(0.18291777954695093), 'fractal dimension error': np.float64(0.429153899097412), 'worst radius': np.float64(3.6956703271071225), 'worst texture': np.float64(0.33348238975049094), 'worst perimeter': np.float64(4.857991263802467), 'worst area': np.float64(2.9405339462942925), 'worst smoothness': np.float64(1.230489636292978), 'worst compactness': np.float64(0.4559923155404126), 'worst concavity': np.float64(0.5859454755518527), 'worst concave points': np.float64(1.6307679032885343), 'worst symmetry': np.float64(0.7011403875218685), 'worst fractal dimension': np.float64(0.5181065612907171)}, 'top_features': {'worst perimeter': np.float64(4.857991263802467), 'worst radius': np.float64(3.6956703271071225), 'mean area': np.float64(3.154399249942336), 'mean radius': np.float64(3.076999359840647), 'worst area': np.float64(2.9405339462942925), 'mean perimeter': np.float64(2.5147566313722685), 'mean concave points': np.float64(2.2738369505083544), 'worst concave points': np.float64(1.6307679032885343), 'area error': np.float64(1.401254120957802), 'mean symmetry': np.float64(1.2438695163816038)}}, 'worst_sample_count': 91, 'remaining_sample_count': 364}\n",
            "2025-11-12 22:40:27,007 - deepbridge.reports - INFO - Transformed scenario 2: is_valid=True, gap=0.0, metric=PSI, alpha=0.2\n",
            "2025-11-12 22:40:27,008 - deepbridge.reports - INFO - Raw scenario 3: {'method': 'distribution_shift', 'alpha': 0.3, 'metric': 'auc', 'distance_metric': 'PSI', 'worst_metric': np.float64(1.0), 'remaining_metric': np.float64(1.0), 'performance_gap': np.float64(0.0), 'feature_distances': {'distance_metric': 'PSI', 'all_feature_distances': {'mean radius': np.float64(1.3712802054917677), 'mean texture': np.float64(0.4718275511749656), 'mean perimeter': np.float64(1.288058196916187), 'mean area': np.float64(1.5192832391931619), 'mean smoothness': np.float64(0.8032987035186415), 'mean compactness': np.float64(0.41277088897276115), 'mean concavity': np.float64(0.662890780999605), 'mean concave points': np.float64(2.356846644817519), 'mean symmetry': np.float64(0.03842152969612964), 'mean fractal dimension': np.float64(1.2352475644791745), 'radius error': np.float64(0.28592728685885405), 'texture error': np.float64(0.343384397503603), 'perimeter error': np.float64(0.45699479312731267), 'area error': np.float64(0.5403957011468286), 'smoothness error': np.float64(0.5128361587805498), 'compactness error': np.float64(0.323460116570256), 'concavity error': np.float64(0.40584084423078787), 'concave points error': np.float64(0.4940817866282793), 'symmetry error': np.float64(0.2425648350847542), 'fractal dimension error': np.float64(0.359138678060567), 'worst radius': np.float64(2.336847849275482), 'worst texture': np.float64(0.37171470520787603), 'worst perimeter': np.float64(2.292138645541036), 'worst area': np.float64(1.3286971091715207), 'worst smoothness': np.float64(1.0143853522226067), 'worst compactness': np.float64(0.9397928353214188), 'worst concavity': np.float64(0.57163683727167), 'worst concave points': np.float64(0.9424167433459241), 'worst symmetry': np.float64(0.466729028492946), 'worst fractal dimension': np.float64(0.671987576260843)}, 'top_features': {'mean concave points': np.float64(2.356846644817519), 'worst radius': np.float64(2.336847849275482), 'worst perimeter': np.float64(2.292138645541036), 'mean area': np.float64(1.5192832391931619), 'mean radius': np.float64(1.3712802054917677), 'worst area': np.float64(1.3286971091715207), 'mean perimeter': np.float64(1.288058196916187), 'mean fractal dimension': np.float64(1.2352475644791745), 'worst smoothness': np.float64(1.0143853522226067), 'worst concave points': np.float64(0.9424167433459241)}}, 'worst_sample_count': 136, 'remaining_sample_count': 319}\n",
            "2025-11-12 22:40:27,009 - deepbridge.reports - INFO - Transformed scenario 3: is_valid=True, gap=0.0, metric=PSI, alpha=0.3\n",
            "2025-11-12 22:40:27,009 - deepbridge.reports - INFO - Raw scenario 4: {'method': 'distribution_shift', 'alpha': 0.1, 'metric': 'auc', 'distance_metric': 'WD1', 'worst_metric': np.float64(1.0), 'remaining_metric': np.float64(1.0), 'performance_gap': np.float64(0.0), 'feature_distances': {'distance_metric': 'WD1', 'all_feature_distances': {'mean radius': np.float64(1.5063474254742548), 'mean texture': np.float64(0.43687804878048797), 'mean perimeter': np.float64(11.484428184281844), 'mean area': np.float64(148.60563685636856), 'mean smoothness': np.float64(0.0018559566395663948), 'mean compactness': np.float64(0.009530455284552847), 'mean concavity': np.float64(0.022112478238482385), 'mean concave points': np.float64(0.018398693224932247), 'mean symmetry': np.float64(0.004864417344173438), 'mean fractal dimension': np.float64(0.002393661246612465), 'radius error': np.float64(0.04755531165311652), 'texture error': np.float64(0.08823682926829265), 'perimeter error': np.float64(0.3664914092140922), 'area error': np.float64(12.498735772357726), 'smoothness error': np.float64(0.001196521138211382), 'compactness error': np.float64(0.0050201626016260145), 'concavity error': np.float64(0.0179955050406504), 'concave points error': np.float64(0.002377486991869919), 'symmetry error': np.float64(0.0023479460704607037), 'fractal dimension error': np.float64(0.0008932740108401085), 'worst radius': np.float64(2.5788314363143634), 'worst texture': np.float64(0.7825013550135506), 'worst perimeter': np.float64(19.607146341463416), 'worst area': np.float64(279.1091869918699), 'worst smoothness': np.float64(0.00542820596205962), 'worst compactness': np.float64(0.0571680081300813), 'worst concavity': np.float64(0.09179097208672087), 'worst concave points': np.float64(0.02967718997289973), 'worst symmetry': np.float64(0.021005338753387528), 'worst fractal dimension': np.float64(0.006529850948509486)}, 'top_features': {'worst area': np.float64(279.1091869918699), 'mean area': np.float64(148.60563685636856), 'worst perimeter': np.float64(19.607146341463416), 'area error': np.float64(12.498735772357726), 'mean perimeter': np.float64(11.484428184281844), 'worst radius': np.float64(2.5788314363143634), 'mean radius': np.float64(1.5063474254742548), 'worst texture': np.float64(0.7825013550135506), 'mean texture': np.float64(0.43687804878048797), 'perimeter error': np.float64(0.3664914092140922)}}, 'worst_sample_count': 45, 'remaining_sample_count': 410}\n",
            "2025-11-12 22:40:27,010 - deepbridge.reports - INFO - Transformed scenario 4: is_valid=True, gap=0.0, metric=WD1, alpha=0.1\n",
            "2025-11-12 22:40:27,010 - deepbridge.reports - INFO - Raw scenario 5: {'method': 'distribution_shift', 'alpha': 0.2, 'metric': 'auc', 'distance_metric': 'WD1', 'worst_metric': np.float64(1.0), 'remaining_metric': np.float64(1.0), 'performance_gap': np.float64(0.0), 'feature_distances': {'distance_metric': 'WD1', 'all_feature_distances': {'mean radius': np.float64(1.6860576923076924), 'mean texture': np.float64(0.6814285714285713), 'mean perimeter': np.float64(12.470082417582416), 'mean area': np.float64(162.7425824175824), 'mean smoothness': np.float64(0.0016054395604395617), 'mean compactness': np.float64(0.016213736263736265), 'mean concavity': np.float64(0.024593429395604393), 'mean concave points': np.float64(0.018443329670329675), 'mean symmetry': np.float64(0.0025684065934065926), 'mean fractal dimension': np.float64(0.002328021978021978), 'radius error': np.float64(0.05855714285714278), 'texture error': np.float64(0.0637862637362637), 'perimeter error': np.float64(0.5211832417582412), 'area error': np.float64(14.258837912087902), 'smoothness error': np.float64(0.0006977390109890109), 'compactness error': np.float64(0.006888403846153846), 'concavity error': np.float64(0.01697721263736264), 'concave points error': np.float64(0.0028628681318681316), 'symmetry error': np.float64(0.0017541840659340661), 'fractal dimension error': np.float64(0.0010369695054945058), 'worst radius': np.float64(2.6574725274725277), 'worst texture': np.float64(0.8156868131868131), 'worst perimeter': np.float64(19.645906593406597), 'worst area': np.float64(286.6637362637363), 'worst smoothness': np.float64(0.005089478021978021), 'worst compactness': np.float64(0.049816208791208794), 'worst concavity': np.float64(0.07992410164835162), 'worst concave points': np.float64(0.03217343131868132), 'worst symmetry': np.float64(0.009355769230769232), 'worst fractal dimension': np.float64(0.005590714285714284)}, 'top_features': {'worst area': np.float64(286.6637362637363), 'mean area': np.float64(162.7425824175824), 'worst perimeter': np.float64(19.645906593406597), 'area error': np.float64(14.258837912087902), 'mean perimeter': np.float64(12.470082417582416), 'worst radius': np.float64(2.6574725274725277), 'mean radius': np.float64(1.6860576923076924), 'worst texture': np.float64(0.8156868131868131), 'mean texture': np.float64(0.6814285714285713), 'perimeter error': np.float64(0.5211832417582412)}}, 'worst_sample_count': 91, 'remaining_sample_count': 364}\n",
            "2025-11-12 22:40:27,011 - deepbridge.reports - INFO - Transformed scenario 5: is_valid=True, gap=0.0, metric=WD1, alpha=0.2\n",
            "2025-11-12 22:40:27,012 - deepbridge.reports - INFO - Raw scenario 6: {'method': 'distribution_shift', 'alpha': 0.3, 'metric': 'auc', 'distance_metric': 'WD1', 'worst_metric': np.float64(1.0), 'remaining_metric': np.float64(1.0), 'performance_gap': np.float64(0.0), 'feature_distances': {'distance_metric': 'WD1', 'all_feature_distances': {'mean radius': np.float64(1.4960918080398304), 'mean texture': np.float64(0.6152074497510605), 'mean perimeter': np.float64(11.027182371381155), 'mean area': np.float64(148.70689194172965), 'mean smoothness': np.float64(0.0022402028397565913), 'mean compactness': np.float64(0.015289454637654434), 'mean concavity': np.float64(0.02348699056795131), 'mean concave points': np.float64(0.01709038094689286), 'mean symmetry': np.float64(0.004159715563341322), 'mean fractal dimension': np.float64(0.002527744560206527), 'radius error': np.float64(0.0567219527936566), 'texture error': np.float64(0.09645540752351098), 'perimeter error': np.float64(0.40973751152498583), 'area error': np.float64(12.856185782777057), 'smoothness error': np.float64(0.0004569581643002023), 'compactness error': np.float64(0.006982835192697767), 'concavity error': np.float64(0.015019355151668808), 'concave points error': np.float64(0.002692145468375437), 'symmetry error': np.float64(0.0016794911257606482), 'fractal dimension error': np.float64(0.0008672260649087212), 'worst radius': np.float64(2.4223179974184035), 'worst texture': np.float64(1.0802431772081875), 'worst perimeter': np.float64(17.420476903927714), 'worst area': np.float64(271.4762078185507), 'worst smoothness': np.float64(0.003465754656094413), 'worst compactness': np.float64(0.05842959962198045), 'worst concavity': np.float64(0.08115963910658305), 'worst concave points': np.float64(0.02955723294302047), 'worst symmetry': np.float64(0.019103641895629724), 'worst fractal dimension': np.float64(0.0070903950765259065)}, 'top_features': {'worst area': np.float64(271.4762078185507), 'mean area': np.float64(148.70689194172965), 'worst perimeter': np.float64(17.420476903927714), 'area error': np.float64(12.856185782777057), 'mean perimeter': np.float64(11.027182371381155), 'worst radius': np.float64(2.4223179974184035), 'mean radius': np.float64(1.4960918080398304), 'worst texture': np.float64(1.0802431772081875), 'mean texture': np.float64(0.6152074497510605), 'perimeter error': np.float64(0.40973751152498583)}}, 'worst_sample_count': 136, 'remaining_sample_count': 319}\n",
            "2025-11-12 22:40:27,012 - deepbridge.reports - INFO - Transformed scenario 6: is_valid=True, gap=0.0, metric=WD1, alpha=0.3\n",
            "2025-11-12 22:40:27,012 - deepbridge.reports - INFO - Raw scenario 7: {'method': 'distribution_shift', 'alpha': 0.1, 'metric': 'auc', 'distance_metric': 'KS', 'worst_metric': np.float64(1.0), 'remaining_metric': np.float64(1.0), 'performance_gap': np.float64(0.0), 'feature_distances': {'distance_metric': 'KS', 'all_feature_distances': {'mean radius': np.float64(0.2062330623306233), 'mean texture': np.float64(0.07208672086720867), 'mean perimeter': np.float64(0.23441734417344173), 'mean area': np.float64(0.21734417344173443), 'mean smoothness': np.float64(0.06829268292682927), 'mean compactness': np.float64(0.14092140921409213), 'mean concavity': np.float64(0.2861788617886179), 'mean concave points': np.float64(0.36260162601626017), 'mean symmetry': np.float64(0.1016260162601626), 'mean fractal dimension': np.float64(0.14905149051490515), 'radius error': np.float64(0.12168021680216802), 'texture error': np.float64(0.1046070460704607), 'perimeter error': np.float64(0.0983739837398374), 'area error': np.float64(0.18997289972899728), 'smoothness error': np.float64(0.17615176151761516), 'compactness error': np.float64(0.11002710027100271), 'concavity error': np.float64(0.18997289972899728), 'concave points error': np.float64(0.1802168021680217), 'symmetry error': np.float64(0.22764227642276422), 'fractal dimension error': np.float64(0.16910569105691056), 'worst radius': np.float64(0.2975609756097561), 'worst texture': np.float64(0.08536585365853659), 'worst perimeter': np.float64(0.32818428184281845), 'worst area': np.float64(0.27940379403794036), 'worst smoothness': np.float64(0.10650406504065041), 'worst compactness': np.float64(0.25094850948509484), 'worst concavity': np.float64(0.2693766937669377), 'worst concave points': np.float64(0.34119241192411925), 'worst symmetry': np.float64(0.1021680216802168), 'worst fractal dimension': np.float64(0.16775067750677508)}, 'top_features': {'mean concave points': np.float64(0.36260162601626017), 'worst concave points': np.float64(0.34119241192411925), 'worst perimeter': np.float64(0.32818428184281845), 'worst radius': np.float64(0.2975609756097561), 'mean concavity': np.float64(0.2861788617886179), 'worst area': np.float64(0.27940379403794036), 'worst concavity': np.float64(0.2693766937669377), 'worst compactness': np.float64(0.25094850948509484), 'mean perimeter': np.float64(0.23441734417344173), 'symmetry error': np.float64(0.22764227642276422)}}, 'worst_sample_count': 45, 'remaining_sample_count': 410}\n",
            "2025-11-12 22:40:27,013 - deepbridge.reports - INFO - Transformed scenario 7: is_valid=True, gap=0.0, metric=KS, alpha=0.1\n",
            "2025-11-12 22:40:27,013 - deepbridge.reports - INFO - Raw scenario 8: {'method': 'distribution_shift', 'alpha': 0.2, 'metric': 'auc', 'distance_metric': 'KS', 'worst_metric': np.float64(1.0), 'remaining_metric': np.float64(1.0), 'performance_gap': np.float64(0.0), 'feature_distances': {'distance_metric': 'KS', 'all_feature_distances': {'mean radius': np.float64(0.30494505494505497), 'mean texture': np.float64(0.13736263736263737), 'mean perimeter': np.float64(0.32142857142857145), 'mean area': np.float64(0.29120879120879123), 'mean smoothness': np.float64(0.06868131868131869), 'mean compactness': np.float64(0.2087912087912088), 'mean concavity': np.float64(0.3159340659340659), 'mean concave points': np.float64(0.37362637362637363), 'mean symmetry': np.float64(0.06043956043956044), 'mean fractal dimension': np.float64(0.14285714285714285), 'radius error': np.float64(0.08241758241758242), 'texture error': np.float64(0.08791208791208792), 'perimeter error': np.float64(0.12912087912087913), 'area error': np.float64(0.1565934065934066), 'smoothness error': np.float64(0.14835164835164835), 'compactness error': np.float64(0.17857142857142858), 'concavity error': np.float64(0.18406593406593408), 'concave points error': np.float64(0.22802197802197802), 'symmetry error': np.float64(0.1620879120879121), 'fractal dimension error': np.float64(0.1620879120879121), 'worst radius': np.float64(0.36538461538461536), 'worst texture': np.float64(0.0989010989010989), 'worst perimeter': np.float64(0.3598901098901099), 'worst area': np.float64(0.33791208791208793), 'worst smoothness': np.float64(0.11538461538461539), 'worst compactness': np.float64(0.23351648351648352), 'worst concavity': np.float64(0.3131868131868132), 'worst concave points': np.float64(0.35714285714285715), 'worst symmetry': np.float64(0.06043956043956044), 'worst fractal dimension': np.float64(0.15384615384615385)}, 'top_features': {'mean concave points': np.float64(0.37362637362637363), 'worst radius': np.float64(0.36538461538461536), 'worst perimeter': np.float64(0.3598901098901099), 'worst concave points': np.float64(0.35714285714285715), 'worst area': np.float64(0.33791208791208793), 'mean perimeter': np.float64(0.32142857142857145), 'mean concavity': np.float64(0.3159340659340659), 'worst concavity': np.float64(0.3131868131868132), 'mean radius': np.float64(0.30494505494505497), 'mean area': np.float64(0.29120879120879123)}}, 'worst_sample_count': 91, 'remaining_sample_count': 364}\n",
            "2025-11-12 22:40:27,014 - deepbridge.reports - INFO - Transformed scenario 8: is_valid=True, gap=0.0, metric=KS, alpha=0.2\n",
            "2025-11-12 22:40:27,014 - deepbridge.reports - INFO - Raw scenario 9: {'method': 'distribution_shift', 'alpha': 0.3, 'metric': 'auc', 'distance_metric': 'KS', 'worst_metric': np.float64(1.0), 'remaining_metric': np.float64(1.0), 'performance_gap': np.float64(0.0), 'feature_distances': {'distance_metric': 'KS', 'all_feature_distances': {'mean radius': np.float64(0.21514844182186982), 'mean texture': np.float64(0.10981006822791813), 'mean perimeter': np.float64(0.25059929928084085), 'mean area': np.float64(0.21936658676009588), 'mean smoothness': np.float64(0.0818043518347778), 'mean compactness': np.float64(0.19587866494560208), 'mean concavity': np.float64(0.31774386870735755), 'mean concave points': np.float64(0.34727088327494005), 'mean symmetry': np.float64(0.09434353678775585), 'mean fractal dimension': np.float64(0.13811543426147888), 'radius error': np.float64(0.09950673059192329), 'texture error': np.float64(0.10141987829614604), 'perimeter error': np.float64(0.0927761386686336), 'area error': np.float64(0.16510695187165775), 'smoothness error': np.float64(0.11720910934906878), 'compactness error': np.float64(0.18167988198414162), 'concavity error': np.float64(0.20226350728379125), 'concave points error': np.float64(0.24774110271067676), 'symmetry error': np.float64(0.08551539738152314), 'fractal dimension error': np.float64(0.1295177945786465), 'worst radius': np.float64(0.2870182555780933), 'worst texture': np.float64(0.10547667342799188), 'worst perimeter': np.float64(0.28810160427807485), 'worst area': np.float64(0.26917757698690764), 'worst smoothness': np.float64(0.08761294486446616), 'worst compactness': np.float64(0.2075650009219989), 'worst concavity': np.float64(0.31546192144569424), 'worst concave points': np.float64(0.30919232896920523), 'worst symmetry': np.float64(0.11070901714917943), 'worst fractal dimension': np.float64(0.15293656647612022)}, 'top_features': {'mean concave points': np.float64(0.34727088327494005), 'mean concavity': np.float64(0.31774386870735755), 'worst concavity': np.float64(0.31546192144569424), 'worst concave points': np.float64(0.30919232896920523), 'worst perimeter': np.float64(0.28810160427807485), 'worst radius': np.float64(0.2870182555780933), 'worst area': np.float64(0.26917757698690764), 'mean perimeter': np.float64(0.25059929928084085), 'concave points error': np.float64(0.24774110271067676), 'mean area': np.float64(0.21936658676009588)}}, 'worst_sample_count': 136, 'remaining_sample_count': 319}\n",
            "2025-11-12 22:40:27,014 - deepbridge.reports - INFO - Transformed scenario 9: is_valid=True, gap=0.0, metric=KS, alpha=0.3\n",
            "2025-11-12 22:40:27,015 - deepbridge.reports - INFO - Total valid scenarios: 9\n",
            "2025-11-12 22:40:27,015 - deepbridge.reports - INFO - ======================================================================\n",
            "2025-11-12 22:40:27,016 - deepbridge.reports - INFO - ================================================================================\n",
            "2025-11-12 22:40:27,017 - deepbridge.reports - INFO - CREATING FEATURE IMPORTANCE CHART\n",
            "2025-11-12 22:40:27,017 - deepbridge.reports - INFO - ================================================================================\n",
            "2025-11-12 22:40:27,017 - deepbridge.reports - INFO - Total features available: 30\n",
            "2025-11-12 22:40:27,018 - deepbridge.reports - INFO - Top 10 features count: 10\n",
            "2025-11-12 22:40:27,018 - deepbridge.reports - INFO - Feature 1: worst area = 0.1400\n",
            "2025-11-12 22:40:27,019 - deepbridge.reports - INFO - Feature 2: worst concave points = 0.1295\n",
            "2025-11-12 22:40:27,019 - deepbridge.reports - INFO - Feature 3: worst radius = 0.0977\n",
            "2025-11-12 22:40:27,020 - deepbridge.reports - INFO - Feature 4: mean concave points = 0.0909\n",
            "2025-11-12 22:40:27,020 - deepbridge.reports - INFO - Feature 5: worst perimeter = 0.0722\n",
            "2025-11-12 22:40:27,021 - deepbridge.reports - INFO - Feature 6: mean perimeter = 0.0696\n",
            "2025-11-12 22:40:27,021 - deepbridge.reports - INFO - Feature 7: mean radius = 0.0687\n",
            "2025-11-12 22:40:27,021 - deepbridge.reports - INFO - Feature 8: mean concavity = 0.0576\n",
            "2025-11-12 22:40:27,022 - deepbridge.reports - INFO - Feature 9: mean area = 0.0492\n",
            "2025-11-12 22:40:27,022 - deepbridge.reports - INFO - Feature 10: worst concavity = 0.0343\n",
            "2025-11-12 22:40:27,023 - deepbridge.reports - INFO - Feature importance chart created with 10 features\n",
            "2025-11-12 22:40:27,023 - deepbridge.reports - INFO - ================================================================================\n",
            "2025-11-12 22:40:27,024 - deepbridge.reports - INFO - ======================================================================\n",
            "2025-11-12 22:40:27,024 - deepbridge.reports - INFO - CREATING OVERVIEW CHART (Resilience Overview)\n",
            "2025-11-12 22:40:27,025 - deepbridge.reports - INFO - Total scenarios received: 9\n",
            "2025-11-12 22:40:27,026 - deepbridge.reports - INFO - Scenario 1: name=Scenario 1, metric=PSI, alpha=0.1, gap=0.0, is_valid=True\n",
            "2025-11-12 22:40:27,026 - deepbridge.reports - INFO - Scenario 2: name=Scenario 2, metric=PSI, alpha=0.2, gap=0.0, is_valid=True\n",
            "2025-11-12 22:40:27,027 - deepbridge.reports - INFO - Scenario 3: name=Scenario 3, metric=PSI, alpha=0.3, gap=0.0, is_valid=True\n",
            "2025-11-12 22:40:27,027 - deepbridge.reports - INFO - Scenario 4: name=Scenario 4, metric=WD1, alpha=0.1, gap=0.0, is_valid=True\n",
            "2025-11-12 22:40:27,027 - deepbridge.reports - INFO - Scenario 5: name=Scenario 5, metric=WD1, alpha=0.2, gap=0.0, is_valid=True\n",
            "2025-11-12 22:40:27,028 - deepbridge.reports - INFO - Scenario 6: name=Scenario 6, metric=WD1, alpha=0.3, gap=0.0, is_valid=True\n",
            "2025-11-12 22:40:27,028 - deepbridge.reports - INFO - Scenario 7: name=Scenario 7, metric=KS, alpha=0.1, gap=0.0, is_valid=True\n",
            "2025-11-12 22:40:27,029 - deepbridge.reports - INFO - Scenario 8: name=Scenario 8, metric=KS, alpha=0.2, gap=0.0, is_valid=True\n",
            "2025-11-12 22:40:27,029 - deepbridge.reports - INFO - Scenario 9: name=Scenario 9, metric=KS, alpha=0.3, gap=0.0, is_valid=True\n",
            "2025-11-12 22:40:27,030 - deepbridge.reports - INFO - Added to chart: metric=PSI, alpha=0.1, gap=0.0, name=Scenario 1\n",
            "2025-11-12 22:40:27,030 - deepbridge.reports - INFO - Added to chart: metric=PSI, alpha=0.2, gap=0.0, name=Scenario 2\n",
            "2025-11-12 22:40:27,031 - deepbridge.reports - INFO - Added to chart: metric=PSI, alpha=0.3, gap=0.0, name=Scenario 3\n",
            "2025-11-12 22:40:27,031 - deepbridge.reports - INFO - Added to chart: metric=WD1, alpha=0.1, gap=0.0, name=Scenario 4\n",
            "2025-11-12 22:40:27,032 - deepbridge.reports - INFO - Added to chart: metric=WD1, alpha=0.2, gap=0.0, name=Scenario 5\n",
            "2025-11-12 22:40:27,032 - deepbridge.reports - INFO - Added to chart: metric=WD1, alpha=0.3, gap=0.0, name=Scenario 6\n",
            "2025-11-12 22:40:27,032 - deepbridge.reports - INFO - Added to chart: metric=KS, alpha=0.1, gap=0.0, name=Scenario 7\n",
            "2025-11-12 22:40:27,033 - deepbridge.reports - INFO - Added to chart: metric=KS, alpha=0.2, gap=0.0, name=Scenario 8\n",
            "2025-11-12 22:40:27,033 - deepbridge.reports - INFO - Added to chart: metric=KS, alpha=0.3, gap=0.0, name=Scenario 9\n",
            "2025-11-12 22:40:27,034 - deepbridge.reports - INFO - Creating trace for metric 'PSI': 3 points, alphas=[0.1, 0.2, 0.3], gaps=[0.0, 0.0, 0.0]\n",
            "2025-11-12 22:40:27,034 - deepbridge.reports - INFO - Creating trace for metric 'WD1': 3 points, alphas=[0.1, 0.2, 0.3], gaps=[0.0, 0.0, 0.0]\n",
            "2025-11-12 22:40:27,035 - deepbridge.reports - INFO - Creating trace for metric 'KS': 3 points, alphas=[0.1, 0.2, 0.3], gaps=[0.0, 0.0, 0.0]\n",
            "2025-11-12 22:40:27,038 - deepbridge.reports - INFO - Total traces created: 3\n",
            "2025-11-12 22:40:27,038 - deepbridge.reports - INFO - ======================================================================\n",
            "2025-11-12 22:40:27,039 - deepbridge.reports - INFO - ================================================================================\n",
            "2025-11-12 22:40:27,040 - deepbridge.reports - INFO - CREATING BY_LEVEL CHART (Missing Data Impact)\n",
            "2025-11-12 22:40:27,041 - deepbridge.reports - INFO - ================================================================================\n",
            "2025-11-12 22:40:27,041 - deepbridge.reports - INFO - missing_data available: False\n",
            "2025-11-12 22:40:27,042 - deepbridge.reports - INFO - by_level available: False\n",
            "2025-11-12 22:40:27,043 - deepbridge.reports - WARNING - No missing data found in primary_model\n",
            "2025-11-12 22:40:27,043 - deepbridge.reports - WARNING - The 'By Missing %' tab in the report will be empty\n",
            "2025-11-12 22:40:27,044 - deepbridge.reports - WARNING - This is expected if the resilience test focused on distribution shift\n",
            "2025-11-12 22:40:27,044 - deepbridge.reports - INFO - ================================================================================\n",
            "2025-11-12 22:40:27,044 - deepbridge.reports - INFO - ================================================================================\n",
            "2025-11-12 22:40:27,045 - deepbridge.reports - INFO - CREATING MISSING PATTERNS CHART\n",
            "2025-11-12 22:40:27,045 - deepbridge.reports - INFO - ================================================================================\n",
            "2025-11-12 22:40:27,046 - deepbridge.reports - INFO - missing_patterns available: False\n",
            "2025-11-12 22:40:27,046 - deepbridge.reports - WARNING - No missing patterns data found in primary_model\n",
            "2025-11-12 22:40:27,047 - deepbridge.reports - WARNING - This is expected if the resilience test did not include missing data pattern analysis\n",
            "2025-11-12 22:40:27,047 - deepbridge.reports - INFO - ================================================================================\n",
            "2025-11-12 22:40:27,047 - deepbridge.reports - INFO - ================================================================================\n",
            "2025-11-12 22:40:27,048 - deepbridge.reports - INFO - CREATING IMPUTATION STRATEGIES CHART\n",
            "2025-11-12 22:40:27,048 - deepbridge.reports - INFO - ================================================================================\n",
            "2025-11-12 22:40:27,049 - deepbridge.reports - INFO - imputation_strategies available: False\n",
            "2025-11-12 22:40:27,049 - deepbridge.reports - WARNING - No imputation strategies data found in primary_model\n",
            "2025-11-12 22:40:27,050 - deepbridge.reports - WARNING - This is expected if the resilience test did not include imputation analysis\n",
            "2025-11-12 22:40:27,050 - deepbridge.reports - INFO - ================================================================================\n",
            "2025-11-12 22:40:27,050 - deepbridge.reports - INFO - Generated charts: ['overview', 'scenarios_by_alpha', 'score_distribution', 'scenarios_by_metric', 'feature_importance', 'features', 'boxplot', 'worst_sample', 'worst_cluster', 'outer_sample', 'hard_sample', 'test_type_comparison', 'by_level', 'patterns', 'strategies']\n",
            "2025-11-12 22:40:27,051 - deepbridge.reports - INFO - score_distribution chart type: <class 'dict'>\n",
            "2025-11-12 22:40:27,051 - deepbridge.reports - INFO - score_distribution has 'data': True\n",
            "2025-11-12 22:40:27,052 - deepbridge.reports - INFO - score_distribution has 'layout': True\n",
            "2025-11-12 22:40:27,052 - deepbridge.reports - INFO - score_distribution data length: 3\n",
            "2025-11-12 22:40:27,053 - deepbridge.reports - INFO - score_distribution data sample: [{'x': [0.1, 0.2, 0.3], 'y': [0.0, 0.0, 0.0], 'type': 'scatter', 'mode': 'lines+markers', 'name': 'Performance Gap', 'line': {'color': 'rgb(255, 65, 54)', 'width': 3}, 'marker': {'size': 10}, 'yaxis': 'y2', 'hovertemplate': '<b>Performance Gap</b><br>Alpha: %{x}<br>Gap: %{y:.4f}<extra></extra>'}]\n",
            "2025-11-12 22:40:27,053 - deepbridge.reports - INFO - Transformation complete. 16 scenarios, 30 features\n",
            "2025-11-12 22:40:27,054 - deepbridge.reports - INFO - Found template at: /home/guhaase/projetos/DeepBridge/deepbridge/templates/report_types/resilience/interactive/index.html\n",
            "2025-11-12 22:40:27,054 - deepbridge.reports - DEBUG - Loading template: /home/guhaase/projetos/DeepBridge/deepbridge/templates/report_types/resilience/interactive/index.html\n",
            "2025-11-12 22:40:27,073 - deepbridge.reports - INFO - Template loaded for resilience/interactive\n",
            "2025-11-12 22:40:27,075 - deepbridge.reports - INFO - CSS compiled successfully using CSSManager for resilience: 30594 chars\n",
            "2025-11-12 22:40:27,080 - deepbridge.reports - DEBUG - Rendering template with context keys: ['report_data', 'report_data_json', 'css_content', 'js_content', 'logo', 'favicon_base64', 'model_name', 'model_type', 'timestamp', 'test_type', 'current_year', 'report_title', 'report_subtitle', 'resilience_score', 'total_scenarios', 'valid_scenarios', 'total_features', 'report_type']\n",
            "2025-11-12 22:40:27,081 - deepbridge.reports - INFO - Report generated and saved to: /home/guhaase/projetos/DeepBridge/examples/notebooks/03_validation_tests/outputs/resilience_classification/resilience_classification_interactive.html (type: interactive)\n",
            "2025-11-12 22:40:27,082 - deepbridge.reports - INFO - Output directory ensured: /home/guhaase/projetos/DeepBridge/examples/notebooks/03_validation_tests/outputs/resilience_classification\n",
            "2025-11-12 22:40:27,083 - deepbridge.reports - INFO - Report saved to: /home/guhaase/projetos/DeepBridge/examples/notebooks/03_validation_tests/outputs/resilience_classification/resilience_classification_interactive.html\n",
            "2025-11-12 22:40:27,083 - deepbridge.reports - INFO - Report generated and saved to: /home/guhaase/projetos/DeepBridge/examples/notebooks/03_validation_tests/outputs/resilience_classification/resilience_classification_interactive.html (type: interactive)\n",
            "\n",
            "‚úÖ Interactive report generated!\n",
            "üìÇ Location: /home/guhaase/projetos/DeepBridge/examples/notebooks/03_validation_tests/outputs/resilience_classification/resilience_classification_interactive.html\n",
            "\n",
            "üí° Open the HTML file in your browser to explore:\n",
            "   - Performance Overview\n",
            "   - Drift Detection Analysis\n",
            "   - Feature Distribution Shifts\n",
            "   - Interactive Plotly charts\n"
          ]
        }
      ],
      "source": [
        "# Create output directory\n",
        "output_dir = './outputs/resilience_classification'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Generate interactive HTML report\n",
        "html_output_path = os.path.join(output_dir, 'resilience_classification_interactive.html')\n",
        "\n",
        "print(\"üìù Generating interactive HTML report...\\n\")\n",
        "\n",
        "report_path = exp.save_html(\n",
        "    test_type='resilience',\n",
        "    file_path=html_output_path,\n",
        "    model_name='RandomForest Classifier',\n",
        "    report_type='interactive'\n",
        ")\n",
        "\n",
        "print(f\"\\n‚úÖ Interactive report generated!\")\n",
        "print(f\"üìÇ Location: {report_path}\")\n",
        "print(f\"\\nüí° Open the HTML file in your browser to explore:\")\n",
        "print(f\"   - Performance Overview\")\n",
        "print(f\"   - Drift Detection Analysis\")\n",
        "print(f\"   - Feature Distribution Shifts\")\n",
        "print(f\"   - Interactive Plotly charts\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6Ô∏è‚É£ Export Results to JSON\n",
        "\n",
        "### JSON export includes:\n",
        "- üîç **Experiment Info**: Configuration and metadata\n",
        "- üìä **Test Results**: Complete resilience analysis data\n",
        "- üéØ **Model Evaluation**: Model metrics and performance\n",
        "- üìà **Drift Metrics**: Distribution shift measurements\n",
        "- üåü **Feature Analysis**: Per-feature drift statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìù Exporting results to JSON...\n",
            "\n",
            "\n",
            "‚úÖ JSON files exported successfully!\n",
            "\n",
            "üìä FILE SIZES:\n",
            "   Full JSON:      308.84 KB\n",
            "   Compact JSON:   304.81 KB\n",
            "   Reduction:         1.3%\n",
            "\n",
            "üìÇ LOCATIONS:\n",
            "   Full:    /home/guhaase/projetos/DeepBridge/examples/notebooks/03_validation_tests/outputs/resilience_classification/resilience_classification_results.json\n",
            "   Compact: /home/guhaase/projetos/DeepBridge/examples/notebooks/03_validation_tests/outputs/resilience_classification/resilience_classification_results_COMPACT.json\n",
            "\n",
            "üìã COMPACT JSON STRUCTURE (optimized for AI):\n",
            "   ‚îî‚îÄ experiment_info/\n",
            "      ‚îú‚îÄ test_type, experiment_type, generation_time, config\n",
            "   ‚îî‚îÄ test_results/\n",
            "      ‚îî‚îÄ primary_model/\n",
            "         ‚îú‚îÄ metrics (all model metrics)\n",
            "         ‚îú‚îÄ resilience_score\n",
            "         ‚îú‚îÄ drift_detected\n",
            "         ‚îî‚îÄ drift_analysis/\n",
            "            ‚îú‚îÄ data_drift_score\n",
            "            ‚îú‚îÄ concept_drift_score\n",
            "            ‚îî‚îÄ per_feature_drift (top affected features)\n",
            "   ‚îî‚îÄ initial_model_evaluation/ (compact)\n",
            "   ‚îî‚îÄ summary/  (AI-friendly analysis)\n",
            "      ‚îú‚îÄ key_findings\n",
            "      ‚îú‚îÄ drift_summary\n",
            "      ‚îú‚îÄ performance_stability\n",
            "      ‚îî‚îÄ recommendations\n",
            "\n",
            "üí° USE CASES:\n",
            "   ‚Ä¢ Full JSON: Deep dive analysis, debugging, research\n",
            "   ‚Ä¢ Compact JSON: AI validation, automated testing, CI/CD pipelines\n"
          ]
        }
      ],
      "source": [
        "# Export to JSON (COMPACT MODE for AI validation)\n",
        "json_output_path = os.path.join(output_dir, 'resilience_classification_results.json')\n",
        "json_compact_path = os.path.join(output_dir, 'resilience_classification_results_COMPACT.json')\n",
        "\n",
        "print(\"üìù Exporting results to JSON...\\n\")\n",
        "\n",
        "# Full JSON (with all data)\n",
        "json_path_full = exp._experiment_result.save_json(\n",
        "    test_type='resilience',\n",
        "    file_path=json_output_path,\n",
        "    include_summary=True,\n",
        "    compact=False  # Full data\n",
        ")\n",
        "\n",
        "# Compact JSON (optimized for AI validation)\n",
        "json_path_compact = exp._experiment_result.save_json(\n",
        "    test_type='resilience',\n",
        "    file_path=json_compact_path,\n",
        "    include_summary=True,\n",
        "    compact=True  # Remove large arrays, keep only essentials\n",
        ")\n",
        "\n",
        "# Compare file sizes\n",
        "import os\n",
        "size_full = os.path.getsize(json_path_full) / 1024  # KB\n",
        "size_compact = os.path.getsize(json_path_compact) / 1024  # KB\n",
        "reduction = ((size_full - size_compact) / size_full) * 100\n",
        "\n",
        "print(f\"\\n‚úÖ JSON files exported successfully!\")\n",
        "print(f\"\\nüìä FILE SIZES:\")\n",
        "print(f\"   Full JSON:    {size_full:>8.2f} KB\")\n",
        "print(f\"   Compact JSON: {size_compact:>8.2f} KB\")\n",
        "print(f\"   Reduction:    {reduction:>8.1f}%\")\n",
        "\n",
        "print(f\"\\nüìÇ LOCATIONS:\")\n",
        "print(f\"   Full:    {json_path_full}\")\n",
        "print(f\"   Compact: {json_path_compact}\")\n",
        "\n",
        "print(f\"\\nüìã COMPACT JSON STRUCTURE (optimized for AI):\")\n",
        "print(f\"   ‚îî‚îÄ experiment_info/\")\n",
        "print(f\"      ‚îú‚îÄ test_type, experiment_type, generation_time, config\")\n",
        "print(f\"   ‚îî‚îÄ test_results/\")\n",
        "print(f\"      ‚îî‚îÄ primary_model/\")\n",
        "print(f\"         ‚îú‚îÄ metrics (all model metrics)\")\n",
        "print(f\"         ‚îú‚îÄ resilience_score\")\n",
        "print(f\"         ‚îú‚îÄ drift_detected\")\n",
        "print(f\"         ‚îî‚îÄ drift_analysis/\")\n",
        "print(f\"            ‚îú‚îÄ data_drift_score\")\n",
        "print(f\"            ‚îú‚îÄ concept_drift_score\")\n",
        "print(f\"            ‚îî‚îÄ per_feature_drift (top affected features)\")\n",
        "print(f\"   ‚îî‚îÄ initial_model_evaluation/ (compact)\")\n",
        "print(f\"   ‚îî‚îÄ summary/  (AI-friendly analysis)\")\n",
        "print(f\"      ‚îú‚îÄ key_findings\")\n",
        "print(f\"      ‚îú‚îÄ drift_summary\")\n",
        "print(f\"      ‚îú‚îÄ performance_stability\")\n",
        "print(f\"      ‚îî‚îÄ recommendations\")\n",
        "\n",
        "print(f\"\\nüí° USE CASES:\")\n",
        "print(f\"   ‚Ä¢ Full JSON: Deep dive analysis, debugging, research\")\n",
        "print(f\"   ‚Ä¢ Compact JSON: AI validation, automated testing, CI/CD pipelines\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7Ô∏è‚É£ Load and Analyze JSON Results\n",
        "\n",
        "Demonstrate how to load and use the exported JSON"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "üìä ANALYZING COMPACT JSON (optimized for AI validation)\n",
            "================================================================================\n",
            "\n",
            "üî¨ EXPERIMENT INFO:\n",
            "   Test Type: resilience\n",
            "   Experiment Type: binary_classification\n",
            "   Generation Time: 2025-11-12 22:40:26\n",
            "\n",
            "üî¨ TEST RESULTS (Compact):\n",
            "   Resilience Score: 1.0\n",
            "   Drift Detected: N/A\n",
            "\n",
            "================================================================================\n",
            "üíæ COMPACT JSON IS OPTIMIZED FOR:\n",
            "================================================================================\n",
            "‚úÖ AI/LLM validation (smaller token count)\n",
            "‚úÖ Automated testing pipelines\n",
            "‚úÖ CI/CD integration\n",
            "‚úÖ Quick drift detection\n",
            "‚úÖ Summary-based decision making\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"üìä ANALYZING COMPACT JSON (optimized for AI validation)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Load COMPACT JSON results\n",
        "with open(json_compact_path, 'r', encoding='utf-8') as f:\n",
        "    results_json = json.load(f)\n",
        "\n",
        "# Experiment Info\n",
        "exp_info = results_json['experiment_info']\n",
        "print(f\"\\nüî¨ EXPERIMENT INFO:\")\n",
        "print(f\"   Test Type: {exp_info['test_type']}\")\n",
        "print(f\"   Experiment Type: {exp_info['experiment_type']}\")\n",
        "print(f\"   Generation Time: {exp_info['generation_time']}\")\n",
        "\n",
        "# Summary (AI-friendly)\n",
        "if 'summary' in results_json:\n",
        "    summary = results_json['summary']\n",
        "    \n",
        "    print(f\"\\nüéØ KEY FINDINGS:\")\n",
        "    for finding in summary.get('key_findings', []):\n",
        "        print(f\"   ‚Ä¢ {finding}\")\n",
        "    \n",
        "    print(f\"\\nüìà DRIFT SUMMARY:\")\n",
        "    drift = summary.get('drift_summary', {})\n",
        "    for key, value in drift.items():\n",
        "        print(f\"   {key}: {value}\")\n",
        "    \n",
        "    print(f\"\\nüîç PERFORMANCE STABILITY:\")\n",
        "    perf = summary.get('performance_stability', {})\n",
        "    for key, value in perf.items():\n",
        "        print(f\"   {key}: {value}\")\n",
        "    \n",
        "    print(f\"\\nüí° RECOMMENDATIONS:\")\n",
        "    for rec in summary.get('recommendations', []):\n",
        "        print(f\"   ‚Ä¢ {rec}\")\n",
        "\n",
        "# Test Results (compact)\n",
        "test_results = results_json['test_results']\n",
        "primary = test_results.get('primary_model', {})\n",
        "\n",
        "print(f\"\\nüî¨ TEST RESULTS (Compact):\")\n",
        "print(f\"   Resilience Score: {primary.get('resilience_score', 'N/A')}\")\n",
        "print(f\"   Drift Detected: {primary.get('drift_detected', 'N/A')}\")\n",
        "\n",
        "# Drift Analysis\n",
        "if 'drift_analysis' in primary:\n",
        "    drift_analysis = primary['drift_analysis']\n",
        "    print(f\"\\nüìä DRIFT ANALYSIS:\")\n",
        "    print(f\"   Data Drift Score: {drift_analysis.get('data_drift_score', 'N/A')}\")\n",
        "    print(f\"   Concept Drift Score: {drift_analysis.get('concept_drift_score', 'N/A')}\")\n",
        "    \n",
        "    if 'per_feature_drift' in drift_analysis:\n",
        "        print(f\"\\nüåü TOP FEATURES WITH HIGHEST DRIFT:\")\n",
        "        print(f\"   {'Feature':<30} {'Drift Score'}\")\n",
        "        print(f\"   {'-'*50}\")\n",
        "        for feat, score in list(drift_analysis['per_feature_drift'].items())[:10]:\n",
        "            print(f\"   {feat:<30} {score:.4f}\")\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"üíæ COMPACT JSON IS OPTIMIZED FOR:\")\n",
        "print(f\"{'='*80}\")\n",
        "print(f\"‚úÖ AI/LLM validation (smaller token count)\")\n",
        "print(f\"‚úÖ Automated testing pipelines\")\n",
        "print(f\"‚úÖ CI/CD integration\")\n",
        "print(f\"‚úÖ Quick drift detection\")\n",
        "print(f\"‚úÖ Summary-based decision making\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8Ô∏è‚É£ Resilience Analysis Summary\n",
        "\n",
        "Extract key insights from resilience testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä RESILIENCE TESTING SUMMARY\n",
            "======================================================================\n",
            "\n",
            "üìà OVERALL RESILIENCE:\n",
            "   Score: 1.000\n",
            "\n",
            "üéØ QUALITY ASSESSMENT:\n",
            "   ‚úÖ Resilience: EXCELLENT (score ‚â• 0.90)\n",
            "      Model is highly stable under distribution shifts\n",
            "\n",
            "üí° RECOMMENDATIONS:\n",
            "   ‚úÖ Model is production-ready\n",
            "   ‚Ä¢ Establish baseline metrics\n",
            "   ‚Ä¢ Set up continuous monitoring\n",
            "   ‚Ä¢ Define retraining triggers\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nüìä RESILIENCE TESTING SUMMARY\\n\" + \"=\"*70)\n",
        "\n",
        "# Access resilience metrics\n",
        "if 'resilience_score' in primary:\n",
        "    resilience_score = primary['resilience_score']\n",
        "    print(f\"\\nüìà OVERALL RESILIENCE:\")\n",
        "    print(f\"   Score: {resilience_score:.3f}\")\n",
        "    \n",
        "    # Quality assessment\n",
        "    print(f\"\\nüéØ QUALITY ASSESSMENT:\")\n",
        "    \n",
        "    if resilience_score >= 0.90:\n",
        "        print(f\"   ‚úÖ Resilience: EXCELLENT (score ‚â• 0.90)\")\n",
        "        print(f\"      Model is highly stable under distribution shifts\")\n",
        "    elif resilience_score >= 0.75:\n",
        "        print(f\"   üü° Resilience: GOOD (score ‚â• 0.75)\")\n",
        "        print(f\"      Model shows acceptable stability\")\n",
        "    elif resilience_score >= 0.60:\n",
        "        print(f\"   ‚ö†Ô∏è  Resilience: MODERATE (score ‚â• 0.60)\")\n",
        "        print(f\"      Monitor model performance closely\")\n",
        "    else:\n",
        "        print(f\"   üî¥ Resilience: LOW (score < 0.60)\")\n",
        "        print(f\"      Consider retraining or model improvement\")\n",
        "\n",
        "# Drift detection\n",
        "if 'drift_detected' in primary:\n",
        "    drift_detected = primary['drift_detected']\n",
        "    print(f\"\\nüîç DRIFT DETECTION:\")\n",
        "    \n",
        "    if drift_detected:\n",
        "        print(f\"   ‚ö†Ô∏è  Drift DETECTED\")\n",
        "        print(f\"      Data distribution has shifted significantly\")\n",
        "        print(f\"      Action: Review drift analysis and consider retraining\")\n",
        "    else:\n",
        "        print(f\"   ‚úÖ No significant drift detected\")\n",
        "        print(f\"      Model remains valid for current data distribution\")\n",
        "\n",
        "# Drift analysis details\n",
        "if 'drift_analysis' in primary:\n",
        "    drift_analysis = primary['drift_analysis']\n",
        "    \n",
        "    print(f\"\\nüìä DRIFT ANALYSIS:\")\n",
        "    \n",
        "    data_drift = drift_analysis.get('data_drift_score', 0)\n",
        "    concept_drift = drift_analysis.get('concept_drift_score', 0)\n",
        "    \n",
        "    print(f\"   Data Drift Score: {data_drift:.3f}\")\n",
        "    if data_drift > 0.3:\n",
        "        print(f\"      ‚ö†Ô∏è  High data drift - feature distributions changed\")\n",
        "    elif data_drift > 0.1:\n",
        "        print(f\"      üü° Moderate data drift detected\")\n",
        "    else:\n",
        "        print(f\"      ‚úÖ Low data drift\")\n",
        "    \n",
        "    print(f\"\\n   Concept Drift Score: {concept_drift:.3f}\")\n",
        "    if concept_drift > 0.3:\n",
        "        print(f\"      ‚ö†Ô∏è  High concept drift - target relationships changed\")\n",
        "    elif concept_drift > 0.1:\n",
        "        print(f\"      üü° Moderate concept drift detected\")\n",
        "    else:\n",
        "        print(f\"      ‚úÖ Low concept drift\")\n",
        "\n",
        "# Recommendations\n",
        "print(f\"\\nüí° RECOMMENDATIONS:\")\n",
        "\n",
        "if primary.get('drift_detected', False):\n",
        "    print(f\"   ‚Ä¢ URGENT: Investigate drift sources\")\n",
        "    print(f\"   ‚Ä¢ Consider retraining with recent data\")\n",
        "    print(f\"   ‚Ä¢ Implement drift monitoring in production\")\n",
        "\n",
        "if primary.get('resilience_score', 1.0) < 0.75:\n",
        "    print(f\"   ‚Ä¢ Model shows sensitivity to distribution shifts\")\n",
        "    print(f\"   ‚Ä¢ Collect more diverse training data\")\n",
        "    print(f\"   ‚Ä¢ Use ensemble methods to improve stability\")\n",
        "    print(f\"   ‚Ä¢ Apply data augmentation techniques\")\n",
        "\n",
        "if primary.get('resilience_score', 1.0) >= 0.90 and not primary.get('drift_detected', False):\n",
        "    print(f\"   ‚úÖ Model is production-ready\")\n",
        "    print(f\"   ‚Ä¢ Establish baseline metrics\")\n",
        "    print(f\"   ‚Ä¢ Set up continuous monitoring\")\n",
        "    print(f\"   ‚Ä¢ Define retraining triggers\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9Ô∏è‚É£ Practical Decision Examples\n",
        "\n",
        "How to use resilience metrics in real-world scenarios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üíº PRACTICAL USE CASES\n",
            "======================================================================\n",
            "\n",
            "üè• MEDICAL DEPLOYMENT - Hospital Transfer\n",
            "----------------------------------------------------------------------\n",
            "   Scenario: Deploying model from Hospital A to Hospital B\n",
            "   Resilience Score: 0.82\n",
            "   Drift Detected: False\n",
            "   Data Drift: 0.15\n",
            "\n",
            "   üìã DECISION PROTOCOL:\n",
            "   ‚úÖ APPROVED for deployment\n",
            "   Reason: High resilience, no significant drift\n",
            "   Action: Deploy with standard monitoring\n",
            "   Schedule: Weekly performance reviews\n",
            "\n",
            "\n",
            "üí∞ CREDIT SCORING - Economic Shift\n",
            "----------------------------------------------------------------------\n",
            "   Scenario: Model trained pre-pandemic, evaluated post-pandemic\n",
            "   Resilience Score: 0.65\n",
            "   Drift Detected: True\n",
            "   Concept Drift: 0.35\n",
            "\n",
            "   üìã DECISION PROTOCOL:\n",
            "   üî¥ IMMEDIATE ACTION REQUIRED\n",
            "   Reason: High concept drift - target relationships changed\n",
            "   Action: STOP using model for automated decisions\n",
            "   Next Steps:\n",
            "      1. Manual review for all applications\n",
            "      2. Collect recent labeled data\n",
            "      3. Retrain model with updated data\n",
            "      4. Re-run resilience testing\n",
            "\n",
            "\n",
            "üîí FRAUD DETECTION - Evolving Threats\n",
            "----------------------------------------------------------------------\n",
            "   Scenario: Quarterly resilience check on fraud detection model\n",
            "   Resilience Score: 0.88\n",
            "   Drift Detected: True\n",
            "   Data Drift: 0.22\n",
            "   Concept Drift: 0.12\n",
            "\n",
            "   üìã DECISION PROTOCOL:\n",
            "   üü° CONTINUE with ENHANCED MONITORING\n",
            "   Reason: High resilience but moderate data drift\n",
            "   Action: Keep model active with adjustments\n",
            "   Adjustments:\n",
            "      ‚Ä¢ Increase manual review threshold from 70% to 60%\n",
            "      ‚Ä¢ Schedule retraining in 1 month\n",
            "      ‚Ä¢ Analyze drifted features for new fraud patterns\n",
            "      ‚Ä¢ Implement feature importance monitoring\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nüíº PRACTICAL USE CASES\\n\" + \"=\"*70)\n",
        "\n",
        "# Scenario 1: Medical Deployment\n",
        "print(f\"\\nüè• MEDICAL DEPLOYMENT - Hospital Transfer\\n\" + \"-\"*70)\n",
        "resilience_score = 0.82\n",
        "drift_detected = False\n",
        "data_drift = 0.15\n",
        "\n",
        "print(f\"   Scenario: Deploying model from Hospital A to Hospital B\")\n",
        "print(f\"   Resilience Score: {resilience_score:.2f}\")\n",
        "print(f\"   Drift Detected: {drift_detected}\")\n",
        "print(f\"   Data Drift: {data_drift:.2f}\")\n",
        "\n",
        "print(f\"\\n   üìã DECISION PROTOCOL:\")\n",
        "if resilience_score >= 0.80 and not drift_detected:\n",
        "    print(f\"   ‚úÖ APPROVED for deployment\")\n",
        "    print(f\"   Reason: High resilience, no significant drift\")\n",
        "    print(f\"   Action: Deploy with standard monitoring\")\n",
        "    print(f\"   Schedule: Weekly performance reviews\")\n",
        "elif resilience_score >= 0.70:\n",
        "    print(f\"   üü° CONDITIONAL approval\")\n",
        "    print(f\"   Reason: Acceptable resilience but requires caution\")\n",
        "    print(f\"   Action: Deploy with enhanced monitoring\")\n",
        "    print(f\"   Requirement: Daily performance checks for first month\")\n",
        "else:\n",
        "    print(f\"   ‚ö†Ô∏è  REJECTED - Retrain required\")\n",
        "    print(f\"   Reason: Insufficient resilience for critical application\")\n",
        "    print(f\"   Action: Collect data from Hospital B and retrain\")\n",
        "\n",
        "# Scenario 2: Credit Scoring - Economic Change\n",
        "print(f\"\\n\\nüí∞ CREDIT SCORING - Economic Shift\\n\" + \"-\"*70)\n",
        "resilience_score = 0.65\n",
        "drift_detected = True\n",
        "concept_drift = 0.35\n",
        "\n",
        "print(f\"   Scenario: Model trained pre-pandemic, evaluated post-pandemic\")\n",
        "print(f\"   Resilience Score: {resilience_score:.2f}\")\n",
        "print(f\"   Drift Detected: {drift_detected}\")\n",
        "print(f\"   Concept Drift: {concept_drift:.2f}\")\n",
        "\n",
        "print(f\"\\n   üìã DECISION PROTOCOL:\")\n",
        "if drift_detected and concept_drift > 0.3:\n",
        "    print(f\"   üî¥ IMMEDIATE ACTION REQUIRED\")\n",
        "    print(f\"   Reason: High concept drift - target relationships changed\")\n",
        "    print(f\"   Action: STOP using model for automated decisions\")\n",
        "    print(f\"   Next Steps:\")\n",
        "    print(f\"      1. Manual review for all applications\")\n",
        "    print(f\"      2. Collect recent labeled data\")\n",
        "    print(f\"      3. Retrain model with updated data\")\n",
        "    print(f\"      4. Re-run resilience testing\")\n",
        "\n",
        "# Scenario 3: Fraud Detection - Evolving Tactics\n",
        "print(f\"\\n\\nüîí FRAUD DETECTION - Evolving Threats\\n\" + \"-\"*70)\n",
        "resilience_score = 0.88\n",
        "drift_detected = True\n",
        "data_drift = 0.22\n",
        "concept_drift = 0.12\n",
        "\n",
        "print(f\"   Scenario: Quarterly resilience check on fraud detection model\")\n",
        "print(f\"   Resilience Score: {resilience_score:.2f}\")\n",
        "print(f\"   Drift Detected: {drift_detected}\")\n",
        "print(f\"   Data Drift: {data_drift:.2f}\")\n",
        "print(f\"   Concept Drift: {concept_drift:.2f}\")\n",
        "\n",
        "print(f\"\\n   üìã DECISION PROTOCOL:\")\n",
        "if resilience_score >= 0.85 and concept_drift < 0.2:\n",
        "    print(f\"   üü° CONTINUE with ENHANCED MONITORING\")\n",
        "    print(f\"   Reason: High resilience but moderate data drift\")\n",
        "    print(f\"   Action: Keep model active with adjustments\")\n",
        "    print(f\"   Adjustments:\")\n",
        "    print(f\"      ‚Ä¢ Increase manual review threshold from 70% to 60%\")\n",
        "    print(f\"      ‚Ä¢ Schedule retraining in 1 month\")\n",
        "    print(f\"      ‚Ä¢ Analyze drifted features for new fraud patterns\")\n",
        "    print(f\"      ‚Ä¢ Implement feature importance monitoring\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîü Visualize Model Stability\n",
        "\n",
        "Visualize how model performance varies across different data subsets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Stability Statistics:\n",
            "   Mean Performance: 0.877\n",
            "   Std Performance: 0.048\n",
            "   Min Performance: 0.793\n",
            "   Max Performance: 0.949\n",
            "   Performance Range: 0.157\n",
            "\n",
            "   Stability Score: 0.952\n",
            "   ‚úÖ Highly stable model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_1999457/2253643128.py:50: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
            "  plt.show()\n"
          ]
        }
      ],
      "source": [
        "# Simulate performance on different data distributions\n",
        "n_simulations = 20\n",
        "performance_scores = []\n",
        "drift_levels = []\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "for i in range(n_simulations):\n",
        "    # Simulate varying drift levels\n",
        "    drift_level = np.random.uniform(0, 0.5)\n",
        "    drift_levels.append(drift_level)\n",
        "    \n",
        "    # Performance degrades with drift\n",
        "    base_performance = 0.95\n",
        "    performance = base_performance - (drift_level * 0.4) + np.random.normal(0, 0.02)\n",
        "    performance_scores.append(max(0.5, min(1.0, performance)))\n",
        "\n",
        "# Create visualization\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Plot 1: Performance vs Drift\n",
        "scatter = ax1.scatter(drift_levels, performance_scores, \n",
        "                     c=performance_scores, s=100, \n",
        "                     cmap='RdYlGn', alpha=0.6, edgecolors='black')\n",
        "ax1.plot(drift_levels, performance_scores, 'b--', alpha=0.3, label='Trend')\n",
        "ax1.axhline(y=0.90, color='green', linestyle='--', linewidth=2, label='Good Performance')\n",
        "ax1.axhline(y=0.75, color='orange', linestyle='--', linewidth=2, label='Acceptable')\n",
        "ax1.axhline(y=0.60, color='red', linestyle='--', linewidth=2, label='Poor')\n",
        "ax1.set_xlabel('Drift Level', fontsize=12, fontweight='bold')\n",
        "ax1.set_ylabel('Model Performance', fontsize=12, fontweight='bold')\n",
        "ax1.set_title('Performance Degradation vs Data Drift', fontsize=14, fontweight='bold')\n",
        "ax1.legend(fontsize=10)\n",
        "ax1.grid(True, alpha=0.3)\n",
        "ax1.set_ylim(0.5, 1.05)\n",
        "plt.colorbar(scatter, ax=ax1, label='Performance')\n",
        "\n",
        "# Plot 2: Performance Distribution\n",
        "ax2.hist(performance_scores, bins=15, color='skyblue', alpha=0.7, edgecolor='black')\n",
        "ax2.axvline(x=np.mean(performance_scores), color='red', linestyle='--', \n",
        "           linewidth=2, label=f'Mean: {np.mean(performance_scores):.3f}')\n",
        "ax2.axvline(x=np.median(performance_scores), color='green', linestyle='--', \n",
        "           linewidth=2, label=f'Median: {np.median(performance_scores):.3f}')\n",
        "ax2.set_xlabel('Performance Score', fontsize=12, fontweight='bold')\n",
        "ax2.set_ylabel('Frequency', fontsize=12, fontweight='bold')\n",
        "ax2.set_title('Distribution of Performance Scores', fontsize=14, fontweight='bold')\n",
        "ax2.legend(fontsize=10)\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nüìä Stability Statistics:\")\n",
        "print(f\"   Mean Performance: {np.mean(performance_scores):.3f}\")\n",
        "print(f\"   Std Performance: {np.std(performance_scores):.3f}\")\n",
        "print(f\"   Min Performance: {np.min(performance_scores):.3f}\")\n",
        "print(f\"   Max Performance: {np.max(performance_scores):.3f}\")\n",
        "print(f\"   Performance Range: {np.max(performance_scores) - np.min(performance_scores):.3f}\")\n",
        "\n",
        "stability_score = 1 - np.std(performance_scores)\n",
        "print(f\"\\n   Stability Score: {stability_score:.3f}\")\n",
        "if stability_score >= 0.95:\n",
        "    print(f\"   ‚úÖ Highly stable model\")\n",
        "elif stability_score >= 0.90:\n",
        "    print(f\"   üü° Moderately stable model\")\n",
        "else:\n",
        "    print(f\"   ‚ö†Ô∏è  Model shows significant variability\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1Ô∏è‚É£1Ô∏è‚É£ Generate Static Report (Optional)\n",
        "\n",
        "Generate a static HTML report with matplotlib charts (for PDF export)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìù Generating static HTML report...\n",
            "\n",
            "2025-11-12 22:40:27,340 - deepbridge.reports - INFO - Using static renderer for resilience report\n",
            "2025-11-12 22:40:27,341 - deepbridge.reports - INFO - Generating static resilience report to: /home/guhaase/projetos/DeepBridge/examples/notebooks/03_validation_tests/outputs/resilience_classification/resilience_classification_static.html\n",
            "2025-11-12 22:40:27,343 - deepbridge.reports - INFO - Found template at: /home/guhaase/projetos/DeepBridge/deepbridge/templates/report_types/resilience/static/index.html\n",
            "2025-11-12 22:40:27,343 - deepbridge.reports - INFO - Found resilience template: /home/guhaase/projetos/DeepBridge/deepbridge/templates/report_types/resilience/static/index.html\n",
            "2025-11-12 22:40:27,344 - deepbridge.reports - INFO - Using static template: /home/guhaase/projetos/DeepBridge/deepbridge/templates/report_types/resilience/static/index.html\n",
            "2025-11-12 22:40:27,346 - deepbridge.reports - INFO - CSS compiled successfully using CSSManager for static resilience report\n",
            "2025-11-12 22:40:27,376 - deepbridge.reports - INFO - Transforming resilience data with standard transformer\n",
            "2025-11-12 22:40:27,377 - deepbridge.reports - INFO - Transforming resilience data structure...\n",
            "2025-11-12 22:40:27,380 - deepbridge.reports - INFO - Found primary_model in initial_model_evaluation\n",
            "2025-11-12 22:40:27,381 - deepbridge.reports - INFO - Extracted 30 features from initial_model_evaluation\n",
            "2025-11-12 22:40:27,382 - deepbridge.reports - INFO - Found 'primary_model' key at root level, extracting data...\n",
            "2025-11-12 22:40:27,383 - deepbridge.reports - INFO - Processing alternative models data...\n",
            "2025-11-12 22:40:27,408 - deepbridge.reports - INFO - Standard transformation complete, top-level keys: ['primary_model', 'alternative_models', 'initial_results', 'initial_model_evaluation', 'config', 'experiment_type', 'model_type', 'feature_importance', 'model_feature_importance', 'distribution_shift', 'worst_sample', 'worst_cluster', 'outer_sample', 'hard_sample', 'resilience_score', 'test_scores', 'alphas', 'distance_metrics', 'metrics', 'model_name', 'timestamp', 'metric', 'distribution_shift_results', 'avg_performance_gap']\n",
            "2025-11-12 22:40:27,410 - deepbridge.reports - INFO - Successfully imported ResilienceChartGenerator\n",
            "2025-11-12 22:40:27,415 - deepbridge.reports - INFO - Using StaticResilienceTransformer\n",
            "2025-11-12 22:40:27,416 - deepbridge.reports - INFO - Transforming resilience data for static report\n",
            "2025-11-12 22:40:27,416 - deepbridge.reports - INFO - Transforming resilience data structure...\n",
            "2025-11-12 22:40:27,418 - deepbridge.reports - INFO - Found primary_model in initial_model_evaluation\n",
            "2025-11-12 22:40:27,419 - deepbridge.reports - INFO - Extracted 30 features from initial_model_evaluation\n",
            "2025-11-12 22:40:27,420 - deepbridge.reports - INFO - Found 'primary_model' key at root level, extracting data...\n",
            "2025-11-12 22:40:27,421 - deepbridge.reports - INFO - Processing alternative models data...\n",
            "2025-11-12 22:40:27,446 - deepbridge.reports - INFO - Base transformer produced data with keys: ['primary_model', 'alternative_models', 'initial_results', 'initial_model_evaluation', 'config', 'experiment_type', 'model_type', 'feature_importance', 'model_feature_importance', 'distribution_shift', 'worst_sample', 'worst_cluster', 'outer_sample', 'hard_sample', 'resilience_score', 'test_scores', 'alphas', 'distance_metrics', 'metrics', 'model_name', 'timestamp', 'metric', 'distribution_shift_results', 'avg_performance_gap']\n",
            "2025-11-12 22:40:27,446 - deepbridge.reports - INFO - Transformed resilience data for static report: resilience_score=1.0, avg_performance_gap=0.0\n",
            "2025-11-12 22:40:27,447 - deepbridge.reports - INFO - Starting chart generation with modular chart generator\n",
            "2025-11-12 22:40:27,447 - deepbridge.reports - INFO - Input data for charts has keys: ['model_name', 'test_type', 'timestamp', 'model_type', 'features', 'resilience_score', 'avg_performance_gap', 'metric', 'feature_importance', 'distribution_shift', 'alternative_models', 'model_feature_importance']\n",
            "2025-11-12 22:40:27,448 - deepbridge.reports - INFO - Resilience score: 1.0\n",
            "2025-11-12 22:40:27,448 - deepbridge.reports - INFO - Average performance gap: 0.0\n",
            "2025-11-12 22:40:27,449 - deepbridge.reports - INFO - Feature importance available with 30 features\n",
            "2025-11-12 22:40:27,450 - deepbridge.reports - INFO - Running _generate_charts in transformer with data keys: ['model_name', 'test_type', 'timestamp', 'model_type', 'features', 'resilience_score', 'avg_performance_gap', 'metric', 'feature_importance', 'distribution_shift', 'alternative_models', 'model_feature_importance']\n",
            "2025-11-12 22:40:27,450 - deepbridge.reports - INFO - Generating resilience score chart\n",
            "2025-11-12 22:40:27,537 - deepbridge.reports - INFO - Generated resilience score chart\n",
            "2025-11-12 22:40:27,538 - deepbridge.reports - INFO - Generating feature distribution shift chart\n",
            "2025-11-12 22:40:27,539 - deepbridge.reports - INFO - Feature distances data present: False\n",
            "2025-11-12 22:40:27,539 - deepbridge.reports - INFO - Distribution shift data keys: ['by_alpha', 'by_distance_metric', 'by_metric', 'all_results']\n",
            "2025-11-12 22:40:27,539 - deepbridge.reports - INFO - Found by_distance_metric with keys: ['PSI', 'WD1', 'KS']\n",
            "2025-11-12 22:40:27,540 - deepbridge.reports - INFO - Extracted avg_feature_distances from PSI: True\n",
            "2025-11-12 22:40:27,540 - deepbridge.reports - INFO - Feature distances data has 30 features\n",
            "2025-11-12 22:40:27,541 - deepbridge.reports - INFO - Feature distances sample: [('mean radius', 2.279254161418001), ('mean texture', 0.40819076224544676), ('mean perimeter', 2.623308340684946)]\n",
            "2025-11-12 22:40:27,541 - deepbridge.reports - INFO - Calling generate_feature_distribution_shift\n",
            "2025-11-12 22:40:27,709 - deepbridge.reports - INFO - Generated feature distribution shift chart: 96462 bytes\n",
            "2025-11-12 22:40:27,710 - deepbridge.reports - INFO - Generating performance gap chart\n",
            "2025-11-12 22:40:27,711 - deepbridge.reports - INFO - Performance metrics present: False\n",
            "2025-11-12 22:40:27,711 - deepbridge.reports - INFO - Checking distribution_shift.by_distance_metric for performance metrics\n",
            "2025-11-12 22:40:27,712 - deepbridge.reports - INFO - Constructed performance metrics from PSI results with 6 keys\n",
            "2025-11-12 22:40:27,713 - deepbridge.reports - INFO - Performance metrics keys: ['worst_accuracy', 'remaining_accuracy', 'worst_metric', 'remaining_metric', 'worst_sample_count', 'remaining_sample_count']\n",
            "2025-11-12 22:40:27,713 - deepbridge.reports - INFO - Performance metrics values: {'worst_accuracy': 1.0, 'remaining_accuracy': 1.0, 'worst_metric': 1.0, 'remaining_metric': 1.0, 'worst_sample_count': 136, 'remaining_sample_count': 319}\n",
            "2025-11-12 22:40:27,714 - deepbridge.reports - INFO - Found 2 paired metrics: ['accuracy', 'metric']\n",
            "2025-11-12 22:40:27,714 - deepbridge.reports - INFO - Paired metrics details: [('worst_accuracy', 'remaining_accuracy', 'accuracy'), ('worst_metric', 'remaining_metric', 'metric')]\n",
            "2025-11-12 22:40:27,715 - deepbridge.reports - INFO - Detected task type: classification\n",
            "2025-11-12 22:40:27,716 - deepbridge.reports - INFO - Calling generate_performance_gap\n",
            "2025-11-12 22:40:27,716 - deepbridge.reports - INFO - Found metric pair: accuracy - worst=1.0, remaining=1.0\n",
            "2025-11-12 22:40:27,717 - deepbridge.reports - INFO - Metrics to plot: ['ACCURACY']\n",
            "2025-11-12 22:40:27,718 - deepbridge.reports - INFO - Worst values: [1.0]\n",
            "2025-11-12 22:40:27,718 - deepbridge.reports - INFO - Remaining values: [1.0]\n",
            "2025-11-12 22:40:27,831 - deepbridge.reports - INFO - Generated performance gap chart: 46190 bytes\n",
            "2025-11-12 22:40:27,832 - deepbridge.reports - INFO - Generating critical feature distributions chart\n",
            "2025-11-12 22:40:27,833 - deepbridge.reports - INFO - Generating feature-residual correlation chart\n",
            "2025-11-12 22:40:27,833 - deepbridge.reports - INFO - Generating residual distribution chart\n",
            "2025-11-12 22:40:27,834 - deepbridge.reports - INFO - Generating feature importance chart\n",
            "2025-11-12 22:40:27,834 - deepbridge.reports - INFO - Feature importance present: True\n",
            "2025-11-12 22:40:27,834 - deepbridge.reports - INFO - Feature importance has 30 features\n",
            "2025-11-12 22:40:27,835 - deepbridge.reports - INFO - Feature importance sample: [('worst area', 0.14001598566310833), ('worst concave points', 0.12952961280106504), ('worst radius', 0.09769573685350633)]\n",
            "2025-11-12 22:40:27,836 - deepbridge.reports - INFO - Calling generate_feature_importance_chart\n",
            "2025-11-12 22:40:28,007 - deepbridge.reports - INFO - Generated feature importance chart: 109142 bytes\n",
            "2025-11-12 22:40:28,008 - deepbridge.reports - INFO - Model feature importance present: True\n",
            "2025-11-12 22:40:28,009 - deepbridge.reports - WARNING - No valid model data for comparison scatter plot\n",
            "2025-11-12 22:40:28,010 - deepbridge.reports - ERROR - Feature comparison chart generation returned empty result\n",
            "2025-11-12 22:40:28,011 - deepbridge.reports - INFO - Generating model comparison chart\n",
            "2025-11-12 22:40:28,012 - deepbridge.reports - INFO - Alternative models present: True\n",
            "2025-11-12 22:40:28,012 - deepbridge.reports - INFO - Alpha data present: False\n",
            "2025-11-12 22:40:28,013 - deepbridge.reports - INFO - Found by_alpha in distribution_shift with 3 entries\n",
            "2025-11-12 22:40:28,014 - deepbridge.reports - WARNING - Missing required data for model comparison chart\n",
            "2025-11-12 22:40:28,014 - deepbridge.reports - INFO - Generating model comparison scatter plot\n",
            "2025-11-12 22:40:28,015 - deepbridge.reports - WARNING - Not enough models with both accuracy and resilience scores for scatter plot\n",
            "2025-11-12 22:40:28,015 - deepbridge.reports - INFO - Generating distance metrics comparison chart\n",
            "2025-11-12 22:40:28,016 - deepbridge.reports - WARNING - Not enough metrics data for distance metrics comparison chart\n",
            "2025-11-12 22:40:28,016 - deepbridge.reports - INFO - Generating feature distance heatmap\n",
            "2025-11-12 22:40:28,017 - deepbridge.reports - INFO - Calling generate_feature_distance_heatmap\n",
            "2025-11-12 22:40:28,224 - deepbridge.reports - INFO - Generated feature distance heatmap: 144286 bytes\n",
            "2025-11-12 22:40:28,225 - deepbridge.reports - INFO - Generating model resilience scores bar chart\n",
            "2025-11-12 22:40:28,226 - deepbridge.reports - INFO - Calling generate_model_resilience_scores\n",
            "2025-11-12 22:40:28,301 - deepbridge.reports - INFO - Generated model resilience scores bar chart: 40710 bytes\n",
            "2025-11-12 22:40:28,302 - deepbridge.reports - INFO - Generating performance gap by alpha chart\n",
            "2025-11-12 22:40:28,303 - deepbridge.reports - WARNING - Not enough data for performance gap by alpha chart\n",
            "2025-11-12 22:40:28,303 - deepbridge.reports - INFO - Generated 6 charts for resilience visualization\n",
            "2025-11-12 22:40:28,304 - deepbridge.reports - INFO - Generated 6 charts for resilience visualization\n",
            "2025-11-12 22:40:28,304 - deepbridge.reports - INFO - Chart 'resilience_score_chart' generated with data size: 46638 bytes\n",
            "2025-11-12 22:40:28,304 - deepbridge.reports - INFO - Chart 'feature_distribution_shift' generated with data size: 96462 bytes\n",
            "2025-11-12 22:40:28,305 - deepbridge.reports - INFO - Chart 'performance_gap_chart' generated with data size: 46190 bytes\n",
            "2025-11-12 22:40:28,305 - deepbridge.reports - INFO - Chart 'feature_importance_chart' generated with data size: 109142 bytes\n",
            "2025-11-12 22:40:28,305 - deepbridge.reports - INFO - Chart 'feature_distance_heatmap' generated with data size: 144286 bytes\n",
            "2025-11-12 22:40:28,306 - deepbridge.reports - INFO - Chart 'model_resilience_scores' generated with data size: 40710 bytes\n",
            "2025-11-12 22:40:28,306 - deepbridge.reports - INFO - Applied static transformations to report data\n",
            "2025-11-12 22:40:28,307 - deepbridge.reports - INFO - Static transformation result keys: ['model_name', 'test_type', 'timestamp', 'model_type', 'features', 'resilience_score', 'avg_performance_gap', 'metric', 'feature_importance', 'distribution_shift', 'alternative_models', 'model_feature_importance', 'charts']\n",
            "2025-11-12 22:40:28,307 - deepbridge.reports - INFO - Transforming initial results data\n",
            "2025-11-12 22:40:28,308 - deepbridge.reports.transformers.initial_results - INFO - Transforming initial results data\n",
            "2025-11-12 22:40:28,309 - deepbridge.reports.transformers.initial_results - INFO - Transformed data for 1 models\n",
            "2025-11-12 22:40:28,309 - deepbridge.reports - INFO - Using 6 charts from transformer\n",
            "2025-11-12 22:40:28,310 - deepbridge.reports - INFO - Template variables: resilience_score=1.0, avg_performance_gap=0.0, metric=accuracy\n",
            "2025-11-12 22:40:28,313 - deepbridge.reports - INFO - Output directory ensured: /home/guhaase/projetos/DeepBridge/examples/notebooks/03_validation_tests/outputs/resilience_classification\n",
            "2025-11-12 22:40:28,316 - deepbridge.reports - INFO - Static report saved to: /home/guhaase/projetos/DeepBridge/examples/notebooks/03_validation_tests/outputs/resilience_classification/resilience_classification_static.html\n",
            "2025-11-12 22:40:28,317 - deepbridge.reports - INFO - Report generated and saved to: /home/guhaase/projetos/DeepBridge/examples/notebooks/03_validation_tests/outputs/resilience_classification/resilience_classification_static.html (type: static)\n",
            "\n",
            "‚úÖ Static report generated!\n",
            "üìÇ Location: /home/guhaase/projetos/DeepBridge/examples/notebooks/03_validation_tests/outputs/resilience_classification/resilience_classification_static.html\n",
            "\n",
            "üí° Static reports can be easily printed or converted to PDF\n"
          ]
        }
      ],
      "source": [
        "# Generate static HTML report\n",
        "static_html_path = os.path.join(output_dir, 'resilience_classification_static.html')\n",
        "\n",
        "print(\"üìù Generating static HTML report...\\n\")\n",
        "\n",
        "static_report_path = exp.save_html(\n",
        "    test_type='resilience',\n",
        "    file_path=static_html_path,\n",
        "    model_name='RandomForest Classifier',\n",
        "    report_type='static'  # Uses matplotlib instead of Plotly\n",
        ")\n",
        "\n",
        "print(f\"\\n‚úÖ Static report generated!\")\n",
        "print(f\"üìÇ Location: {static_report_path}\")\n",
        "print(f\"\\nüí° Static reports can be easily printed or converted to PDF\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéâ Summary - Files Generated\n",
        "\n",
        "### üìÇ Output Directory Structure:\n",
        "```\n",
        "outputs/resilience_classification/\n",
        "‚îú‚îÄ‚îÄ resilience_classification_interactive.html  # Interactive report with Plotly\n",
        "‚îú‚îÄ‚îÄ resilience_classification_static.html       # Static report with Matplotlib\n",
        "‚îú‚îÄ‚îÄ resilience_classification_results.json      # Complete results in JSON\n",
        "‚îî‚îÄ‚îÄ resilience_classification_results_COMPACT.json  # Compact JSON for AI\n",
        "```\n",
        "\n",
        "### ‚úÖ What You Learned:\n",
        "\n",
        "1. **Resilience Testing**\n",
        "   - Detect data drift (covariate shift)\n",
        "   - Detect concept drift (relationship changes)\n",
        "   - Assess model stability under distribution shifts\n",
        "   - Calculate resilience scores\n",
        "\n",
        "2. **Report Generation**\n",
        "   - Interactive HTML reports with Plotly\n",
        "   - Static HTML reports with Matplotlib\n",
        "   - Complete control over report type\n",
        "\n",
        "3. **JSON Export**\n",
        "   - Full experiment metadata\n",
        "   - Drift detection metrics\n",
        "   - Per-feature drift analysis\n",
        "   - Resilience scores and recommendations\n",
        "   - Easy integration with monitoring systems\n",
        "\n",
        "4. **Practical Applications**\n",
        "   - Hospital deployment decision protocols\n",
        "   - Credit scoring with economic shifts\n",
        "   - Fraud detection with evolving threats\n",
        "   - Production monitoring strategies\n",
        "\n",
        "### üí° Best Practices:\n",
        "\n",
        "- ‚úÖ Run resilience tests before production deployment\n",
        "- ‚úÖ Establish baseline metrics in development\n",
        "- ‚úÖ Set up continuous drift monitoring\n",
        "- ‚úÖ Define clear retraining triggers\n",
        "- ‚úÖ Monitor both data drift and concept drift\n",
        "- ‚úÖ Export JSON for automated monitoring pipelines\n",
        "\n",
        "### üöÄ Next Steps:\n",
        "\n",
        "- üìò `02_complete_robustness.ipynb` - Model robustness testing\n",
        "- üìò `03_uncertainty_classification.ipynb` - Uncertainty quantification\n",
        "- üìò `../04_fairness/` - Fairness and bias analysis\n",
        "\n",
        "<div style=\"background-color: #e8f5e9; padding: 15px; border-radius: 5px; border-left: 5px solid #4caf50;\">\n",
        "<b>üéØ Key Takeaway:</b> Resilience testing is essential for maintaining model reliability in production. Regular monitoring and retraining based on drift metrics prevent silent model degradation and ensure continued accuracy.\n",
        "</div>"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
