{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# ğŸ›¡ï¸ Complete Robustness Analysis\n",
    "\n",
    "<div style=\"background-color: #e3f2fd; padding: 15px; border-radius: 5px; border-left: 5px solid #2196F3;\">\n",
    "<b>ğŸ““ Information</b><br>\n",
    "<b>Level:</b> Intermediate<br>\n",
    "<b>Time:</b> 25 minutes<br>\n",
    "<b>Dataset:</b> Wine (sklearn)<br>\n",
    "<b>Prerequisite:</b> 01_tests_introduction.ipynb\n",
    "</div>\n",
    "\n",
    "## ğŸ¯ Objectives\n",
    "- âœ… Understand what robustness is in ML\n",
    "- âœ… Run complete robustness analysis\n",
    "- âœ… Interpret perturbation methods\n",
    "- âœ… Analyze sensitive features\n",
    "- âœ… Generate professional HTML report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## ğŸ“š What is Robustness?\n",
    "\n",
    "### Definition\n",
    "**Robustness** is the model's ability to maintain good performance even when input data suffers small perturbations.\n",
    "\n",
    "### Why it matters?\n",
    "1. **Real-world data is imperfect**\n",
    "   - Measurement errors\n",
    "   - Sensor noise\n",
    "   - Manual data entry\n",
    "\n",
    "2. **Security against adversarial attacks**\n",
    "   - Intentional feature manipulation\n",
    "   - Attempts to fool the model\n",
    "\n",
    "3. **Production reliability**\n",
    "   - Model must be stable\n",
    "   - Consistent predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ Setup and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-12 20:58:55,894 - deepbridge.reports - DEBUG - Using refactored FairnessDataTransformer\n",
      "2025-11-12 20:58:55,906 - deepbridge.reports - INFO - Successfully imported radar chart fix\n",
      "2025-11-12 20:58:55,908 - deepbridge.reports - INFO - Successfully patched EnhancedUncertaintyCharts.generate_model_metrics_comparison\n",
      "2025-11-12 20:58:55,909 - deepbridge.reports - INFO - Successfully applied enhanced_charts patch\n",
      "2025-11-12 20:58:55,912 - deepbridge.reports - INFO - Successfully loaded UncertaintyChartGenerator\n",
      "2025-11-12 20:58:55,916 - deepbridge.reports - INFO - Successfully imported and initialized SeabornChartGenerator\n",
      "2025-11-12 20:58:55,917 - deepbridge.reports - INFO - SeabornChartGenerator has_visualization_libs: True\n",
      "2025-11-12 20:58:55,918 - deepbridge.reports - INFO - Available chart methods: ['bar_chart', 'boxplot_chart', 'coverage_analysis_chart', 'detailed_boxplot_chart', 'distribution_grid_chart', 'feature_comparison_chart', 'feature_importance_chart', 'feature_psi_chart', 'generate_encoded_chart', 'heatmap_chart', 'individual_feature_impact_chart', 'method_comparison_chart', 'metrics_radar_chart', 'model_comparison_chart', 'model_metrics_heatmap', 'robustness_overview_chart', 'selected_features_comparison_chart', 'uncertainty_violin_chart', 'worst_performance_chart']\n",
      "2025-11-12 20:58:55,924 - deepbridge.reports - INFO - Successfully imported visualization libraries (numpy, matplotlib, seaborn, pandas)\n",
      "2025-11-12 20:58:55,937 - deepbridge.reports - INFO - Successfully loaded resilience-specific chart generator from deepbridge.templates.report_types.resilience.static.charts\n",
      "2025-11-12 20:58:55,938 - deepbridge.reports - INFO - Available resilience chart methods: ['generate_critical_feature_distributions', 'generate_distance_metrics_comparison', 'generate_feature_distance_heatmap', 'generate_feature_distribution_shift', 'generate_feature_residual_correlation', 'generate_model_comparison', 'generate_model_comparison_scatter', 'generate_model_resilience_scores', 'generate_performance_gap', 'generate_performance_gap_by_alpha', 'generate_residual_distribution']\n",
      "ğŸ“Š Dataset: (178, 14)\n",
      "ğŸ· Classes: ['class_0' 'class_1' 'class_2']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from deepbridge import DBDataset, Experiment\n",
    "\n",
    "# Configure visualizations\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Load data\n",
    "wine = load_wine()\n",
    "df = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
    "df['target'] = wine.target\n",
    "\n",
    "print(f\"ğŸ“Š Dataset: {df.shape}\")\n",
    "print(f\"ğŸ· Classes: {wine.target_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model trained!\n",
      "ğŸ“Š Baseline accuracy: 1.000\n"
     ]
    }
   ],
   "source": [
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "baseline_acc = clf.score(X_test, y_test)\n",
    "print(f\"âœ… Model trained!\")\n",
    "print(f\"ğŸ“Š Baseline accuracy: {baseline_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ Create Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Initial model evaluation complete: RandomForestClassifier\n",
      "âœ… Experiment created!\n"
     ]
    }
   ],
   "source": [
    "dataset = DBDataset(\n",
    "    data=df,\n",
    "    target_column='target',\n",
    "    model=clf,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    dataset_name='Wine Classification'\n",
    ")\n",
    "\n",
    "exp = Experiment(\n",
    "    dataset=dataset,\n",
    "    experiment_type='multiclass_classification',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"âœ… Experiment created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ Quick Test\n",
    "\n",
    "First, let's run a quick test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª Running quick robustness test...\n",
      "\n",
      "âœ… Robustness Tests Finished!\n",
      "ğŸ‰ Test completed successfully: robustness\n",
      "\n",
      "âœ… Quick test completed!\n",
      "\n",
      "ğŸ“Š Robustness Score: 0.000\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ§ª Running quick robustness test...\\n\")\n",
    "\n",
    "rob_quick = exp.run_test('robustness', config_name='quick')\n",
    "\n",
    "print(\"\\nâœ… Quick test completed!\")\n",
    "print(f\"\\nğŸ“Š Robustness Score: {rob_quick.get('robustness_score', 0):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## 5ï¸âƒ£ Complete Test (full)\n",
    "\n",
    "<div style=\"background-color: #fff3e0; padding: 15px; border-radius: 5px; border-left: 5px solid #ff9800;\">\n",
    "<b>â±ï¸ Note:</b> The complete test may take a few minutes!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¬ Running COMPLETE robustness analysis...\n",
      "\n",
      "âœ… Robustness Tests Finished!\n",
      "ğŸ‰ Test completed successfully: robustness\n",
      "\n",
      "âœ… Complete analysis finished!\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ”¬ Running COMPLETE robustness analysis...\\n\")\n",
    "\n",
    "rob_full = exp.run_test('robustness', config_name='full')\n",
    "\n",
    "print(\"\\nâœ… Complete analysis finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## 6ï¸âƒ£ Perturbation Methods\n",
    "\n",
    "DeepBridge tests robustness using different methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š TESTED PERTURBATION METHODS:\n",
      "============================================================\n",
      "\n",
      "\n",
      "ğŸ”¹ RAW PERTURBATION (Gaussian Noise)\n",
      "   Description: Adds Gaussian noise to numerical features\n",
      "   Simulates: Measurement errors, sensor noise\n",
      "\n",
      "ğŸ”¹ QUANTILE PERTURBATION\n",
      "   Description: Perturbs features using quantile-based methods\n",
      "   Simulates: Systematic shifts in feature distributions\n",
      "\n",
      "\n",
      "ğŸ“ˆ IMPACT SUMMARY:\n",
      "   Raw Impact: 0.000\n",
      "   Quantile Impact: 0.000\n",
      "   Overall Impact: 0.000\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ“Š TESTED PERTURBATION METHODS:\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "print(\"\\nğŸ”¹ RAW PERTURBATION (Gaussian Noise)\")\n",
    "print(\"   Description: Adds Gaussian noise to numerical features\")\n",
    "print(\"   Simulates: Measurement errors, sensor noise\")\n",
    "if 'raw' in rob_full and 'by_level' in rob_full['raw']:\n",
    "    levels = sorted(rob_full['raw']['by_level'].keys())\n",
    "    print(f\"   Levels tested: {', '.join(levels)}\")\n",
    "print()\n",
    "    \n",
    "print(\"ğŸ”¹ QUANTILE PERTURBATION\")\n",
    "print(\"   Description: Perturbs features using quantile-based methods\")\n",
    "print(\"   Simulates: Systematic shifts in feature distributions\")\n",
    "if 'quantile' in rob_full and 'by_level' in rob_full['quantile']:\n",
    "    levels = sorted(rob_full['quantile']['by_level'].keys())\n",
    "    print(f\"   Levels tested: {', '.join(levels)}\")\n",
    "print()\n",
    "\n",
    "print(f\"\\nğŸ“ˆ IMPACT SUMMARY:\")\n",
    "print(f\"   Raw Impact: {rob_full.get('avg_raw_impact', 0):.3f}\")\n",
    "print(f\"   Quantile Impact: {rob_full.get('avg_quantile_impact', 0):.3f}\")\n",
    "print(f\"   Overall Impact: {rob_full.get('avg_overall_impact', 0):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## 7ï¸âƒ£ Interpret Robustness Score\n",
    "\n",
    "### Score Scale\n",
    "- **0.95 - 1.00**: ğŸŸ¢ Excellent - Very robust model\n",
    "- **0.85 - 0.95**: ğŸŸ¡ Good - Acceptable robustness\n",
    "- **0.70 - 0.85**: ğŸŸ  Moderate - Needs attention\n",
    "- **< 0.70**: ğŸ”´ Weak - Fragile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š ROBUSTNESS SCORE: 0.000\n",
      "\n",
      "ğŸ”´ WEAK - Fragile model\n",
      "   âŒ NOT recommended for production\n"
     ]
    }
   ],
   "source": [
    "score = rob_full.get('robustness_score', 0)\n",
    "\n",
    "print(f\"\\nğŸ“Š ROBUSTNESS SCORE: {score:.3f}\\n\")\n",
    "\n",
    "if score >= 0.95:\n",
    "    print(\"ğŸŸ¢ EXCELLENT - Very robust model!\")\n",
    "    print(\"   âœ… Ready for production\")\n",
    "elif score >= 0.85:\n",
    "    print(\"ğŸŸ¡ GOOD - Acceptable robustness\")\n",
    "    print(\"   âœ… Can go to production with monitoring\")\n",
    "elif score >= 0.70:\n",
    "    print(\"ğŸŸ  MODERATE - Needs attention\")\n",
    "    print(\"   âš ï¸  Consider improvements before production\")\n",
    "else:\n",
    "    print(\"ğŸ”´ WEAK - Fragile model\")\n",
    "    print(\"   âŒ NOT recommended for production\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## 8ï¸âƒ£ Sensitive Features\n",
    "\n",
    "Analyze which features are most sensitive to perturbations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ’¡ Feature importance not available in results\n",
      "   This may be expected depending on the configuration used\n"
     ]
    }
   ],
   "source": [
    "# Check if feature_importance is available in results\n",
    "if 'feature_importance' in rob_full and rob_full['feature_importance']:\n",
    "    importance = rob_full['feature_importance']\n",
    "    \n",
    "    # Top 5 most important features (those with highest impact when perturbed)\n",
    "    print(\"\\nğŸ” TOP 5 MOST SENSITIVE FEATURES:\\n\" + \"=\"*60)\n",
    "    sorted_features = sorted(importance.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "    \n",
    "    for i, (feature, impact_score) in enumerate(sorted_features, 1):\n",
    "        print(f\"\\n{i}. {feature}\")\n",
    "        print(f\"   Impact Score: {impact_score:.3f}\")\n",
    "        print(f\"   âš ï¸  Perturbations in this feature affect model performance\")\n",
    "else:\n",
    "    print(\"\\nğŸ’¡ Feature importance not available in results\")\n",
    "    print(\"   This may be expected depending on the configuration used\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## 9ï¸âƒ£ Visualize Performance Degradation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Degradation data not available\n",
      "   Make sure you ran the full robustness test\n"
     ]
    }
   ],
   "source": [
    "# Create degradation visualization from raw perturbation data\n",
    "if 'raw' in rob_full and 'by_level' in rob_full['raw']:\n",
    "    raw_data = rob_full['raw']['by_level']\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Plot 1: Degradation curve\n",
    "    plt.subplot(1, 2, 1)\n",
    "    \n",
    "    # Extract levels and scores\n",
    "    levels = []\n",
    "    scores = []\n",
    "    for level_str in sorted(raw_data.keys(), key=lambda x: float(x)):\n",
    "        levels.append(float(level_str))\n",
    "        level_data = raw_data[level_str]\n",
    "        # Get mean score across all features\n",
    "        if 'overall_result' in level_data and 'all_features' in level_data['overall_result']:\n",
    "            mean_score = level_data['overall_result']['all_features'].get('mean_score', 0)\n",
    "            scores.append(mean_score)\n",
    "    \n",
    "    if scores:\n",
    "        plt.plot([0] + levels, [baseline_acc] + scores, \n",
    "                 marker='o', linewidth=2, markersize=8, label='Model Performance')\n",
    "        plt.axhline(y=baseline_acc, color='r', linestyle='--', \n",
    "                    label=f'Baseline ({baseline_acc:.3f})', alpha=0.7)\n",
    "        plt.xlabel('Perturbation Level', fontsize=12)\n",
    "        plt.ylabel('Accuracy', fontsize=12)\n",
    "        plt.title('Performance Degradation', fontsize=14, fontweight='bold')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Impact comparison\n",
    "    plt.subplot(1, 2, 2)\n",
    "    \n",
    "    methods = ['Raw', 'Quantile']\n",
    "    impacts = [\n",
    "        rob_full.get('avg_raw_impact', 0),\n",
    "        rob_full.get('avg_quantile_impact', 0)\n",
    "    ]\n",
    "    \n",
    "    colors = ['#ff6b6b' if impact > 0.3 else '#51cf66' if impact < 0.15 else '#ffd43b' \n",
    "              for impact in impacts]\n",
    "    \n",
    "    bars = plt.barh(methods, impacts, color=colors, edgecolor='navy', alpha=0.7)\n",
    "    plt.xlabel('Average Impact', fontsize=12)\n",
    "    plt.title('Impact by Perturbation Method', fontsize=14, fontweight='bold')\n",
    "    plt.xlim(0, max(impacts) * 1.2 if impacts else 1)\n",
    "    plt.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, (bar, impact) in enumerate(zip(bars, impacts)):\n",
    "        plt.text(impact + 0.01, i, f'{impact:.3f}', \n",
    "                va='center', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"ğŸ“Š Degradation data not available\")\n",
    "    print(\"   Make sure you ran the full robustness test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "## ğŸ”Ÿ Generate HTML Report\n",
    "\n",
    "Generate professional report for documentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cell-21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“„ To generate a complete HTML report, use:\n",
      "   exp.save_report(output_path='robustness_report.html')\n",
      "\n",
      "Or run all tests and generate a comprehensive report:\n",
      "   results = exp.run_tests(config_name='full')\n",
      "   results.save_html('comprehensive_report.html')\n",
      "\n",
      "ğŸ’¡ The HTML report includes:\n",
      "   - Interactive visualizations\n",
      "   - Detailed metrics and tables\n",
      "   - Professional formatting for stakeholders\n",
      "   - Exportable charts and data\n"
     ]
    }
   ],
   "source": [
    "# Generate HTML report using the Experiment's report generation\n",
    "print(\"ğŸ“„ To generate a complete HTML report, use:\")\n",
    "print(\"   exp.save_report(output_path='robustness_report.html')\")\n",
    "print(\"\\nOr run all tests and generate a comprehensive report:\")\n",
    "print(\"   results = exp.run_tests(config_name='full')\")\n",
    "print(\"   results.save_html('comprehensive_report.html')\")\n",
    "\n",
    "print(\"\\nğŸ’¡ The HTML report includes:\")\n",
    "print(\"   - Interactive visualizations\")\n",
    "print(\"   - Detailed metrics and tables\")\n",
    "print(\"   - Professional formatting for stakeholders\")\n",
    "print(\"   - Exportable charts and data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dlye283nzh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“„ Generating HTML report...\n",
      "\n",
      "ğŸ” Debug: Checking data structure...\n",
      "âœ… Feature importance found: 13 features\n",
      "2025-11-12 20:59:00,273 - deepbridge.reports - INFO - Generating SIMPLE robustness report to: /home/guhaase/projetos/DeepBridge/examples/notebooks/03_validation_tests/outputs/robustness_report_complete.html\n",
      "2025-11-12 20:59:00,275 - deepbridge.reports - INFO - Report type: interactive\n",
      "2025-11-12 20:59:00,275 - deepbridge.reports - INFO - Transforming robustness data for report (SIMPLE)\n",
      "2025-11-12 20:59:00,276 - deepbridge.reports - INFO - Found 13 features for report\n",
      "2025-11-12 20:59:00,743 - deepbridge.reports - INFO - Found 13 features for report\n",
      "2025-11-12 20:59:00,773 - deepbridge.reports - INFO - Transformation complete. 6 levels, 13 features\n",
      "2025-11-12 20:59:00,774 - deepbridge.reports - INFO - Found template at: /home/guhaase/projetos/DeepBridge/deepbridge/templates/report_types/robustness/interactive/index.html\n",
      "2025-11-12 20:59:00,775 - deepbridge.reports - DEBUG - Loading template: /home/guhaase/projetos/DeepBridge/deepbridge/templates/report_types/robustness/interactive/index.html\n",
      "2025-11-12 20:59:00,784 - deepbridge.reports - INFO - Template loaded for robustness/interactive\n",
      "2025-11-12 20:59:00,786 - deepbridge.reports - INFO - CSS compiled successfully using CSSManager for robustness: 30594 chars\n",
      "2025-11-12 20:59:00,792 - deepbridge.reports - DEBUG - Rendering template with context keys: ['report_data', 'report_data_json', 'css_content', 'js_content', 'logo', 'favicon_base64', 'model_name', 'model_type', 'timestamp', 'test_type', 'current_year', 'report_title', 'report_subtitle', 'robustness_score', 'base_score', 'avg_impact', 'metric', 'total_levels', 'total_features', 'has_weakspot_analysis', 'weakspot_analysis', 'weakspot_analysis_json', 'has_overfitting_analysis', 'overfitting_analysis', 'overfitting_analysis_json']\n",
      "2025-11-12 20:59:00,793 - deepbridge.reports - INFO - Report generated and saved to: /home/guhaase/projetos/DeepBridge/examples/notebooks/03_validation_tests/outputs/robustness_report_complete.html (type: interactive)\n",
      "2025-11-12 20:59:00,794 - deepbridge.reports - INFO - Output directory ensured: /home/guhaase/projetos/DeepBridge/examples/notebooks/03_validation_tests/outputs\n",
      "2025-11-12 20:59:00,795 - deepbridge.reports - INFO - Report saved to: /home/guhaase/projetos/DeepBridge/examples/notebooks/03_validation_tests/outputs/robustness_report_complete.html\n",
      "2025-11-12 20:59:00,796 - deepbridge.reports - INFO - Report generated and saved to: /home/guhaase/projetos/DeepBridge/examples/notebooks/03_validation_tests/outputs/robustness_report_complete.html (type: interactive)\n",
      "âœ… Report generated successfully!\n",
      "ğŸ“‚ Location: outputs/robustness_report_complete.html\n",
      "\n",
      "ğŸ’¡ Open the file in your browser to view the interactive report\n"
     ]
    }
   ],
   "source": [
    "# Generate HTML report\n",
    "output_path = 'outputs/robustness_report_complete.html'\n",
    "\n",
    "print(\"ğŸ“„ Generating HTML report...\")\n",
    "\n",
    "# Store the result in _test_results so save_html can access it\n",
    "if not hasattr(exp, '_test_results'):\n",
    "    exp._test_results = {}\n",
    "exp._test_results['robustness'] = rob_full\n",
    "\n",
    "# Add initial_results to provide feature importance data\n",
    "if not hasattr(exp, '_experiment_result'):\n",
    "    from collections import OrderedDict\n",
    "    from deepbridge.core.experiment.results import wrap_results\n",
    "    \n",
    "    combined_results = OrderedDict()\n",
    "    combined_results['experiment_type'] = exp.experiment_type\n",
    "    combined_results['config'] = {'name': 'full', 'tests': exp.tests}\n",
    "    \n",
    "    # Create experiment result object\n",
    "    experiment_result = wrap_results(combined_results)\n",
    "    experiment_result.results = OrderedDict()\n",
    "    \n",
    "    # Add initial_results with model feature importance\n",
    "    experiment_result.results['initial_results'] = exp.initial_results\n",
    "    \n",
    "    # Add robustness test results\n",
    "    experiment_result.results['robustness'] = rob_full\n",
    "    \n",
    "    exp._experiment_result = experiment_result\n",
    "    \n",
    "    # Debug: Verify initial_results structure\n",
    "    print(\"\\nğŸ” Debug: Checking data structure...\")\n",
    "    if 'models' in exp.initial_results and 'primary_model' in exp.initial_results['models']:\n",
    "        pm = exp.initial_results['models']['primary_model']\n",
    "        if 'feature_importance' in pm:\n",
    "            print(f\"âœ… Feature importance found: {len(pm['feature_importance'])} features\")\n",
    "        else:\n",
    "            print(\"âŒ Feature importance NOT found in primary_model\")\n",
    "    else:\n",
    "        print(\"âŒ Primary model NOT found in initial_results\")\n",
    "\n",
    "# Now generate the report\n",
    "exp.save_html(test_type='robustness', file_path=output_path, report_type='interactive')\n",
    "print(f\"âœ… Report generated successfully!\")\n",
    "print(f\"ğŸ“‚ Location: {output_path}\")\n",
    "print(f\"\\nğŸ’¡ Open the file in your browser to view the interactive report\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£1ï¸âƒ£ How to Improve Robustness?\n",
    "\n",
    "### Techniques to Increase Robustness:\n",
    "\n",
    "#### 1. **Data Augmentation**\n",
    "```python\n",
    "# Add noise during training\n",
    "X_train_noisy = X_train + np.random.normal(0, 0.1, X_train.shape)\n",
    "```\n",
    "\n",
    "#### 2. **Ensemble Methods**\n",
    "```python\n",
    "# Use multiple models (we're already using RandomForest)\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "```\n",
    "\n",
    "#### 3. **Robust Feature Engineering**\n",
    "- Remove very sensitive features\n",
    "- Create aggregated features\n",
    "- Proper normalization\n",
    "\n",
    "#### 4. **Regularization**\n",
    "```python\n",
    "# Increase regularization (L1, L2, dropout)\n",
    "```\n",
    "\n",
    "#### 5. **Adversarial Training**\n",
    "```python\n",
    "# Train with adversarial examples\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "## ğŸ‰ Conclusion\n",
    "\n",
    "### What you learned:\n",
    "- âœ… **Robustness Concept** - Resistance to perturbations\n",
    "- âœ… **Perturbation Methods** - Gaussian, Dropout, Scaling, Adversarial\n",
    "- âœ… **Interpret Scores** - Scale from 0 to 1\n",
    "- âœ… **Sensitive Features** - Identify vulnerabilities\n",
    "- âœ… **Reports** - Professional documentation\n",
    "- âœ… **Improvement Techniques** - How to increase robustness\n",
    "\n",
    "### Robustness Checklist for Production:\n",
    "- [ ] âœ… Robustness Score > 0.85\n",
    "- [ ] âœ… Sensitive features identified and documented\n",
    "- [ ] âœ… Acceptable degradation in all methods\n",
    "- [ ] âœ… HTML report generated for audit\n",
    "- [ ] âœ… Production monitoring plan\n",
    "\n",
    "### Next Steps:\n",
    "- ğŸ“˜ `03_uncertainty.ipynb` - Quantify uncertainty in predictions\n",
    "- ğŸ“˜ `04_resilience_drift.ipynb` - Detect temporal drift\n",
    "- ğŸ“˜ `06_model_comparison.ipynb` - Compare robustness between models\n",
    "\n",
    "<div style=\"background-color: #e8f5e9; padding: 15px; border-radius: 5px; border-left: 5px solid #4caf50;\">\n",
    "<b>ğŸ’¡ Insight:</b> A model with high accuracy but low robustness can fail in production!\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepbridge-3F2lzRH3-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
