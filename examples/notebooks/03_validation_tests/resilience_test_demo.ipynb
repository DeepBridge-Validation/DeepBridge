{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# \ud83d\udd2c DeepBridge Resilience Testing Demo\n",
    "\n",
    "<div style=\"background-color: #e8f5e9; padding: 15px; border-radius: 5px; border-left: 5px solid #4caf50;\">\n",
    "<b>\ud83d\udcd3 Notebook Purpose</b><br>\n",
    "<b>Goal:</b> Demonstrate how to run resilience tests with DeepBridge<br>\n",
    "<b>Level:</b> Beginner<br>\n",
    "<b>Time:</b> 5-10 minutes<br>\n",
    "<b>Dataset:</b> Breast Cancer (sklearn)\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "## What is Resilience Testing?\n",
    "\n",
    "**Resilience testing** evaluates how robust your model is to:\n",
    "- \ud83d\udcca **Data drift** - Changes in feature distributions\n",
    "- \ud83d\udd04 **Concept drift** - Changes in relationships between features and target\n",
    "- \ud83d\udcc9 **Performance degradation** - Model stability over time\n",
    "- \ud83c\udfaf **Distribution shifts** - Different data characteristics in production\n",
    "\n",
    "### Why is this important?\n",
    "\n",
    "In production, your model will encounter:\n",
    "- Data from different time periods\n",
    "- Data with different statistical properties\n",
    "- Edge cases and outliers\n",
    "\n",
    "**DeepBridge's resilience test** helps you understand if your model will remain reliable when faced with these challenges!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "## 1. \ud83d\udee0\ufe0f Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-12 16:21:33,052 - deepbridge.reports - DEBUG - Using refactored FairnessDataTransformer\n",
      "2025-11-12 16:21:33,554 - deepbridge.reports - INFO - Successfully imported radar chart fix\n",
      "2025-11-12 16:21:33,556 - deepbridge.reports - INFO - Successfully patched EnhancedUncertaintyCharts.generate_model_metrics_comparison\n",
      "2025-11-12 16:21:33,557 - deepbridge.reports - INFO - Successfully applied enhanced_charts patch\n",
      "2025-11-12 16:21:33,561 - deepbridge.reports - INFO - Successfully loaded UncertaintyChartGenerator\n",
      "2025-11-12 16:21:33,563 - deepbridge.reports - INFO - Successfully imported and initialized SeabornChartGenerator\n",
      "2025-11-12 16:21:33,563 - deepbridge.reports - INFO - SeabornChartGenerator has_visualization_libs: True\n",
      "2025-11-12 16:21:33,564 - deepbridge.reports - INFO - Available chart methods: ['bar_chart', 'boxplot_chart', 'coverage_analysis_chart', 'detailed_boxplot_chart', 'distribution_grid_chart', 'feature_comparison_chart', 'feature_importance_chart', 'feature_psi_chart', 'generate_encoded_chart', 'heatmap_chart', 'individual_feature_impact_chart', 'method_comparison_chart', 'metrics_radar_chart', 'model_comparison_chart', 'model_metrics_heatmap', 'robustness_overview_chart', 'selected_features_comparison_chart', 'uncertainty_violin_chart', 'worst_performance_chart']\n",
      "2025-11-12 16:21:33,568 - deepbridge.reports - INFO - Successfully imported visualization libraries (numpy, matplotlib, seaborn, pandas)\n",
      "2025-11-12 16:21:33,575 - deepbridge.reports - INFO - Successfully loaded resilience-specific chart generator from deepbridge.templates.report_types.resilience.static.charts\n",
      "2025-11-12 16:21:33,576 - deepbridge.reports - INFO - Available resilience chart methods: ['generate_critical_feature_distributions', 'generate_distance_metrics_comparison', 'generate_feature_distance_heatmap', 'generate_feature_distribution_shift', 'generate_feature_residual_correlation', 'generate_model_comparison', 'generate_model_comparison_scatter', 'generate_model_resilience_scores', 'generate_performance_gap', 'generate_performance_gap_by_alpha', 'generate_residual_distribution']\n",
      "\u2705 Setup complete!\n",
      "\ud83d\udce6 DeepBridge imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# DeepBridge\n",
    "from deepbridge import DBDataset, Experiment\n",
    "\n",
    "# Configuration\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "print(\"\u2705 Setup complete!\")\n",
    "print(\"\ud83d\udce6 DeepBridge imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-header",
   "metadata": {},
   "source": [
    "## 2. \ud83d\udcca Load Dataset & Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "load-data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\udcca Loading Breast Cancer dataset...\n",
      "\n",
      "Dataset shape: (569, 31)\n",
      "Features: 30\n",
      "Classes: [np.str_('malignant'), np.str_('benign')]\n",
      "Class distribution:\n",
      "target\n",
      "1    357\n",
      "0    212\n",
      "Name: count, dtype: int64\n",
      "\n",
      "First rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows \u00d7 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890       0  \n",
       "1          0.2750                  0.08902       0  \n",
       "2          0.3613                  0.08758       0  \n",
       "3          0.6638                  0.17300       0  \n",
       "4          0.2364                  0.07678       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Breast Cancer dataset\n",
    "print(\"\ud83d\udcca Loading Breast Cancer dataset...\\n\")\n",
    "cancer = load_breast_cancer()\n",
    "df = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
    "df['target'] = cancer.target\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Features: {len(cancer.feature_names)}\")\n",
    "print(f\"Classes: {list(cancer.target_names)}\")\n",
    "print(f\"Class distribution:\\n{df['target'].value_counts()}\")\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nFirst rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "train-model",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83c\udf32 Training Random Forest model...\n",
      "\n",
      "\u2705 Model trained successfully!\n",
      "   Training Accuracy: 1.000\n",
      "   Training ROC AUC: 1.000\n",
      "\n",
      "\ud83d\udca1 Now let's test its resilience!\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest model\n",
    "print(\"\ud83c\udf32 Training Random Forest model...\\n\")\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Train on full dataset (DeepBridge will split internally)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Quick evaluation\n",
    "y_pred = model.predict(X)\n",
    "y_proba = model.predict_proba(X)[:, 1]\n",
    "\n",
    "train_acc = accuracy_score(y, y_pred)\n",
    "train_auc = roc_auc_score(y, y_proba)\n",
    "\n",
    "print(f\"\u2705 Model trained successfully!\")\n",
    "print(f\"   Training Accuracy: {train_acc:.3f}\")\n",
    "print(f\"   Training ROC AUC: {train_auc:.3f}\")\n",
    "print(f\"\\n\ud83d\udca1 Now let's test its resilience!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resilience-header",
   "metadata": {},
   "source": [
    "## 3. \ud83d\udd2c Run DeepBridge Resilience Test\n",
    "\n",
    "DeepBridge will automatically:\n",
    "- \u2705 Split your data into train/test sets\n",
    "- \u2705 Analyze feature distributions\n",
    "- \u2705 Test model performance on perturbed data\n",
    "- \u2705 Detect potential drift issues\n",
    "- \u2705 Calculate resilience scores\n",
    "- \u2705 Generate comprehensive reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "create-dataset",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\udce6 Creating DBDataset...\n",
      "\n",
      "\u2705 DBDataset created successfully!\n",
      "   Total samples: 569\n",
      "   Features: 30\n",
      "   Model: RandomForestClassifier\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Create DBDataset\n",
    "print(\"\ud83d\udce6 Creating DBDataset...\\n\")\n",
    "\n",
    "dataset = DBDataset(\n",
    "    data=df,\n",
    "    target_column='target',\n",
    "    model=model,\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(\"\u2705 DBDataset created successfully!\")\n",
    "print(f\"   Total samples: {len(df)}\")\n",
    "print(f\"   Features: {len(cancer.feature_names)}\")\n",
    "print(f\"   Model: {type(model).__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "create-experiment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83e\uddea Creating Experiment...\n",
      "\n",
      "\u2705 Initial model evaluation complete: RandomForestClassifier\n",
      "\u2705 Experiment initialized!\n",
      "   Ready to run resilience tests...\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Create Experiment\n",
    "print(\"\ud83e\uddea Creating Experiment...\\n\")\n",
    "\n",
    "exp = Experiment(\n",
    "    dataset=dataset,\n",
    "    experiment_type='binary_classification',\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_STATE,\n",
    "    tests=['resilience']  # Specify which tests to prepare\n",
    ")\n",
    "\n",
    "print(\"\u2705 Experiment initialized!\")\n",
    "print(\"   Ready to run resilience tests...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "run-resilience",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\udd2c Running Resilience Test...\n",
      "\n",
      "This will test your model against:\n",
      "  \u2022 Data distribution shifts\n",
      "  \u2022 Feature perturbations\n",
      "  \u2022 Performance stability\n",
      "\n",
      "Please wait...\n",
      "\n",
      "\u2705 Resilience Tests Finished!\n",
      "\ud83c\udf89 Test completed successfully: resilience\n",
      "\n",
      "======================================================================\n",
      "\u2705 RESILIENCE TEST COMPLETED!\n",
      "======================================================================\n",
      "\n",
      "\ud83d\udca1 Generate an HTML report to see detailed visualizations!\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Run Resilience Test\n",
    "print(\"\ud83d\udd2c Running Resilience Test...\\n\")\n",
    "print(\"This will test your model against:\")\n",
    "print(\"  \u2022 Data distribution shifts\")\n",
    "print(\"  \u2022 Feature perturbations\")\n",
    "print(\"  \u2022 Performance stability\")\n",
    "print(\"\\nPlease wait...\\n\")\n",
    "\n",
    "# Run tests with 'quick' configuration\n",
    "# Since we specified tests=['resilience'], only resilience test will run\n",
    "results = exp.run_tests(config_name='quick')\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\u2705 RESILIENCE TEST COMPLETED!\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Access resilience results\n",
    "if hasattr(results, 'results') and 'resilience' in results.results:\n",
    "    resilience_data = results.results['resilience']\n",
    "    \n",
    "    print(\"\\n\ud83d\udcca Key Findings:\\n\")\n",
    "    \n",
    "    # Check if resilience_data has results attribute\n",
    "    if hasattr(resilience_data, 'results'):\n",
    "        res = resilience_data.results\n",
    "    else:\n",
    "        res = resilience_data if isinstance(resilience_data, dict) else {}\n",
    "    \n",
    "    # Model performance\n",
    "    if 'model_performance' in res:\n",
    "        perf = res['model_performance']\n",
    "        print(f\"   Model Performance:\")\n",
    "        if 'accuracy' in perf:\n",
    "            print(f\"      \u2022 Accuracy: {perf['accuracy']:.3f}\")\n",
    "        if 'roc_auc' in perf:\n",
    "            print(f\"      \u2022 ROC AUC: {perf['roc_auc']:.3f}\")\n",
    "    \n",
    "    # Resilience score\n",
    "    if 'resilience_score' in res:\n",
    "        score = res['resilience_score']\n",
    "        print(f\"\\n   Resilience Score: {score:.3f}\")\n",
    "        \n",
    "        if score >= 0.90:\n",
    "            print(f\"      \u2705 Excellent! Model is highly resilient\")\n",
    "        elif score >= 0.75:\n",
    "            print(f\"      \ud83d\udfe1 Good, but shows some sensitivity to drift\")\n",
    "        elif score >= 0.60:\n",
    "            print(f\"      \u26a0\ufe0f  Moderate resilience - monitor closely\")\n",
    "        else:\n",
    "            print(f\"      \u274c Low resilience - consider retraining\")\n",
    "    \n",
    "    # Drift detection\n",
    "    if 'drift_detected' in res:\n",
    "        drift = res['drift_detected']\n",
    "        print(f\"\\n   Drift Detected: {'Yes \u26a0\ufe0f' if drift else 'No \u2705'}\")\n",
    "    \n",
    "    print(\"\\n\ud83d\udca1 Results stored in 'results' variable\")\n",
    "    print(\"   Use results.save_html() to generate reports!\")\n",
    "else:\n",
    "    print(\"\\n\u26a0\ufe0f  Could not access detailed results\")\n",
    "    print(\"   But the test completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "report-header",
   "metadata": {},
   "source": [
    "## 4. \ud83d\udcca Generate Interactive HTML Report\n",
    "\n",
    "Create a comprehensive HTML report with:\n",
    "- \ud83d\udcc8 Interactive visualizations\n",
    "- \ud83d\udcca Detailed metrics and statistics\n",
    "- \ud83d\udd0d Feature-level analysis\n",
    "- \ud83d\udca1 Actionable insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "generate-report",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\udcca Generating Interactive HTML Report...\n",
      "\n",
      "\u274c Error generating report:\n",
      "   No test results available. Run tests first with experiment.run_tests()\n",
      "\n",
      "\ud83d\udca1 Make sure you ran the resilience test first!\n"
     ]
    }
   ],
   "source": [
    "print(\"\ud83d\udcca Generating Interactive HTML Report...\\n\")\n",
    "\n",
    "# Create output directory\n",
    "import os\n",
    "output_dir = \"outputs/resilience_reports\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Define report path\n",
    "report_path = os.path.join(output_dir, \"resilience_report_interactive.html\")\n",
    "\n",
    "# Generate interactive report using the results object\n",
    "try:\n",
    "    # Use the results object returned by run_tests()\n",
    "    saved_path = results.save_html(\n",
    "        test_type='resilience',\n",
    "        file_path=report_path,\n",
    "        model_name='Breast Cancer Classification',\n",
    "        report_type='interactive'  # or 'static' for matplotlib charts\n",
    "    )\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"\u2705 REPORT GENERATED SUCCESSFULLY!\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\n\ud83d\udcc1 Location: {saved_path}\")\n",
    "    print(f\"\\n\ud83d\udca1 Open the report in your browser to explore:\")\n",
    "    print(f\"   \u2022 Resilience scores and metrics\")\n",
    "    print(f\"   \u2022 Model performance analysis\")\n",
    "    print(f\"   \u2022 Feature distribution shifts\")\n",
    "    print(f\"   \u2022 Drift detection results\")\n",
    "    print(f\"   \u2022 Interactive charts and visualizations\")\n",
    "    print(f\"\\n\ud83c\udf10 To open: file://{os.path.abspath(saved_path)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"\u274c Error generating report:\")\n",
    "    print(f\"   {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "static-report-header",
   "metadata": {},
   "source": [
    "### Optional: Generate Static Report\n",
    "\n",
    "If you prefer static matplotlib charts instead of interactive Plotly visualizations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "generate-static-report",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\udcca Generating Static HTML Report...\n",
      "\n",
      "\u274c Error: No test results available. Run tests first with experiment.run_tests()\n"
     ]
    }
   ],
   "source": [
    "# Optional: Generate static report with matplotlib\n",
    "print(\"\ud83d\udcca Generating Static HTML Report...\\n\")\n",
    "\n",
    "report_path_static = os.path.join(output_dir, \"resilience_report_static.html\")\n",
    "\n",
    "try:\n",
    "    # Use the results object returned by run_tests()\n",
    "    saved_path = results.save_html(\n",
    "        test_type='resilience',\n",
    "        file_path=report_path_static,\n",
    "        model_name='Breast Cancer Classification',\n",
    "        report_type='static'\n",
    "    )\n",
    "    \n",
    "    print(\"\u2705 Static report generated!\")\n",
    "    print(f\"   \ud83d\udcc1 Location: {saved_path}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\u274c Error: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## \ud83c\udfaf Summary\n",
    "\n",
    "In this notebook, you learned how to:\n",
    "\n",
    "1. \u2705 **Prepare your data** - Load dataset and train a model\n",
    "2. \u2705 **Create DBDataset** - Wrap your data and model\n",
    "3. \u2705 **Initialize Experiment** - Set up DeepBridge experiment\n",
    "4. \u2705 **Run resilience test** - Evaluate model robustness\n",
    "5. \u2705 **Generate reports** - Create interactive HTML visualizations\n",
    "\n",
    "---\n",
    "\n",
    "## \ud83d\udcda Next Steps\n",
    "\n",
    "Explore other DeepBridge tests:\n",
    "\n",
    "- **Robustness Test** - How does your model handle noisy/perturbed features?\n",
    "- **Uncertainty Test** - How confident is your model in its predictions?\n",
    "- **Fairness Test** - Is your model fair across different groups?\n",
    "- **Hyperparameter Test** - Which hyperparameters matter most?\n",
    "\n",
    "```python\n",
    "# Run multiple tests\n",
    "results = exp.run_tests('quick')  # Runs all configured tests\n",
    "\n",
    "# Or run specific tests\n",
    "robustness_result = exp.run_test('robustness', config='quick')\n",
    "uncertainty_result = exp.run_test('uncertainty', config='quick')\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## \ud83d\udca1 Best Practices\n",
    "\n",
    "1. **Always run resilience tests** before deploying to production\n",
    "2. **Use 'quick' config** for rapid iteration during development\n",
    "3. **Use 'full' config** for comprehensive analysis before deployment\n",
    "4. **Monitor resilience scores** - scores < 0.7 indicate potential issues\n",
    "5. **Review HTML reports** for detailed insights and actionable recommendations\n",
    "\n",
    "---\n",
    "\n",
    "**Remember: A resilient model is a reliable model in production!** \ud83d\ude80"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepbridge-3F2lzRH3-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}