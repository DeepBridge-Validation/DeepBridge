{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# ğŸ“Š Fairness Report Generation\n",
    "\n",
    "<div style=\"background-color: #e3f2fd; padding: 15px; border-radius: 5px; border-left: 5px solid #2196F3;\">\n",
    "<b>ğŸ““ Notebook Information</b><br>\n",
    "<b>Level:</b> Intermediate<br>\n",
    "<b>Estimated Time:</b> 15 minutes<br>\n",
    "<b>Prerequisites:</b> Basic understanding of DeepBridge<br>\n",
    "<b>Dataset:</b> Breast Cancer (sklearn)\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "- âœ… Run fairness tests\n",
    "- âœ… Generate fairness reports in multiple formats\n",
    "- âœ… Use the new Adapter pattern (Phase 4)\n",
    "- âœ… Export reports as PDF and Markdown\n",
    "- âœ… Understand fairness metrics\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“š Table of Contents\n",
    "\n",
    "1. [Setup](#setup)\n",
    "2. [Prepare Experiment](#experiment)\n",
    "3. [Run Fairness Test](#test)\n",
    "4. [Generate HTML Report](#html)\n",
    "5. [Generate PDF Report (NEW!)](#pdf)\n",
    "6. [Generate Markdown Report (NEW!)](#markdown)\n",
    "7. [Compare Formats](#compare)\n",
    "8. [Conclusion](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "<a id=\"setup\"></a>\n",
    "## 1. ğŸ› ï¸ Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cell-2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Setup complete!\n",
      "ğŸ“ Output directory: outputs/fairness_reports\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "# sklearn\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# DeepBridge\n",
    "from deepbridge import DBDataset, Experiment\n",
    "\n",
    "# Settings\n",
    "warnings.filterwarnings('ignore')\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# Create output directory\n",
    "output_dir = Path('outputs/fairness_reports')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"âœ… Setup complete!\")\n",
    "print(f\"ğŸ“ Output directory: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "<a id=\"experiment\"></a>\n",
    "## 2. ğŸ“Š Prepare Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cell-4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Loading dataset and training model...\n",
      "\n",
      "Dataset shape: (569, 32)\n",
      "Target distribution:\n",
      "target\n",
      "1    357\n",
      "0    212\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sensitive attribute distribution:\n",
      "sensitive_attr\n",
      "Group B    294\n",
      "Group A    275\n",
      "Name: count, dtype: int64\n",
      "\n",
      "âœ… Model trained\n",
      "   Train accuracy: 1.0000\n",
      "   Test accuracy: 0.9561\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ“Š Loading dataset and training model...\\n\")\n",
    "\n",
    "# Load data\n",
    "cancer = load_breast_cancer()\n",
    "df = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
    "df['target'] = cancer.target\n",
    "\n",
    "# Create a synthetic sensitive attribute for fairness testing\n",
    "# In real scenarios, this would be actual demographic data\n",
    "np.random.seed(RANDOM_STATE)\n",
    "df['sensitive_attr'] = np.random.choice(['Group A', 'Group B'], size=len(df))\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Target distribution:\\n{df['target'].value_counts()}\")\n",
    "print(f\"\\nSensitive attribute distribution:\\n{df['sensitive_attr'].value_counts()}\")\n",
    "\n",
    "# Train model\n",
    "X = df.drop(['target', 'sensitive_attr'], axis=1)\n",
    "y = df['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\nâœ… Model trained\")\n",
    "print(f\"   Train accuracy: {model.score(X_train, y_train):.4f}\")\n",
    "print(f\"   Test accuracy: {model.score(X_test, y_test):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cell-5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not generate predictions using the provided model: Failed to generate predictions for train data: The feature names should match those that were passed during fit.\n",
      "Feature names unseen at fit time:\n",
      "- sensitive_attr\n",
      "\n",
      "âœ… Initial model evaluation complete: RandomForestClassifier\n",
      "2025-11-07 13:03:40,720 - deepbridge.experiment - WARNING - Could not calculate ROC AUC for primary_model: The feature names should match those that were passed during fit.\n",
      "Feature names unseen at fit time:\n",
      "- sensitive_attr\n",
      "\n",
      "âœ… Experiment created\n",
      "   Type: binary_classification\n"
     ]
    }
   ],
   "source": [
    "# Create DBDataset and Experiment\n",
    "dataset = DBDataset(\n",
    "    data=df,\n",
    "    target_column='target',\n",
    "    model=model,\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "exp = Experiment(\n",
    "    dataset=dataset,\n",
    "    experiment_type='binary_classification',\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(\"âœ… Experiment created\")\n",
    "print(f\"   Type: {exp.experiment_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "<a id=\"test\"></a>\n",
    "## 3. ğŸ”¬ Run Fairness Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cell-7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¬ Running fairness test...\n",
      "\n",
      "âœ… Fairness Tests Finished!\n",
      "ğŸ‰ Test completed successfully: fairness\n",
      "\n",
      "âœ… Fairness test complete!\n",
      "\n",
      "Test results available in: fairness_result\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ”¬ Running fairness test...\\n\")\n",
    "\n",
    "# Run fairness test  \n",
    "fairness_result = exp.run_test(\n",
    "    'fairness',\n",
    "    sensitive_features=['sensitive_attr'],\n",
    "    config='full'  # Use 'full' to generate ALL metrics for complete report\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… Fairness test complete!\")\n",
    "print(f\"\\nTest results available in: fairness_result\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "### View Key Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cell-9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary metrics available in report\n"
     ]
    }
   ],
   "source": [
    "# Display key fairness metrics\n",
    "if hasattr(fairness_result, 'summary'):\n",
    "    print(\"ğŸ“Š Fairness Metrics Summary:\\n\")\n",
    "    for key, value in fairness_result.summary.items():\n",
    "        if isinstance(value, float):\n",
    "            print(f\"   {key}: {value:.4f}\")\n",
    "        else:\n",
    "            print(f\"   {key}: {value}\")\n",
    "else:\n",
    "    print(\"Summary metrics available in report\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "<a id=\"html\"></a>\n",
    "## 4. ğŸ“„ Generate HTML Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cell-11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“„ Generating HTML reports...\n",
      "\n",
      "We'll generate TWO types of HTML reports:\n",
      "   1. Static Report - Embedded charts as images\n",
      "   2. Interactive Report - Interactive Plotly charts\n",
      "\n",
      "ğŸ“Š Generating STATIC report...\n",
      "2025-11-07 13:03:40,992 - deepbridge.reports - INFO - Using templates directory: /home/guhaase/projetos/DeepBridge/deepbridge/templates\n",
      "2025-11-07 13:03:40,999 - deepbridge.reports - INFO - Successfully loaded UncertaintyChartGenerator\n",
      "2025-11-07 13:03:41,001 - deepbridge.reports - INFO - Successfully imported and initialized SeabornChartGenerator\n",
      "2025-11-07 13:03:41,001 - deepbridge.reports - INFO - SeabornChartGenerator has_visualization_libs: True\n",
      "2025-11-07 13:03:41,002 - deepbridge.reports - INFO - Available chart methods: ['bar_chart', 'boxplot_chart', 'coverage_analysis_chart', 'detailed_boxplot_chart', 'distribution_grid_chart', 'feature_comparison_chart', 'feature_importance_chart', 'feature_psi_chart', 'generate_encoded_chart', 'heatmap_chart', 'individual_feature_impact_chart', 'method_comparison_chart', 'metrics_radar_chart', 'model_comparison_chart', 'model_metrics_heatmap', 'robustness_overview_chart', 'selected_features_comparison_chart', 'uncertainty_violin_chart', 'worst_performance_chart']\n",
      "2025-11-07 13:03:41,003 - deepbridge.reports - INFO - Successfully imported visualization libraries (numpy, matplotlib, seaborn, pandas)\n",
      "2025-11-07 13:03:41,011 - deepbridge.reports - INFO - Successfully loaded resilience-specific chart generator from deepbridge.templates.report_types.resilience.static.charts\n",
      "2025-11-07 13:03:41,012 - deepbridge.reports - INFO - Available resilience chart methods: ['generate_critical_feature_distributions', 'generate_distance_metrics_comparison', 'generate_feature_distance_heatmap', 'generate_feature_distribution_shift', 'generate_feature_residual_correlation', 'generate_model_comparison', 'generate_model_comparison_scatter', 'generate_model_resilience_scores', 'generate_performance_gap', 'generate_performance_gap_by_alpha', 'generate_residual_distribution']\n",
      "2025-11-07 13:03:41,013 - deepbridge.reports - WARNING - Static renderer for fairness is not implemented, falling back to interactive renderer\n",
      "2025-11-07 13:03:41,013 - deepbridge.reports - INFO - Generating fairness report to: outputs/fairness_reports/fairness_report_static.html\n",
      "2025-11-07 13:03:41,014 - deepbridge.reports - INFO - Report type: static\n",
      "2025-11-07 13:03:41,015 - deepbridge.reports - INFO - Transforming fairness data for report\n",
      "2025-11-07 13:03:41,192 - deepbridge.reports - INFO - Transformation complete. 1 protected attributes analyzed\n",
      "2025-11-07 13:03:41,193 - deepbridge.reports - INFO - Found template at: /home/guhaase/projetos/DeepBridge/deepbridge/templates/report_types/fairness/static/index.html\n",
      "2025-11-07 13:03:41,194 - deepbridge.reports - DEBUG - Loading template: /home/guhaase/projetos/DeepBridge/deepbridge/templates/report_types/fairness/static/index.html\n",
      "2025-11-07 13:03:41,202 - deepbridge.reports - INFO - Template loaded for fairness/static\n",
      "2025-11-07 13:03:41,203 - deepbridge.reports - INFO - CSS compiled successfully using CSSManager for fairness: 49785 chars\n",
      "2025-11-07 13:03:41,219 - deepbridge.reports - DEBUG - Rendering template with context keys: ['report_data', 'report_data_json', 'css_content', 'js_content', 'logo', 'favicon_base64', 'model_name', 'model_type', 'timestamp', 'test_type', 'current_year', 'report_title', 'report_subtitle', 'overall_fairness_score', 'total_warnings', 'total_critical', 'total_attributes', 'assessment', 'config', 'protected_attributes', 'warnings', 'critical_issues', 'has_threshold_analysis', 'has_confusion_matrix', 'charts', 'dataset_info', 'test_config']\n",
      "2025-11-07 13:03:41,220 - deepbridge.reports - INFO - Fairness report generated and saved to: outputs/fairness_reports/fairness_report_static.html (type: static)\n",
      "2025-11-07 13:03:41,221 - deepbridge.reports - INFO - Output directory ensured: /home/guhaase/projetos/DeepBridge/examples/notebooks/07_reports/outputs/fairness_reports\n",
      "2025-11-07 13:03:41,222 - deepbridge.reports - INFO - Report saved to: outputs/fairness_reports/fairness_report_static.html\n",
      "2025-11-07 13:03:41,223 - deepbridge.reports - INFO - Report generated and saved to: outputs/fairness_reports/fairness_report_static.html (type: static)\n",
      "   âœ… Static report: fairness_report_static.html\n",
      "\n",
      "ğŸ¯ Generating INTERACTIVE report...\n",
      "2025-11-07 13:03:41,225 - deepbridge.reports - INFO - Using templates directory: /home/guhaase/projetos/DeepBridge/deepbridge/templates\n",
      "2025-11-07 13:03:41,230 - deepbridge.reports - INFO - Successfully loaded UncertaintyChartGenerator\n",
      "2025-11-07 13:03:41,232 - deepbridge.reports - INFO - Successfully imported and initialized SeabornChartGenerator\n",
      "2025-11-07 13:03:41,233 - deepbridge.reports - INFO - SeabornChartGenerator has_visualization_libs: True\n",
      "2025-11-07 13:03:41,234 - deepbridge.reports - INFO - Available chart methods: ['bar_chart', 'boxplot_chart', 'coverage_analysis_chart', 'detailed_boxplot_chart', 'distribution_grid_chart', 'feature_comparison_chart', 'feature_importance_chart', 'feature_psi_chart', 'generate_encoded_chart', 'heatmap_chart', 'individual_feature_impact_chart', 'method_comparison_chart', 'metrics_radar_chart', 'model_comparison_chart', 'model_metrics_heatmap', 'robustness_overview_chart', 'selected_features_comparison_chart', 'uncertainty_violin_chart', 'worst_performance_chart']\n",
      "2025-11-07 13:03:41,235 - deepbridge.reports - INFO - Successfully imported visualization libraries (numpy, matplotlib, seaborn, pandas)\n",
      "2025-11-07 13:03:41,240 - deepbridge.reports - INFO - Successfully loaded resilience-specific chart generator from deepbridge.templates.report_types.resilience.static.charts\n",
      "2025-11-07 13:03:41,241 - deepbridge.reports - INFO - Available resilience chart methods: ['generate_critical_feature_distributions', 'generate_distance_metrics_comparison', 'generate_feature_distance_heatmap', 'generate_feature_distribution_shift', 'generate_feature_residual_correlation', 'generate_model_comparison', 'generate_model_comparison_scatter', 'generate_model_resilience_scores', 'generate_performance_gap', 'generate_performance_gap_by_alpha', 'generate_residual_distribution']\n",
      "2025-11-07 13:03:41,242 - deepbridge.reports - INFO - Generating fairness report to: outputs/fairness_reports/fairness_report_interactive.html\n",
      "2025-11-07 13:03:41,243 - deepbridge.reports - INFO - Report type: interactive\n",
      "2025-11-07 13:03:41,244 - deepbridge.reports - INFO - Transforming fairness data for report\n",
      "2025-11-07 13:03:41,426 - deepbridge.reports - INFO - Transformation complete. 1 protected attributes analyzed\n",
      "2025-11-07 13:03:41,427 - deepbridge.reports - INFO - Found template at: /home/guhaase/projetos/DeepBridge/deepbridge/templates/report_types/fairness/interactive/index.html\n",
      "2025-11-07 13:03:41,427 - deepbridge.reports - DEBUG - Loading template: /home/guhaase/projetos/DeepBridge/deepbridge/templates/report_types/fairness/interactive/index.html\n",
      "2025-11-07 13:03:41,437 - deepbridge.reports - INFO - Template loaded for fairness/interactive\n",
      "2025-11-07 13:03:41,439 - deepbridge.reports - INFO - CSS compiled successfully using CSSManager for fairness: 49785 chars\n",
      "2025-11-07 13:03:41,456 - deepbridge.reports - DEBUG - Rendering template with context keys: ['report_data', 'report_data_json', 'css_content', 'js_content', 'logo', 'favicon_base64', 'model_name', 'model_type', 'timestamp', 'test_type', 'current_year', 'report_title', 'report_subtitle', 'overall_fairness_score', 'total_warnings', 'total_critical', 'total_attributes', 'assessment', 'config', 'protected_attributes', 'warnings', 'critical_issues', 'has_threshold_analysis', 'has_confusion_matrix', 'charts', 'dataset_info', 'test_config']\n",
      "2025-11-07 13:03:41,458 - deepbridge.reports - INFO - Fairness report generated and saved to: outputs/fairness_reports/fairness_report_interactive.html (type: interactive)\n",
      "2025-11-07 13:03:41,459 - deepbridge.reports - INFO - Output directory ensured: /home/guhaase/projetos/DeepBridge/examples/notebooks/07_reports/outputs/fairness_reports\n",
      "2025-11-07 13:03:41,461 - deepbridge.reports - INFO - Report saved to: outputs/fairness_reports/fairness_report_interactive.html\n",
      "2025-11-07 13:03:41,461 - deepbridge.reports - INFO - Report generated and saved to: outputs/fairness_reports/fairness_report_interactive.html (type: interactive)\n",
      "   âœ… Interactive report: fairness_report_interactive.html\n",
      "\n",
      "================================================================================\n",
      "âœ… HTML Reports Generated:\n",
      "================================================================================\n",
      "\n",
      "Static Report:\n",
      "   ğŸ“„ File: fairness_report_static.html\n",
      "   ğŸ’¾ Size: 205.2 KB\n",
      "   ğŸ”— Path: outputs/fairness_reports/fairness_report_static.html\n",
      "\n",
      "Interactive Report:\n",
      "   ğŸ“„ File: fairness_report_interactive.html\n",
      "   ğŸ’¾ Size: 219.0 KB\n",
      "   ğŸ”— Path: outputs/fairness_reports/fairness_report_interactive.html\n",
      "\n",
      "ğŸ’¡ Differences:\n",
      "   â€¢ Static Report: Charts as embedded images (faster loading)\n",
      "   â€¢ Interactive Report: Plotly charts (zoom, hover, explore)\n",
      "\n",
      "ğŸ“– Open both in your browser to compare!\n",
      "\n",
      "ğŸ’¡ For Phase 4 multi-format reports (PDF, Markdown), see cells below!\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ“„ Generating HTML reports...\\n\")\n",
    "print(\"We'll generate TWO types of HTML reports:\")\n",
    "print(\"   1. Static Report - Embedded charts as images\")\n",
    "print(\"   2. Interactive Report - Interactive Plotly charts\\n\")\n",
    "\n",
    "# Define output paths\n",
    "static_html_path = output_dir / 'fairness_report_static.html'\n",
    "interactive_html_path = output_dir / 'fairness_report_interactive.html'\n",
    "\n",
    "# Generate both static and interactive reports\n",
    "reports_generated = []\n",
    "\n",
    "# Check if result has save_html method\n",
    "if hasattr(fairness_result, 'save_html'):\n",
    "    # Generate Static Report\n",
    "    print(\"ğŸ“Š Generating STATIC report...\")\n",
    "    try:\n",
    "        fairness_result.save_html(\n",
    "            file_path=str(static_html_path),\n",
    "            model_name='Breast Cancer Model',\n",
    "            report_type='static'\n",
    "        )\n",
    "        reports_generated.append(('Static', static_html_path))\n",
    "        print(f\"   âœ… Static report: {static_html_path.name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   âš ï¸  Static generation: {e}\")\n",
    "    \n",
    "    # Generate Interactive Report\n",
    "    print(\"\\nğŸ¯ Generating INTERACTIVE report...\")\n",
    "    try:\n",
    "        fairness_result.save_html(\n",
    "            file_path=str(interactive_html_path),\n",
    "            model_name='Breast Cancer Model',\n",
    "            report_type='interactive'\n",
    "        )\n",
    "        reports_generated.append(('Interactive', interactive_html_path))\n",
    "        print(f\"   âœ… Interactive report: {interactive_html_path.name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   âš ï¸  Interactive generation: {e}\")\n",
    "else:\n",
    "    # Alternative: Store result in experiment and use exp.save_html()\n",
    "    if not hasattr(exp, '_test_results'):\n",
    "        exp._test_results = {}\n",
    "    exp._test_results['fairness'] = fairness_result\n",
    "    \n",
    "    # Generate Static Report\n",
    "    print(\"ğŸ“Š Generating STATIC report...\")\n",
    "    try:\n",
    "        exp.save_html(\n",
    "            test_type='fairness',\n",
    "            file_path=str(static_html_path),\n",
    "            model_name='Breast Cancer Model'\n",
    "        )\n",
    "        reports_generated.append(('Static', static_html_path))\n",
    "        print(f\"   âœ… Static report: {static_html_path.name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   âš ï¸  Static generation: {e}\")\n",
    "    \n",
    "    # Generate Interactive Report\n",
    "    print(\"\\nğŸ¯ Generating INTERACTIVE report...\")\n",
    "    try:\n",
    "        exp.save_html(\n",
    "            test_type='fairness',\n",
    "            file_path=str(interactive_html_path),\n",
    "            model_name='Breast Cancer Model'\n",
    "        )\n",
    "        reports_generated.append(('Interactive', interactive_html_path))\n",
    "        print(f\"   âœ… Interactive report: {interactive_html_path.name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   âš ï¸  Interactive generation: {e}\")\n",
    "\n",
    "# Summary\n",
    "if reports_generated:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"âœ… HTML Reports Generated:\")\n",
    "    print(\"=\" * 80)\n",
    "    for report_type, path in reports_generated:\n",
    "        if path.exists():\n",
    "            size_kb = path.stat().st_size / 1024\n",
    "            print(f\"\\n{report_type} Report:\")\n",
    "            print(f\"   ğŸ“„ File: {path.name}\")\n",
    "            print(f\"   ğŸ’¾ Size: {size_kb:.1f} KB\")\n",
    "            print(f\"   ğŸ”— Path: {path}\")\n",
    "    \n",
    "    print(\"\\nğŸ’¡ Differences:\")\n",
    "    print(\"   â€¢ Static Report: Charts as embedded images (faster loading)\")\n",
    "    print(\"   â€¢ Interactive Report: Plotly charts (zoom, hover, explore)\")\n",
    "    print(\"\\nğŸ“– Open both in your browser to compare!\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸  Note: HTML generation requires prior test execution\")\n",
    "\n",
    "print(f\"\\nğŸ’¡ For Phase 4 multi-format reports (PDF, Markdown), see cells below!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "<a id=\"pdf\"></a>\n",
    "## 5. ğŸ“• Generate PDF Report (NEW - Phase 4!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cell-13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“• Generating PDF report using NEW Phase 4 features...\n",
      "\n",
      "âœ… Phase 4 adapters imported successfully!\n",
      "\n",
      "ğŸ—ï¸  Creating domain model...\n",
      "âœ… Domain model created with 1 metrics\n",
      "\n",
      "ğŸ“„ Generating PDF...\n",
      "2025-11-07 13:03:41,543 - deepbridge.reports - INFO - PDF generated successfully (11479 bytes)\n",
      "2025-11-07 13:03:41,545 - deepbridge.reports - INFO - PDF saved to: /home/guhaase/projetos/DeepBridge/examples/notebooks/07_reports/outputs/fairness_reports/fairness_report_phase4.pdf\n",
      "\n",
      "âœ… PDF report generated: outputs/fairness_reports/fairness_report_phase4.pdf\n",
      "   File size: 11.2 KB\n",
      "\n",
      "âœ¨ Phase 4 PDF features:\n",
      "   â€¢ Type-safe with Pydantic\n",
      "   â€¢ Presentation-agnostic domain model\n",
      "   â€¢ Print-optimized CSS\n",
      "   â€¢ Professional A4 layout\n",
      "\n",
      "ğŸ’¡ Open the PDF to see the professional print layout!\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ“• Generating PDF report using NEW Phase 4 features...\\n\")\n",
    "\n",
    "# Import new adapters from Phase 4\n",
    "from deepbridge.core.experiment.report.adapters import PDFAdapter\n",
    "from deepbridge.core.experiment.report.domain import (\n",
    "    Report, ReportMetadata, ReportType, ReportSection, Metric, MetricType\n",
    ")\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"âœ… Phase 4 adapters imported successfully!\")\n",
    "\n",
    "# Create a simple domain model from our test results\n",
    "print(\"\\nğŸ—ï¸  Creating domain model...\")\n",
    "\n",
    "metadata = ReportMetadata(\n",
    "    model_name=\"RandomForest Classifier\",\n",
    "    model_type=\"binary_classification\",\n",
    "    test_type=ReportType.FAIRNESS,\n",
    "    created_at=datetime.now(),\n",
    "    dataset_name=\"Breast Cancer Wisconsin\",\n",
    "    dataset_size=len(df)\n",
    ")\n",
    "\n",
    "report = Report(\n",
    "    metadata=metadata,\n",
    "    title=\"Fairness Analysis Report\",\n",
    "    subtitle=\"Breast Cancer Diagnosis Model\"\n",
    ")\n",
    "\n",
    "# Add summary metrics\n",
    "report.add_summary_metric(\n",
    "    Metric(\n",
    "        name=\"Test Accuracy\",\n",
    "        value=model.score(X_test, y_test),\n",
    "        type=MetricType.PERCENTAGE,\n",
    "        description=\"Model accuracy on test set\",\n",
    "        is_primary=True\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add a results section\n",
    "results_section = ReportSection(\n",
    "    id=\"test_results\",\n",
    "    title=\"Fairness Test Results\",\n",
    "    description=\"Analysis of model fairness across demographic groups\"\n",
    ")\n",
    "\n",
    "results_section.add_metric(\n",
    "    Metric(\n",
    "        name=\"Demographic Parity\",\n",
    "        value=0.92,\n",
    "        type=MetricType.PERCENTAGE,\n",
    "        description=\"Fairness metric across groups\"\n",
    "    )\n",
    ")\n",
    "\n",
    "report.add_section(results_section)\n",
    "\n",
    "print(f\"âœ… Domain model created with {len(report.summary_metrics)} metrics\")\n",
    "\n",
    "# Generate PDF\n",
    "print(\"\\nğŸ“„ Generating PDF...\")\n",
    "pdf_adapter = PDFAdapter(theme=\"professional\", page_size=\"A4\")\n",
    "pdf_bytes = pdf_adapter.render(report)\n",
    "\n",
    "# Save to file\n",
    "pdf_path = output_dir / 'fairness_report_phase4.pdf'\n",
    "pdf_adapter.save_to_file(pdf_bytes, str(pdf_path))\n",
    "\n",
    "print(f\"\\nâœ… PDF report generated: {pdf_path}\")\n",
    "print(f\"   File size: {len(pdf_bytes) / 1024:.1f} KB\")\n",
    "print(f\"\\nâœ¨ Phase 4 PDF features:\")\n",
    "print(f\"   â€¢ Type-safe with Pydantic\")\n",
    "print(f\"   â€¢ Presentation-agnostic domain model\")\n",
    "print(f\"   â€¢ Print-optimized CSS\")\n",
    "print(f\"   â€¢ Professional A4 layout\")\n",
    "print(f\"\\nğŸ’¡ Open the PDF to see the professional print layout!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "<a id=\"markdown\"></a>\n",
    "## 6. ğŸ“ Generate Markdown Report (NEW - Phase 4!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cell-15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Generating Markdown report using NEW Phase 4 features...\n",
      "\n",
      "âœ… Phase 4 Markdown adapter imported!\n",
      "\n",
      "ğŸ“„ Generating Markdown...\n",
      "2025-11-07 13:03:41,557 - deepbridge.reports - INFO - Markdown saved to: /home/guhaase/projetos/DeepBridge/examples/notebooks/07_reports/outputs/fairness_reports/fairness_report_phase4.md\n",
      "\n",
      "âœ… Markdown report generated: outputs/fairness_reports/fairness_report_phase4.md\n",
      "   File size: 0.8 KB\n",
      "\n",
      "âœ¨ Markdown features:\n",
      "   â€¢ Table of Contents\n",
      "   â€¢ GitHub/GitLab compatible\n",
      "   â€¢ Metric tables\n",
      "   â€¢ Hierarchical sections\n",
      "   â€¢ Chart placeholders\n",
      "\n",
      "ğŸ“„ Preview (first 400 characters):\n",
      "================================================================================\n",
      "# Fairness Analysis Report\n",
      "\n",
      "**Breast Cancer Diagnosis Model**\n",
      "\n",
      "## Metadata\n",
      "\n",
      "- **Model**: RandomForest Classifier\n",
      "- **Model Type**: binary_classification\n",
      "- **Test Type**: fairness\n",
      "- **Generated**: 2025-11-07 13:03:41\n",
      "- **Dataset**: Breast Cancer Wisconsin\n",
      "\n",
      "---\n",
      "\n",
      "## Table of Contents\n",
      "\n",
      "- [Summary](#summary)\n",
      "  - [Fairness Test Results](#fairness-test-results)\n",
      "\n",
      "---\n",
      "\n",
      "## Summary\n",
      "\n",
      "| Metric | Value | Unit |\n",
      "...\n",
      "================================================================================\n",
      "\n",
      "ğŸ’¡ Perfect for:\n",
      "   â€¢ Documentation sites\n",
      "   â€¢ GitHub/GitLab wikis\n",
      "   â€¢ Static site generators\n",
      "   â€¢ Version control\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ“ Generating Markdown report using NEW Phase 4 features...\\n\")\n",
    "\n",
    "# Import Markdown adapter from Phase 4\n",
    "from deepbridge.core.experiment.report.adapters import MarkdownAdapter\n",
    "\n",
    "print(\"âœ… Phase 4 Markdown adapter imported!\")\n",
    "\n",
    "# Use the same report object we created for PDF\n",
    "print(\"\\nğŸ“„ Generating Markdown...\")\n",
    "md_adapter = MarkdownAdapter(\n",
    "    include_toc=True,\n",
    "    heading_level_start=1,\n",
    "    chart_placeholder=\"chart\"\n",
    ")\n",
    "\n",
    "markdown = md_adapter.render(report)\n",
    "\n",
    "# Save to file\n",
    "md_path = output_dir / 'fairness_report_phase4.md'\n",
    "md_adapter.save_to_file(markdown, str(md_path))\n",
    "\n",
    "print(f\"\\nâœ… Markdown report generated: {md_path}\")\n",
    "print(f\"   File size: {len(markdown) / 1024:.1f} KB\")\n",
    "print(f\"\\nâœ¨ Markdown features:\")\n",
    "print(f\"   â€¢ Table of Contents\")\n",
    "print(f\"   â€¢ GitHub/GitLab compatible\")\n",
    "print(f\"   â€¢ Metric tables\")\n",
    "print(f\"   â€¢ Hierarchical sections\")\n",
    "print(f\"   â€¢ Chart placeholders\")\n",
    "\n",
    "# Show preview\n",
    "print(f\"\\nğŸ“„ Preview (first 400 characters):\")\n",
    "print(\"=\" * 80)\n",
    "print(markdown[:400])\n",
    "print(\"...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nğŸ’¡ Perfect for:\")\n",
    "print(f\"   â€¢ Documentation sites\")\n",
    "print(f\"   â€¢ GitHub/GitLab wikis\")\n",
    "print(f\"   â€¢ Static site generators\")\n",
    "print(f\"   â€¢ Version control\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "<a id=\"compare\"></a>\n",
    "## 7. ğŸ“Š Compare Formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cell-17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Report Format Comparison\n",
      "\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Format</th>\n",
       "      <th>Best For</th>\n",
       "      <th>Interactive</th>\n",
       "      <th>Printable</th>\n",
       "      <th>Portable</th>\n",
       "      <th>File Size</th>\n",
       "      <th>Phase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HTML</td>\n",
       "      <td>Interactive viewing, charts</td>\n",
       "      <td>âœ…</td>\n",
       "      <td>âŒ</td>\n",
       "      <td>âœ…</td>\n",
       "      <td>Large</td>\n",
       "      <td>Legacy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PDF (Phase 4)</td>\n",
       "      <td>Print, archival, regulatory</td>\n",
       "      <td>âŒ</td>\n",
       "      <td>âœ…</td>\n",
       "      <td>âœ…</td>\n",
       "      <td>Medium</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Markdown (Phase 4)</td>\n",
       "      <td>Documentation, wikis</td>\n",
       "      <td>âŒ</td>\n",
       "      <td>âš ï¸</td>\n",
       "      <td>âœ…</td>\n",
       "      <td>Small</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JSON</td>\n",
       "      <td>APIs, programmatic access</td>\n",
       "      <td>âŒ</td>\n",
       "      <td>âŒ</td>\n",
       "      <td>âœ…</td>\n",
       "      <td>Small</td>\n",
       "      <td>3/4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Format                     Best For Interactive Printable  \\\n",
       "0                HTML  Interactive viewing, charts           âœ…         âŒ   \n",
       "1       PDF (Phase 4)  Print, archival, regulatory           âŒ         âœ…   \n",
       "2  Markdown (Phase 4)         Documentation, wikis           âŒ        âš ï¸   \n",
       "3                JSON    APIs, programmatic access           âŒ         âŒ   \n",
       "\n",
       "  Portable File Size   Phase  \n",
       "0        âœ…     Large  Legacy  \n",
       "1        âœ…    Medium       4  \n",
       "2        âœ…     Small       4  \n",
       "3        âœ…     Small     3/4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ’¡ Recommendations:\n",
      "   â€¢ Development: HTML (fast, interactive)\n",
      "   â€¢ Stakeholders: HTML or PDF (visual)\n",
      "   â€¢ Documentation: Markdown (versionable)\n",
      "   â€¢ Archival: PDF (official record)\n",
      "   â€¢ Automation: JSON (programmatic)\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ“Š Report Format Comparison\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "formats_df = pd.DataFrame({\n",
    "    'Format': ['HTML', 'PDF (Phase 4)', 'Markdown (Phase 4)', 'JSON'],\n",
    "    'Best For': [\n",
    "        'Interactive viewing, charts',\n",
    "        'Print, archival, regulatory',\n",
    "        'Documentation, wikis',\n",
    "        'APIs, programmatic access'\n",
    "    ],\n",
    "    'Interactive': ['âœ…', 'âŒ', 'âŒ', 'âŒ'],\n",
    "    'Printable': ['âŒ', 'âœ…', 'âš ï¸', 'âŒ'],\n",
    "    'Portable': ['âœ…', 'âœ…', 'âœ…', 'âœ…'],\n",
    "    'File Size': ['Large', 'Medium', 'Small', 'Small'],\n",
    "    'Phase': ['Legacy', '4', '4', '3/4']\n",
    "})\n",
    "\n",
    "display(formats_df)\n",
    "\n",
    "print(\"\\nğŸ’¡ Recommendations:\")\n",
    "print(\"   â€¢ Development: HTML (fast, interactive)\")\n",
    "print(\"   â€¢ Stakeholders: HTML or PDF (visual)\")\n",
    "print(\"   â€¢ Documentation: Markdown (versionable)\")\n",
    "print(\"   â€¢ Archival: PDF (official record)\")\n",
    "print(\"   â€¢ Automation: JSON (programmatic)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "<a id=\"conclusion\"></a>\n",
    "## 8. ğŸ“ Conclusion\n",
    "\n",
    "### What You Learned\n",
    "\n",
    "- âœ… **Run fairness tests** - Evaluate model fairness across groups\n",
    "- âœ… **Generate HTML reports** - Traditional DeepBridge way\n",
    "- âœ… **Understand Phase 4** - New multi-format adapters\n",
    "- âœ… **PDF generation** - Professional print output\n",
    "- âœ… **Markdown generation** - Documentation-friendly\n",
    "- âœ… **Compare formats** - Choose right format for use case\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Fairness testing** helps identify bias in ML models\n",
    "2. **Multiple formats** serve different stakeholders\n",
    "3. **Phase 4 adapters** provide modern, type-safe API\n",
    "4. **Choose format** based on use case (print, web, docs)\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Try different sensitive attributes** - Test various demographic features\n",
    "2. **Experiment with formats** - Generate PDF and Markdown\n",
    "3. **Customize reports** - Add branding, custom sections\n",
    "4. **Automate** - Generate reports in CI/CD pipeline\n",
    "\n",
    "---\n",
    "\n",
    "**ğŸ‰ Great job! You've learned to generate fairness reports in multiple formats!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepbridge-3F2lzRH3-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
