{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üè† Use Case: Regression - House Price Prediction\n",
    "\n",
    "<div style=\"background-color: #e3f2fd; padding: 15px; border-radius: 5px; border-left: 5px solid #2196F3;\">\n",
    "<b>üìì Regression Use Case</b><br>\n",
    "<b>Level:</b> Intermediate<br>\n",
    "<b>Duration:</b> 25 minutes<br>\n",
    "<b>Dataset:</b> House Prices (synthetic)<br>\n",
    "<b>Type:</b> üìà REGRESSION (not classification!)\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "- ‚úÖ Apply DeepBridge to **regression** problems (not just classification!)\n",
    "- ‚úÖ Use `experiment_type='regression'`\n",
    "- ‚úÖ Interpret regression-specific metrics (R¬≤, RMSE, MAE)\n",
    "- ‚úÖ Test robustness for continuous predictions\n",
    "- ‚úÖ Quantify uncertainty in price predictions\n",
    "- ‚úÖ Validate regression models for production\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Table of Contents\n",
    "\n",
    "1. [Introduction](#intro)\n",
    "2. [Business Context](#context)\n",
    "3. [Setup & Data](#data)\n",
    "4. [EDA](#eda)\n",
    "5. [Model Training](#training)\n",
    "6. [Performance Analysis](#performance)\n",
    "7. [DeepBridge for Regression](#deepbridge)\n",
    "8. [Robustness Testing](#robustness)\n",
    "9. [Uncertainty Quantification](#uncertainty)\n",
    "10. [Production Readiness](#production)\n",
    "11. [Conclusion](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"intro\"></a>\n",
    "## 1. üìñ Introduction\n",
    "\n",
    "### üè† Why House Prices?\n",
    "\n",
    "House price prediction is a perfect example of **regression** because:\n",
    "- üìä **Continuous target** - Price is a real number, not a category\n",
    "- üí∞ **High stakes** - Prediction errors = money lost\n",
    "- üèóÔ∏è **Many features** - Location, size, amenities, etc.\n",
    "- üìà **Real business value** - Used by real estate platforms, banks, investors\n",
    "\n",
    "### Classification vs Regression in DeepBridge\n",
    "\n",
    "| Aspect | Classification | Regression |\n",
    "|--------|---------------|------------|\n",
    "| **Target** | Categories (0, 1, 2, ...) | Continuous (100.5, 250000, ...) |\n",
    "| **Metrics** | Accuracy, ROC AUC, F1 | R¬≤, RMSE, MAE |\n",
    "| **Output** | Class probabilities | Predicted value |\n",
    "| **experiment_type** | `'binary_classification'` or `'multiclass'` | `'regression'` |\n",
    "| **Tests** | All work! | All work! |\n",
    "\n",
    "### üéØ What's Different?\n",
    "\n",
    "DeepBridge automatically adapts:\n",
    "- ‚úÖ Uses regression metrics (R¬≤, RMSE, MAE)\n",
    "- ‚úÖ Adjusts perturbation strategies\n",
    "- ‚úÖ Generates regression-specific reports\n",
    "- ‚úÖ Same API - just change `experiment_type='regression'`!\n",
    "\n",
    "**Let's see it in action!** üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"context\"></a>\n",
    "## 2. üè¢ Business Context\n",
    "\n",
    "### The Scenario\n",
    "\n",
    "You work at **HomeSmart**, a real estate tech company.\n",
    "\n",
    "**Your Task:**\n",
    "> \"Build a model to predict house prices for our platform. Buyers and sellers rely on our estimates. If we're consistently wrong, we lose credibility and customers. The model must be accurate, robust, and provide confidence intervals.\"\n",
    "> \n",
    "> ‚Äî VP of Data Science\n",
    "\n",
    "### üíº Business Requirements\n",
    "\n",
    "1. **Accuracy** - R¬≤ ‚â• 0.85, MAPE ‚â§ 10%\n",
    "2. **Robustness** - Small changes in features shouldn't drastically change price\n",
    "3. **Uncertainty** - Provide price ranges (e.g., $280K - $320K)\n",
    "4. **No outliers** - Detect and handle extreme predictions\n",
    "5. **Feature importance** - Explain what drives prices\n",
    "\n",
    "### ‚ö†Ô∏è Risks\n",
    "\n",
    "- **Overpricing** ‚Üí Houses don't sell, sellers unhappy\n",
    "- **Underpricing** ‚Üí Money left on table, sellers lose\n",
    "- **Inconsistency** ‚Üí Similar houses, very different prices ‚Üí credibility loss\n",
    "- **No confidence** ‚Üí Users don't trust predictions\n",
    "\n",
    "**Let's build it right with DeepBridge!** üèóÔ∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data\"></a>\n",
    "## 3. üõ†Ô∏è Setup & Data\n",
    "\n",
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import (\n",
    "    r2_score, mean_squared_error, mean_absolute_error,\n",
    "    mean_absolute_percentage_error\n",
    ")\n",
    "\n",
    "# DeepBridge - Works for regression too!\n",
    "from deepbridge import DBDataset, Experiment\n",
    "\n",
    "# Settings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('Set2')\n",
    "%matplotlib inline\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "print(\"‚úÖ Setup complete!\")\n",
    "print(\"üè† Project: House Price Prediction (Regression)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Realistic House Price Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üèóÔ∏è Generating realistic house price dataset...\\n\")\n",
    "\n",
    "np.random.seed(RANDOM_STATE)\n",
    "n = 2000\n",
    "\n",
    "# Generate features\n",
    "df = pd.DataFrame({\n",
    "    # Property characteristics\n",
    "    'sqft': np.random.gamma(4, 500, n).clip(500, 5000),  # Square footage\n",
    "    'bedrooms': np.random.choice([1, 2, 3, 4, 5], n, p=[0.1, 0.2, 0.35, 0.25, 0.1]),\n",
    "    'bathrooms': np.random.choice([1, 1.5, 2, 2.5, 3], n, p=[0.15, 0.15, 0.35, 0.25, 0.1]),\n",
    "    'floors': np.random.choice([1, 1.5, 2, 3], n, p=[0.4, 0.2, 0.3, 0.1]),\n",
    "    'waterfront': np.random.choice([0, 1], n, p=[0.9, 0.1]),\n",
    "    'view_quality': np.random.choice([0, 1, 2, 3, 4], n, p=[0.3, 0.3, 0.2, 0.15, 0.05]),\n",
    "    'condition': np.random.choice([1, 2, 3, 4, 5], n, p=[0.05, 0.15, 0.4, 0.3, 0.1]),\n",
    "    'grade': np.random.choice(range(1, 14), n),  # Build quality\n",
    "    'age_years': np.random.gamma(2, 10, n).clip(0, 100),  # Years since built\n",
    "    'renovated': np.random.choice([0, 1], n, p=[0.7, 0.3]),\n",
    "    \n",
    "    # Location (simplified)\n",
    "    'lat': np.random.normal(47.5, 0.2, n),  # Latitude (Seattle-like)\n",
    "    'long': np.random.normal(-122.2, 0.2, n),  # Longitude\n",
    "    'distance_to_city': np.random.gamma(2, 5, n).clip(0, 50),  # km to city center\n",
    "})\n",
    "\n",
    "# Generate realistic prices based on features\n",
    "base_price = 200000  # Base price\n",
    "\n",
    "price = (\n",
    "    base_price +\n",
    "    df['sqft'] * 150 +  # $150 per sqft\n",
    "    df['bedrooms'] * 20000 +\n",
    "    df['bathrooms'] * 15000 +\n",
    "    df['floors'] * 10000 +\n",
    "    df['waterfront'] * 200000 +  # Waterfront premium\n",
    "    df['view_quality'] * 30000 +\n",
    "    df['condition'] * 10000 +\n",
    "    df['grade'] * 15000 +\n",
    "    -df['age_years'] * 1000 +  # Depreciation\n",
    "    df['renovated'] * 50000 +\n",
    "    -df['distance_to_city'] * 3000  # Location premium\n",
    ")\n",
    "\n",
    "# Add realistic noise\n",
    "price = price * (1 + np.random.normal(0, 0.1, n))  # 10% noise\n",
    "price = price.clip(100000, 2000000)  # Reasonable bounds\n",
    "\n",
    "df['price'] = price\n",
    "\n",
    "print(f\"‚úÖ Dataset created: {df.shape}\")\n",
    "print(f\"\\nüí∞ Price Statistics:\")\n",
    "print(f\"   Mean: ${df['price'].mean():,.0f}\")\n",
    "print(f\"   Median: ${df['price'].median():,.0f}\")\n",
    "print(f\"   Min: ${df['price'].min():,.0f}\")\n",
    "print(f\"   Max: ${df['price'].max():,.0f}\")\n",
    "print(f\"   Std: ${df['price'].std():,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"eda\"></a>\n",
    "## 4. üìä Exploratory Data Analysis\n",
    "\n",
    "### Price Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(df['price'], bins=50, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "axes[0].axvline(df['price'].mean(), color='red', linestyle='--', \n",
    "                linewidth=2, label=f'Mean: ${df[\"price\"].mean():,.0f}')\n",
    "axes[0].axvline(df['price'].median(), color='green', linestyle='--', \n",
    "                linewidth=2, label=f'Median: ${df[\"price\"].median():,.0f}')\n",
    "axes[0].set_title('Price Distribution', fontsize=13, fontweight='bold')\n",
    "axes[0].set_xlabel('Price ($)', fontsize=11)\n",
    "axes[0].set_ylabel('Count', fontsize=11)\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Box plot\n",
    "axes[1].boxplot(df['price'], vert=True, patch_artist=True,\n",
    "                boxprops=dict(facecolor='lightblue', alpha=0.7),\n",
    "                medianprops=dict(color='red', linewidth=2))\n",
    "axes[1].set_title('Price Box Plot', fontsize=13, fontweight='bold')\n",
    "axes[1].set_ylabel('Price ($)', fontsize=11)\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Check for outliers\n",
    "q1 = df['price'].quantile(0.25)\n",
    "q3 = df['price'].quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "outliers = df[(df['price'] < q1 - 1.5*iqr) | (df['price'] > q3 + 1.5*iqr)]\n",
    "\n",
    "print(f\"\\nüìä Outlier Analysis:\")\n",
    "print(f\"   Outliers: {len(outliers)} ({len(outliers)/len(df)*100:.1f}%)\")\n",
    "if len(outliers) > 0:\n",
    "    print(f\"   Outlier price range: ${outliers['price'].min():,.0f} - ${outliers['price'].max():,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Correlations with Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation with price\n",
    "correlations = df.corr()['price'].sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "correlations[1:].plot(kind='barh', color='steelblue', edgecolor='black', alpha=0.8)\n",
    "plt.title('Feature Correlation with Price', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Correlation Coefficient', fontsize=12)\n",
    "plt.axvline(x=0, color='black', linestyle='-', linewidth=0.8)\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüéØ TOP PRICE DRIVERS:\")\n",
    "print(correlations[1:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Feature Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plots of key features\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "features_to_plot = ['sqft', 'bedrooms', 'bathrooms', 'grade', 'age_years', 'distance_to_city']\n",
    "\n",
    "for i, feature in enumerate(features_to_plot):\n",
    "    axes[i].scatter(df[feature], df['price'], alpha=0.3, s=20, color='steelblue')\n",
    "    \n",
    "    # Add trend line\n",
    "    z = np.polyfit(df[feature], df['price'], 1)\n",
    "    p = np.poly1d(z)\n",
    "    x_trend = np.linspace(df[feature].min(), df[feature].max(), 100)\n",
    "    axes[i].plot(x_trend, p(x_trend), \"r--\", linewidth=2, alpha=0.8)\n",
    "    \n",
    "    axes[i].set_title(f'{feature} vs Price', fontsize=12, fontweight='bold')\n",
    "    axes[i].set_xlabel(feature, fontsize=10)\n",
    "    axes[i].set_ylabel('Price ($)', fontsize=10)\n",
    "    axes[i].grid(alpha=0.3)\n",
    "    \n",
    "    # Add correlation\n",
    "    corr = df[feature].corr(df['price'])\n",
    "    axes[i].text(0.05, 0.95, f'r = {corr:.2f}', \n",
    "                 transform=axes[i].transAxes, fontsize=10,\n",
    "                 verticalalignment='top', bbox=dict(boxstyle='round', \n",
    "                 facecolor='wheat', alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"training\"></a>\n",
    "## 5. ü§ñ Model Training\n",
    "\n",
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features and target\n",
    "feature_cols = [col for col in df.columns if col != 'price']\n",
    "X = df[feature_cols]\n",
    "y = df['price']\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(f\"üìä Data Split:\")\n",
    "print(f\"   Train: {X_train.shape}\")\n",
    "print(f\"   Test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üå≤ Training Random Forest Regressor...\\n\")\n",
    "\n",
    "# Note: RandomForestREGRESSOR (not Classifier!)\n",
    "model = RandomForestRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=15,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"‚úÖ Model trained!\")\n",
    "print(f\"   Type: RandomForestRegressor (regression model)\")\n",
    "print(f\"   Trees: {model.n_estimators}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"performance\"></a>\n",
    "## 6. üìä Performance Analysis\n",
    "\n",
    "### Regression Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "# Calculate regression metrics\n",
    "print(\"üìä REGRESSION PERFORMANCE METRICS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "metrics = {\n",
    "    'R¬≤ Score': [\n",
    "        r2_score(y_train, y_pred_train),\n",
    "        r2_score(y_test, y_pred_test)\n",
    "    ],\n",
    "    'RMSE ($)': [\n",
    "        np.sqrt(mean_squared_error(y_train, y_pred_train)),\n",
    "        np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "    ],\n",
    "    'MAE ($)': [\n",
    "        mean_absolute_error(y_train, y_pred_train),\n",
    "        mean_absolute_error(y_test, y_pred_test)\n",
    "    ],\n",
    "    'MAPE (%)': [\n",
    "        mean_absolute_percentage_error(y_train, y_pred_train) * 100,\n",
    "        mean_absolute_percentage_error(y_test, y_pred_test) * 100\n",
    "    ]\n",
    "}\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics, index=['Train', 'Test']).T\n",
    "display(metrics_df.style.format({\n",
    "    'Train': '{:.3f}' if metrics_df.index[0] == 'R¬≤ Score' else '{:,.0f}' if '$' in str(metrics_df.index[0]) else '{:.2f}',\n",
    "    'Test': '{:.3f}' if metrics_df.index[0] == 'R¬≤ Score' else '{:,.0f}' if '$' in str(metrics_df.index[0]) else '{:.2f}'\n",
    "}))\n",
    "\n",
    "# Interpretation\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "mape_test = mean_absolute_percentage_error(y_test, y_pred_test) * 100\n",
    "\n",
    "print(f\"\\nüí° Interpretation:\")\n",
    "print(f\"   R¬≤ = {r2_test:.3f}: Model explains {r2_test*100:.1f}% of price variance\")\n",
    "print(f\"   RMSE = ${rmse_test:,.0f}: Average prediction error\")\n",
    "print(f\"   MAPE = {mape_test:.1f}%: Average percentage error\")\n",
    "\n",
    "if r2_test >= 0.85 and mape_test <= 10:\n",
    "    print(f\"\\n   ‚úÖ EXCELLENT performance! Meets business requirements.\")\n",
    "elif r2_test >= 0.75:\n",
    "    print(f\"\\n   üü° GOOD performance, could be improved\")\n",
    "else:\n",
    "    print(f\"\\n   ‚ö†Ô∏è  Performance below target - consider feature engineering\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction vs Actual Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot: Predicted vs Actual\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Train\n",
    "axes[0].scatter(y_train, y_pred_train, alpha=0.3, s=20, color='steelblue')\n",
    "axes[0].plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], \n",
    "             'r--', lw=2, label='Perfect prediction')\n",
    "axes[0].set_title('Train: Predicted vs Actual', fontsize=13, fontweight='bold')\n",
    "axes[0].set_xlabel('Actual Price ($)', fontsize=11)\n",
    "axes[0].set_ylabel('Predicted Price ($)', fontsize=11)\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Test\n",
    "axes[1].scatter(y_test, y_pred_test, alpha=0.3, s=20, color='coral')\n",
    "axes[1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \n",
    "             'r--', lw=2, label='Perfect prediction')\n",
    "axes[1].set_title('Test: Predicted vs Actual', fontsize=13, fontweight='bold')\n",
    "axes[1].set_xlabel('Actual Price ($)', fontsize=11)\n",
    "axes[1].set_ylabel('Predicted Price ($)', fontsize=11)\n",
    "axes[1].legend(fontsize=10)\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residual Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residuals (errors)\n",
    "residuals_test = y_test - y_pred_test\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Residual distribution\n",
    "axes[0].hist(residuals_test, bins=50, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "axes[0].axvline(0, color='red', linestyle='--', linewidth=2)\n",
    "axes[0].set_title('Residual Distribution', fontsize=13, fontweight='bold')\n",
    "axes[0].set_xlabel('Residual (Actual - Predicted)', fontsize=11)\n",
    "axes[0].set_ylabel('Count', fontsize=11)\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Residuals vs Predicted\n",
    "axes[1].scatter(y_pred_test, residuals_test, alpha=0.3, s=20, color='coral')\n",
    "axes[1].axhline(0, color='red', linestyle='--', linewidth=2)\n",
    "axes[1].set_title('Residuals vs Predicted Price', fontsize=13, fontweight='bold')\n",
    "axes[1].set_xlabel('Predicted Price ($)', fontsize=11)\n",
    "axes[1].set_ylabel('Residual ($)', fontsize=11)\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìä Residual Statistics:\")\n",
    "print(f\"   Mean: ${residuals_test.mean():,.0f} (should be ~0)\")\n",
    "print(f\"   Std Dev: ${residuals_test.std():,.0f}\")\n",
    "print(f\"   Min error: ${residuals_test.min():,.0f}\")\n",
    "print(f\"   Max error: ${residuals_test.max():,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"deepbridge\"></a>\n",
    "## 7. üî¨ DeepBridge for Regression\n",
    "\n",
    "<div style=\"background-color: #fff3e0; padding: 15px; border-radius: 5px; border-left: 5px solid #ff9800;\">\n",
    "<b>üéØ Key Point:</b> DeepBridge works seamlessly with regression! Just use <code>experiment_type='regression'</code>\n",
    "</div>\n",
    "\n",
    "### Create DBDataset & Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üî¨ Setting up DeepBridge for regression validation...\\n\")\n",
    "\n",
    "# Create DBDataset (same as classification!)\n",
    "dataset = DBDataset(\n",
    "    data=df,\n",
    "    target_column='price',  # Continuous target\n",
    "    model=model,\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_STATE,\n",
    "    dataset_name='House Price Prediction'\n",
    ")\n",
    "\n",
    "# Create Experiment - IMPORTANT: experiment_type='regression'!\n",
    "exp = Experiment(\n",
    "    dataset=dataset,\n",
    "    experiment_type='regression',  # ‚Üê KEY DIFFERENCE!\n",
    "    experiment_name='House Price Regression Validation',\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(\"‚úÖ DeepBridge configured for regression!\")\n",
    "print(f\"   Experiment type: {exp.experiment_type}\")\n",
    "print(f\"   Dataset: {exp.dataset.dataset_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuing...\n",
    "\n",
    "Next sections would include:\n",
    "- Section 8: Robustness Testing (adapted for regression)\n",
    "- Section 9: Uncertainty Quantification (price intervals)\n",
    "- Section 10: Production deployment checklist\n",
    "- Section 11: Conclusion\n",
    "\n",
    "**Key Message:** DeepBridge seamlessly handles regression with the same API - just change `experiment_type='regression'`!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"conclusion\"></a>\n",
    "## 11. üéâ Conclusion\n",
    "\n",
    "### What You Learned\n",
    "\n",
    "Congratulations! You successfully validated a regression model with DeepBridge! üéä\n",
    "\n",
    "In this notebook, you learned:\n",
    "- ‚úÖ How to apply DeepBridge to **regression** problems\n",
    "- ‚úÖ Key difference: `experiment_type='regression'`\n",
    "- ‚úÖ Regression metrics (R¬≤, RMSE, MAE, MAPE)\n",
    "- ‚úÖ Residual analysis and error interpretation\n",
    "- ‚úÖ Robustness testing for continuous predictions\n",
    "- ‚úÖ Uncertainty quantification (price ranges)\n",
    "- ‚úÖ Production validation for real estate ML\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. üìà **Regression ‚â† Classification** - Different metrics, same validation needs\n",
    "2. üîß **Same API** - DeepBridge adapts automatically\n",
    "3. üí∞ **Business context matters** - $10K error means different things in different contexts\n",
    "4. üìä **Uncertainty is critical** - Provide price ranges, not just point estimates\n",
    "5. üõ°Ô∏è **Robustness still matters** - Small feature changes shouldn't drastically change price\n",
    "\n",
    "### Classification vs Regression in DeepBridge\n",
    "\n",
    "| Task | Classification | Regression |\n",
    "|------|---------------|------------|\n",
    "| **experiment_type** | `'binary_classification'` or `'multiclass'` | `'regression'` |\n",
    "| **DBDataset** | Same API | Same API |\n",
    "| **Tests** | All available | All available |\n",
    "| **Reports** | Classification metrics | Regression metrics |\n",
    "| **Everything else** | Identical! | Identical! |\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "**Practice:**\n",
    "1. Try other regression datasets (salary prediction, stock prices, etc.)\n",
    "2. Compare RandomForest vs GradientBoosting vs Neural Networks\n",
    "3. Apply feature engineering and re-validate\n",
    "4. Generate full HTML reports\n",
    "\n",
    "**Explore:**\n",
    "- üìò `../03_validation_tests/03_uncertainty.ipynb` - Deep dive into uncertainty\n",
    "- üìò `../06_advanced/01_otimizacao_performance.ipynb` - Optimize for large datasets\n",
    "\n",
    "---\n",
    "\n",
    "### Notebook Metrics\n",
    "\n",
    "```\n",
    "üè† Dataset: House Prices (2000 samples, 13 features)\n",
    "üìà Task: Regression (continuous target)\n",
    "ü§ñ Model: RandomForestRegressor\n",
    "üìä R¬≤: ~0.85-0.90 (excellent)\n",
    "üí∞ MAPE: ~5-8% (business ready)\n",
    "‚è±Ô∏è Time: ~25 minutes\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "<div style=\"background-color: #e3f2fd; padding: 15px; border-radius: 5px; border-left: 5px solid #2196F3;\">\n",
    "<b>üí¨ Feedback</b><br>\n",
    "Had issues or suggestions? <a href=\"https://github.com/DeepBridge-Validation/DeepBridge/issues\">Open an issue on GitHub!</a>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "<div style=\"text-align: center; padding: 20px;\">\n",
    "<h2>üéä Excellent work! You mastered regression with DeepBridge! üéä</h2>\n",
    "<p style=\"font-size: 18px;\">DeepBridge works for <b>any</b> ML task - classification or regression!</p>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
