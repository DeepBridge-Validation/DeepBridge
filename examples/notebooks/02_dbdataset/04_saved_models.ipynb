{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ’¾ Loading Saved Models (Production Models)\n",
    "\n",
    "<div style=\"background-color: #e3f2fd; padding: 15px; border-radius: 5px; border-left: 5px solid #2196F3;\">\n",
    "<b>ğŸ““ Notebook Information</b><br>\n",
    "<b>Level:</b> Intermediate<br>\n",
    "<b>Estimated Time:</b> 15 minutes<br>\n",
    "<b>Prerequisites:</b> 03_model_integration.ipynb<br>\n",
    "<b>Dataset:</b> Wine (sklearn)\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "- âœ… Save trained models to disk (.pkl, .joblib)\n",
    "- âœ… Load models using DBDataset with `model_path`\n",
    "- âœ… Validate production models with DeepBridge\n",
    "- âœ… Understand supported formats (.pkl, .joblib, .h5, .onnx)\n",
    "- âœ… Apply to production validation scenarios\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“š Table of Contents\n",
    "\n",
    "1. [Introduction](#intro)\n",
    "2. [Setup](#setup)\n",
    "3. [Train and Save Model](#train)\n",
    "4. [Load with model_path](#load)\n",
    "5. [Supported Formats](#formats)\n",
    "6. [Production Use Case](#production)\n",
    "7. [Best Practices](#practices)\n",
    "8. [Conclusion](#conclusion)\n",
    "9. [Next Steps](#next)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"intro\"></a>\n",
    "## 1. ğŸ“– Introduction\n",
    "\n",
    "### The Scenario\n",
    "\n",
    "In production environments, you often have:\n",
    "- ğŸ¤– **Trained models saved to disk** (.pkl, .joblib, etc.)\n",
    "- ğŸ“¦ **New data to validate** against these models\n",
    "- ğŸ” **Need to re-validate** periodically\n",
    "\n",
    "### Why Load Saved Models?\n",
    "\n",
    "1. **Production Validation**: Validate existing production models\n",
    "2. **Re-training**: Compare new model vs current production model\n",
    "3. **A/B Testing**: Test multiple model versions\n",
    "4. **Audit**: Reproduce validation results from historical models\n",
    "5. **CI/CD**: Automate model validation in pipelines\n",
    "\n",
    "### DeepBridge Makes it Easy!\n",
    "\n",
    "```python\n",
    "# Instead of:\n",
    "# 1. Load model manually\n",
    "# 2. Make predictions\n",
    "# 3. Create DBDataset with predictions\n",
    "\n",
    "# Just do:\n",
    "dataset = DBDataset(\n",
    "    data=df,\n",
    "    target_column='target',\n",
    "    model_path='my_model.pkl'  # â† Automatic!\n",
    ")\n",
    "```\n",
    "\n",
    "**Let's learn how!** ğŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"setup\"></a>\n",
    "## 2. ğŸ› ï¸ Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import joblib\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "# sklearn\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# DeepBridge\n",
    "from deepbridge import DBDataset, Experiment\n",
    "\n",
    "# Visualization settings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"Set2\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Create directory for saved models\n",
    "models_dir = Path('/tmp/deepbridge_models')\n",
    "models_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"âœ… Setup complete!\")\n",
    "print(f\"ğŸ“ Models directory: {models_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"train\"></a>\n",
    "## 3. ğŸ¤– Train and Save Model\n",
    "\n",
    "First, let's train a model and save it - simulating what you would do in production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Wine dataset\n",
    "wine = load_wine()\n",
    "df = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
    "df['target'] = wine.target\n",
    "\n",
    "print(\"ğŸ· Wine Classification Dataset\")\n",
    "print(f\"   Shape: {df.shape}\")\n",
    "print(f\"   Features: {len(wine.feature_names)}\")\n",
    "print(f\"   Classes: {len(np.unique(wine.target))}\")\n",
    "print(f\"\\n   First rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple split for training\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Train RandomForest\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "train_acc = model.score(X_train, y_train)\n",
    "test_acc = model.score(X_test, y_test)\n",
    "\n",
    "print(\"âœ… Model trained!\")\n",
    "print(f\"\\nğŸ“Š Performance:\")\n",
    "print(f\"   Train Accuracy: {train_acc:.3f}\")\n",
    "print(f\"   Test Accuracy: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model - Multiple Formats\n",
    "\n",
    "Let's save the model in different formats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Save with joblib (recommended for sklearn)\n",
    "model_path_joblib = models_dir / 'wine_model.joblib'\n",
    "joblib.dump(model, model_path_joblib)\n",
    "print(f\"âœ… Saved with joblib: {model_path_joblib}\")\n",
    "print(f\"   Size: {model_path_joblib.stat().st_size / 1024:.1f} KB\")\n",
    "\n",
    "# 2. Save with pickle\n",
    "model_path_pkl = models_dir / 'wine_model.pkl'\n",
    "with open(model_path_pkl, 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "print(f\"\\nâœ… Saved with pickle: {model_path_pkl}\")\n",
    "print(f\"   Size: {model_path_pkl.stat().st_size / 1024:.1f} KB\")\n",
    "\n",
    "print(\"\\nğŸ’¡ Both formats work! joblib is usually preferred for sklearn models.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #d4edda; padding: 10px; border-radius: 5px; border-left: 5px solid #28a745;\">\n",
    "<b>âœ… Best Practice:</b> Use <code>joblib</code> for sklearn models - it's optimized for numpy arrays and is more efficient!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"load\"></a>\n",
    "## 4. ğŸ”„ Load Model with DBDataset\n",
    "\n",
    "Now comes the magic! Let's load the saved model using DBDataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1: Using model_path (Recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DBDataset with model_path\n",
    "dataset = DBDataset(\n",
    "    data=df,\n",
    "    target_column='target',\n",
    "    model_path=str(model_path_joblib),  # â† Just provide the path!\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    dataset_name='Wine Classification'\n",
    ")\n",
    "\n",
    "print(\"âœ… DBDataset created with saved model!\")\n",
    "print(f\"\\nğŸ“Š Details:\")\n",
    "print(f\"   Model loaded from: {model_path_joblib.name}\")\n",
    "print(f\"   Train samples: {len(dataset.train_data)}\")\n",
    "print(f\"   Test samples: {len(dataset.test_data)}\")\n",
    "print(f\"   Features: {len(dataset.features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What happened?\n",
    "\n",
    "DBDataset automatically:\n",
    "1. âœ… **Loaded the model** from disk\n",
    "2. âœ… **Made predictions** on train and test data\n",
    "3. âœ… **Stored predictions** in the dataset\n",
    "4. âœ… **Validated** everything is consistent\n",
    "\n",
    "**All with one parameter!** ğŸ‰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access predictions\n",
    "if hasattr(dataset, 'test_predictions'):\n",
    "    y_pred = dataset.test_predictions\n",
    "    y_true = dataset.get_target_data('test')\n",
    "    \n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    print(\"ğŸ“Š Predictions from loaded model:\")\n",
    "    print(f\"   Test Accuracy: {accuracy:.3f}\")\n",
    "    print(f\"\\n   Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=wine.target_names))\n",
    "else:\n",
    "    print(\"ğŸ’¡ Predictions will be computed when needed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted probabilities\n",
    "if hasattr(dataset, 'test_probabilities'):\n",
    "    test_proba = dataset.test_probabilities\n",
    "    \n",
    "    print(\"ğŸ“Š Predicted Probabilities (first 5 samples):\")\n",
    "    print(f\"   Shape: {test_proba.shape}\")\n",
    "    print(f\"\\n   Probabilities:\")\n",
    "    \n",
    "    proba_df = pd.DataFrame(\n",
    "        test_proba[:5],\n",
    "        columns=[f'Class {i}' for i in range(test_proba.shape[1])]\n",
    "    )\n",
    "    display(proba_df.style.format(\"{:.3f}\").background_gradient(cmap='Blues'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"formats\"></a>\n",
    "## 5. ğŸ“¦ Supported Formats\n",
    "\n",
    "DeepBridge supports multiple model formats:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supported Formats\n",
    "\n",
    "| Format | Extension | Best For | Notes |\n",
    "|--------|-----------|----------|-------|\n",
    "| **Joblib** | `.joblib` | sklearn models | âœ… Recommended for sklearn |\n",
    "| **Pickle** | `.pkl` | Any Python object | âš ï¸ Security concerns |\n",
    "| **Keras/TF** | `.h5`, `.keras` | Deep Learning | Neural networks |\n",
    "| **ONNX** | `.onnx` | Cross-platform | Universal format |\n",
    "| **PyTorch** | `.pt`, `.pth` | Deep Learning | Requires PyTorch |\n",
    "\n",
    "### Example with .pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load with .pkl file\n",
    "dataset_pkl = DBDataset(\n",
    "    data=df,\n",
    "    target_column='target',\n",
    "    model_path=str(model_path_pkl),  # â† .pkl works too!\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"âœ… Model loaded from .pkl file!\")\n",
    "print(f\"   Format: pickle\")\n",
    "print(f\"   Status: Working perfectly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #fff3cd; padding: 10px; border-radius: 5px; border-left: 5px solid #ffc107;\">\n",
    "<b>âš ï¸ Security Warning:</b> Only load models from trusted sources! Pickle files can execute arbitrary code.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"production\"></a>\n",
    "## 6. ğŸ­ Production Use Case: Validation Pipeline\n",
    "\n",
    "### Scenario\n",
    "You have a model in production and want to:\n",
    "1. Validate it with new data\n",
    "2. Run all DeepBridge tests\n",
    "3. Generate validation report\n",
    "\n",
    "**Let's do it!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load production model\n",
    "print(\"ğŸ“¦ Step 1: Loading production model...\")\n",
    "dataset = DBDataset(\n",
    "    data=df,\n",
    "    target_column='target',\n",
    "    model_path=str(model_path_joblib),\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    dataset_name='Wine Classifier - Production Validation'\n",
    ")\n",
    "print(\"âœ… Model loaded!\\n\")\n",
    "\n",
    "# Step 2: Create Experiment\n",
    "print(\"ğŸ”¬ Step 2: Creating experiment...\")\n",
    "exp = Experiment(\n",
    "    dataset=dataset,\n",
    "    experiment_type='multiclass_classification',\n",
    "    experiment_name='Production Model Validation',\n",
    "    random_state=42\n",
    ")\n",
    "print(\"âœ… Experiment created!\\n\")\n",
    "\n",
    "# Step 3: Run quick tests\n",
    "print(\"ğŸ§ª Step 3: Running validation tests (quick)...\")\n",
    "print(\"   This may take a moment...\\n\")\n",
    "\n",
    "results = exp.run_tests(config='quick')\n",
    "\n",
    "print(\"\\nâœ… Validation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of validation\n",
    "print(\"ğŸ“Š PRODUCTION MODEL VALIDATION SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if hasattr(results, 'summary'):\n",
    "    summary = results.summary()\n",
    "    for test_name, test_results in summary.items():\n",
    "        print(f\"\\nğŸ“‹ {test_name.upper()}:\")\n",
    "        print(f\"   Status: {test_results.get('status', 'N/A')}\")\n",
    "        print(f\"   Score: {test_results.get('score', 'N/A')}\")\n",
    "else:\n",
    "    print(\"\\nâœ… All tests completed successfully!\")\n",
    "    print(\"   Model passed basic validation\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"\\nğŸ’¡ Generate full HTML report with: exp.save_html('report.html')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #d4edda; padding: 15px; border-radius: 5px; border-left: 5px solid #28a745;\">\n",
    "<b>ğŸ¯ Production Pipeline:</b><br>\n",
    "1. Load model with <code>model_path</code><br>\n",
    "2. Create Experiment<br>\n",
    "3. Run tests (robustness, uncertainty, etc.)<br>\n",
    "4. Generate HTML report<br>\n",
    "5. Make decision: approve/reject for production<br>\n",
    "<br>\n",
    "<b>All automated with DeepBridge!</b> ğŸš€\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"practices\"></a>\n",
    "## 7. ğŸ“ Best Practices\n",
    "\n",
    "### 1. Model Naming Convention\n",
    "\n",
    "```python\n",
    "# Good naming:\n",
    "model_name = f\"wine_classifier_v1.2_20250104.joblib\"\n",
    "#             â””â”€nameâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€versionâ”€â”˜ â””â”€dateâ”€â”˜\n",
    "```\n",
    "\n",
    "### 2. Save Metadata with Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model + metadata\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "metadata = {\n",
    "    'model_type': 'RandomForestClassifier',\n",
    "    'version': '1.0',\n",
    "    'train_date': datetime.now().isoformat(),\n",
    "    'train_accuracy': float(train_acc),\n",
    "    'test_accuracy': float(test_acc),\n",
    "    'n_samples': len(df),\n",
    "    'n_features': len(dataset.features),\n",
    "    'hyperparameters': model.get_params()\n",
    "}\n",
    "\n",
    "# Save metadata\n",
    "metadata_path = models_dir / 'wine_model_metadata.json'\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(\"âœ… Metadata saved!\")\n",
    "print(f\"\\nğŸ“„ Metadata:\")\n",
    "print(json.dumps(metadata, indent=2)[:300] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Version Control for Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory structure example\n",
    "print(\"ğŸ“ Recommended Directory Structure:\")\n",
    "print(\"\"\"\n",
    "models/\n",
    "â”œâ”€â”€ production/\n",
    "â”‚   â”œâ”€â”€ wine_classifier_v1.0.joblib\n",
    "â”‚   â””â”€â”€ wine_classifier_v1.0_metadata.json\n",
    "â”œâ”€â”€ staging/\n",
    "â”‚   â”œâ”€â”€ wine_classifier_v1.1.joblib\n",
    "â”‚   â””â”€â”€ wine_classifier_v1.1_metadata.json\n",
    "â””â”€â”€ archive/\n",
    "    â””â”€â”€ wine_classifier_v0.9.joblib\n",
    "\"\"\")\n",
    "\n",
    "print(\"ğŸ’¡ Benefits:\")\n",
    "print(\"   - Easy rollback\")\n",
    "print(\"   - A/B testing\")\n",
    "print(\"   - Audit trail\")\n",
    "print(\"   - Version comparison\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Automated Validation Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example validation function\n",
    "def validate_production_model(model_path, data, target_column, output_dir):\n",
    "    \"\"\"\n",
    "    Complete production model validation.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model_path : str\n",
    "        Path to saved model\n",
    "    data : pd.DataFrame\n",
    "        Validation data\n",
    "    target_column : str\n",
    "        Target column name\n",
    "    output_dir : str\n",
    "        Directory for reports\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    bool : True if validation passes\n",
    "    \"\"\"\n",
    "    print(f\"ğŸ”¬ Validating model: {Path(model_path).name}\")\n",
    "    \n",
    "    # Create dataset\n",
    "    dataset = DBDataset(\n",
    "        data=data,\n",
    "        target_column=target_column,\n",
    "        model_path=model_path,\n",
    "        test_size=0.2,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Create experiment\n",
    "    exp = Experiment(\n",
    "        dataset=dataset,\n",
    "        experiment_type='multiclass_classification'\n",
    "    )\n",
    "    \n",
    "    # Run tests\n",
    "    results = exp.run_tests(config='full')\n",
    "    \n",
    "    # Save report\n",
    "    report_path = Path(output_dir) / f'validation_report_{datetime.now():%Y%m%d_%H%M%S}.html'\n",
    "    if hasattr(results, 'save_html'):\n",
    "        results.save_html(str(report_path))\n",
    "        print(f\"âœ… Report saved: {report_path}\")\n",
    "    \n",
    "    # Validation criteria\n",
    "    # (customize based on your requirements)\n",
    "    passes = True  # Implement your criteria\n",
    "    \n",
    "    return passes\n",
    "\n",
    "print(\"âœ… Validation function defined!\")\n",
    "print(\"\\nğŸ’¡ Use in CI/CD pipeline:\")\n",
    "print(\"   python validate.py --model model.joblib --data data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"conclusion\"></a>\n",
    "## 8. ğŸ‰ Conclusion\n",
    "\n",
    "### What you learned\n",
    "\n",
    "Congratulations! You mastered loading saved models with DeepBridge! ğŸŠ\n",
    "\n",
    "In this notebook, you learned:\n",
    "- âœ… How to save models with joblib and pickle\n",
    "- âœ… How to load models using `model_path` parameter\n",
    "- âœ… Supported formats (.joblib, .pkl, .h5, .onnx)\n",
    "- âœ… Production validation workflow\n",
    "- âœ… Best practices for model management\n",
    "- âœ… How to create automated validation pipelines\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. ğŸ’¾ **model_path is powerful** - One parameter loads and integrates everything\n",
    "2. ğŸ”§ **Multiple formats supported** - Use what works for your stack\n",
    "3. ğŸ­ **Production ready** - Easy to integrate in pipelines\n",
    "4. ğŸ“ **Always save metadata** - Version, date, metrics, hyperparameters\n",
    "5. ğŸ”’ **Security matters** - Only load models from trusted sources\n",
    "\n",
    "---\n",
    "\n",
    "### Notebook Metrics\n",
    "\n",
    "```\n",
    "ğŸ· Dataset: Wine (178 samples, 13 features, 3 classes)\n",
    "ğŸ¤– Model: RandomForestClassifier\n",
    "ğŸ’¾ Formats: .joblib and .pkl demonstrated\n",
    "ğŸ”¬ Validation: Full pipeline executed\n",
    "â±ï¸ Time: ~15 minutes\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"next\"></a>\n",
    "## 9. ğŸ¯ Next Steps\n",
    "\n",
    "### Recommended\n",
    "\n",
    "ğŸ“˜ **Next Notebook:** `05_probabilidades_precomputadas.ipynb`\n",
    "- Optimize with pre-computed probabilities\n",
    "- Save time with large models\n",
    "\n",
    "### Alternative\n",
    "\n",
    "ğŸ“˜ **Jump to:** `../03_validation_tests/06_comparacao_modelos.ipynb`\n",
    "- Compare multiple saved models\n",
    "- Choose best model for production\n",
    "\n",
    "### Challenge\n",
    "\n",
    "ğŸ’ª **Production Pipeline Challenge!**\n",
    "1. Train 3 different models (RandomForest, GradientBoosting, LogisticRegression)\n",
    "2. Save all with proper naming and metadata\n",
    "3. Load and validate each one\n",
    "4. Compare results\n",
    "5. Select best for \"production\"\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“š Additional Resources\n",
    "\n",
    "- ğŸ“– [DBDataset Documentation](../../../planejamento_doc/1-CORE/01-DBDATASET.md)\n",
    "- ğŸ’» [Model Serialization Guide](https://scikit-learn.org/stable/model_persistence.html)\n",
    "- ğŸ”’ [Security Best Practices](https://docs.python.org/3/library/pickle.html#comparison-with-json)\n",
    "\n",
    "---\n",
    "\n",
    "<div style=\"background-color: #e3f2fd; padding: 15px; border-radius: 5px; border-left: 5px solid #2196F3;\">\n",
    "<b>ğŸ’¬ Feedback</b><br>\n",
    "Had issues or suggestions? <a href=\"https://github.com/DeepBridge-Validation/DeepBridge/issues\">Open an issue on GitHub!</a>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "<div style=\"text-align: center; padding: 20px;\">\n",
    "<h2>ğŸŠ Great job completing this notebook! ğŸŠ</h2>\n",
    "<p style=\"font-size: 18px;\">Continue mastering DBDataset with: <code>05_probabilidades_precomputadas.ipynb</code></p>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
