{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# ‚ö° Advanced Performance Optimization\n",
    "\n",
    "<div style=\"background-color: #e3f2fd; padding: 15px; border-radius: 5px; border-left: 5px solid #2196F3;\">\n",
    "<b>üìì Notebook Information</b><br>\n",
    "<b>Level:</b> Advanced<br>\n",
    "<b>Estimated Time:</b> 25 minutes<br>\n",
    "<b>Prerequisites:</b> All basic notebooks<br>\n",
    "<b>Dataset:</b> Large synthetic dataset\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "- ‚úÖ Optimize DeepBridge for large-scale datasets\n",
    "- ‚úÖ Use parallel processing for faster validation\n",
    "- ‚úÖ Leverage pre-computed probabilities\n",
    "- ‚úÖ Optimize memory usage\n",
    "- ‚úÖ Profile and benchmark your experiments\n",
    "- ‚úÖ Apply production-grade optimization techniques\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Table of Contents\n",
    "\n",
    "1. [Introduction](#intro)\n",
    "2. [Setup](#setup)\n",
    "3. [Baseline Performance](#baseline)\n",
    "4. [Optimization 1: Pre-computed Probabilities](#precomputed)\n",
    "5. [Optimization 2: Parallel Processing](#parallel)\n",
    "6. [Optimization 3: Memory Management](#memory)\n",
    "7. [Optimization 4: Config Tuning](#config)\n",
    "8. [Performance Comparison](#comparison)\n",
    "9. [Production Best Practices](#production)\n",
    "10. [Conclusion](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "<a id=\"intro\"></a>\n",
    "## 1. üìñ Introduction\n",
    "\n",
    "### Why Optimize Performance?\n",
    "\n",
    "**The Reality:**\n",
    "- üêå **Validation can be slow** - Especially with complex models\n",
    "- üí∞ **Time = Money** - Faster iteration = more experiments\n",
    "- üìä **Large datasets** - Real-world data can be massive\n",
    "- ‚ö° **Production constraints** - Need real-time or near-real-time validation\n",
    "\n",
    "**Real-world example:**\n",
    "```python\n",
    "# Before optimization\n",
    "exp.run_test('robustness')  # 15 minutes ‚ùå\n",
    "\n",
    "# After optimization\n",
    "exp.run_test('robustness')  # 45 seconds ‚úÖ\n",
    "```\n",
    "\n",
    "### Performance Bottlenecks\n",
    "\n",
    "1. **Model Inference**\n",
    "   - Problem: Model.predict() called 100+ times\n",
    "   - Solution: Pre-compute probabilities\n",
    "\n",
    "2. **Sequential Processing**\n",
    "   - Problem: Tests run one at a time\n",
    "   - Solution: Parallel processing\n",
    "\n",
    "3. **Memory Usage**\n",
    "   - Problem: Loading full dataset multiple times\n",
    "   - Solution: Smart caching and chunking\n",
    "\n",
    "4. **Unnecessary Computations**\n",
    "   - Problem: Running expensive tests you don't need\n",
    "   - Solution: Use 'quick' config, selective testing\n",
    "\n",
    "### Optimization Strategy\n",
    "\n",
    "| Technique | Speedup | Complexity | Memory Impact |\n",
    "|-----------|---------|------------|---------------|\n",
    "| **Pre-computed Probs** | 10-100x | üü¢ Low | üü° +10-20% |\n",
    "| **Parallel Processing** | 2-4x | üü° Medium | üî¥ +50-100% |\n",
    "| **Config Tuning** | 2-10x | üü¢ Low | üü¢ None |\n",
    "| **Memory Management** | 1-2x | üî¥ High | üü¢ -30-50% |\n",
    "\n",
    "**Let's optimize!** üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup",
   "metadata": {},
   "source": [
    "<a id=\"setup\"></a>\n",
    "## 2. üõ†Ô∏è Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from time import time\n",
    "import psutil\n",
    "import os\n",
    "\n",
    "# sklearn\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# DeepBridge\n",
    "from deepbridge import DBDataset, Experiment\n",
    "\n",
    "# Settings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('Set2')\n",
    "%matplotlib inline\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "print(\"‚úÖ Setup complete!\")\n",
    "print(\"‚ö° Topic: Advanced Performance Optimization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "create_data",
   "metadata": {},
   "source": [
    "### Create Large-Scale Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìä Creating large synthetic dataset...\\n\")\n",
    "\n",
    "# Create a large dataset to demonstrate performance\n",
    "n_samples = 50000  # Large enough to see performance differences\n",
    "n_features = 50\n",
    "\n",
    "X, y = make_classification(\n",
    "    n_samples=n_samples,\n",
    "    n_features=n_features,\n",
    "    n_informative=30,\n",
    "    n_redundant=10,\n",
    "    n_classes=2,\n",
    "    class_sep=0.7,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Create DataFrame\n",
    "feature_names = [f'feature_{i}' for i in range(n_features)]\n",
    "df = pd.DataFrame(X, columns=feature_names)\n",
    "df['target'] = y\n",
    "\n",
    "print(f\"‚úÖ Dataset created: {df.shape}\")\n",
    "print(f\"   Samples: {n_samples:,}\")\n",
    "print(f\"   Features: {n_features}\")\n",
    "print(f\"   Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
    "print(f\"   Class balance: {y.mean():.1%} positive class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baseline",
   "metadata": {},
   "source": [
    "<a id=\"baseline\"></a>\n",
    "## 3. üìä Baseline Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baseline_model",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üèÅ Establishing Baseline Performance\\n\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Split data\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "# Train a moderately complex model (GradientBoosting is slower)\n",
    "print(\"Training GradientBoosting model (this will take a moment)...\\n\")\n",
    "start = time()\n",
    "model = GradientBoostingClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "train_time = time() - start\n",
    "\n",
    "# Test prediction time\n",
    "start = time()\n",
    "y_pred = model.predict(X_test)\n",
    "pred_time = time() - start\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"‚úÖ Model trained\")\n",
    "print(f\"   Training time: {train_time:.2f}s\")\n",
    "print(f\"   Prediction time (10K samples): {pred_time:.3f}s\")\n",
    "print(f\"   Predictions per second: {len(X_test)/pred_time:,.0f}\")\n",
    "print(f\"   Accuracy: {acc:.3f}\")\n",
    "\n",
    "# Estimate test time\n",
    "n_predictions_in_test = 100  # Approximate number of model calls in robustness test\n",
    "estimated_test_time = pred_time * n_predictions_in_test\n",
    "\n",
    "print(f\"\\n‚è±Ô∏è  Estimated robustness test time: {estimated_test_time:.1f}s ({estimated_test_time/60:.1f} min)\")\n",
    "print(f\"   (Based on ~{n_predictions_in_test} model inference calls)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baseline_test",
   "metadata": {},
   "source": [
    "### Run Baseline Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run_baseline",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üî¨ Running Baseline Robustness Test (SLOW)\\n\")\n",
    "print(\"‚ö†Ô∏è  This will call model.predict() many times...\\n\")\n",
    "\n",
    "# Create DBDataset (traditional way)\n",
    "dataset_baseline = DBDataset(\n",
    "    data=df,\n",
    "    target_column='target',\n",
    "    model=model,\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Create Experiment\n",
    "exp_baseline = Experiment(\n",
    "    dataset=dataset_baseline,\n",
    "    experiment_type='binary_classification',\n",
    "    experiment_name='Baseline Performance Test',\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Run test with timing\n",
    "start = time()\n",
    "result_baseline = exp_baseline.run_test('robustness', config='quick')\n",
    "baseline_test_time = time() - start\n",
    "\n",
    "print(f\"\\n‚úÖ Baseline test complete\")\n",
    "print(f\"   Time: {baseline_test_time:.2f}s ({baseline_test_time/60:.2f} min)\")\n",
    "print(f\"\\nüí° This is our baseline to beat!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precomputed",
   "metadata": {},
   "source": [
    "<a id=\"precomputed\"></a>\n",
    "## 4. ‚ö° Optimization 1: Pre-computed Probabilities\n",
    "\n",
    "### The Problem: Redundant Model Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precompute_probs",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"‚ö° Optimization 1: Pre-computed Probabilities\\n\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nThe Problem:\")\n",
    "print(\"   ‚Ä¢ Robustness test calls model.predict() ~100+ times\")\n",
    "print(\"   ‚Ä¢ Each call takes time (especially for GB/Neural Nets)\")\n",
    "print(\"   ‚Ä¢ Predictions on same data are always the same!\")\n",
    "print(\"\\nThe Solution:\")\n",
    "print(\"   ‚Ä¢ Compute probabilities ONCE upfront\")\n",
    "print(\"   ‚Ä¢ Store in DataFrame columns\")\n",
    "print(\"   ‚Ä¢ Use prob_cols parameter in DBDataset\")\n",
    "print(\"   ‚Ä¢ 10-100x speedup! ‚ö°\\n\")\n",
    "\n",
    "# Pre-compute probabilities\n",
    "print(\"Computing probabilities once...\")\n",
    "start = time()\n",
    "probs = model.predict_proba(X)\n",
    "compute_time = time() - start\n",
    "\n",
    "# Add to DataFrame\n",
    "df_optimized = df.copy()\n",
    "df_optimized['prob_0'] = probs[:, 0]\n",
    "df_optimized['prob_1'] = probs[:, 1]\n",
    "\n",
    "print(f\"‚úÖ Probabilities computed in {compute_time:.3f}s\")\n",
    "print(f\"\\nüìä DataFrame now has probability columns:\")\n",
    "print(f\"   {df_optimized.columns.tolist()[-3:]}\")\n",
    "print(f\"\\nüí° These probabilities will be reused for all tests!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "use_precomputed",
   "metadata": {},
   "source": [
    "### Use Pre-computed Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run_optimized",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üî¨ Running Optimized Robustness Test (FAST)\\n\")\n",
    "print(\"‚ö° Using pre-computed probabilities...\\n\")\n",
    "\n",
    "# Create DBDataset with prob_cols\n",
    "dataset_optimized = DBDataset(\n",
    "    data=df_optimized,\n",
    "    target_column='target',\n",
    "    prob_cols=['prob_0', 'prob_1'],  # Magic parameter! ‚ú®\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Create Experiment\n",
    "exp_optimized = Experiment(\n",
    "    dataset=dataset_optimized,\n",
    "    experiment_type='binary_classification',\n",
    "    experiment_name='Optimized Performance Test',\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Run test with timing\n",
    "start = time()\n",
    "result_optimized = exp_optimized.run_test('robustness', config='quick')\n",
    "optimized_test_time = time() - start\n",
    "\n",
    "print(f\"\\n‚úÖ Optimized test complete\")\n",
    "print(f\"   Time: {optimized_test_time:.2f}s\")\n",
    "\n",
    "# Calculate speedup\n",
    "speedup = baseline_test_time / optimized_test_time\n",
    "\n",
    "print(f\"\\nüöÄ SPEEDUP: {speedup:.1f}x faster!\")\n",
    "print(f\"   Baseline: {baseline_test_time:.2f}s\")\n",
    "print(f\"   Optimized: {optimized_test_time:.2f}s\")\n",
    "print(f\"   Saved: {baseline_test_time - optimized_test_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parallel",
   "metadata": {},
   "source": [
    "<a id=\"parallel\"></a>\n",
    "## 5. üîÄ Optimization 2: Parallel Processing\n",
    "\n",
    "### Use Multiple CPU Cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parallel_processing",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîÄ Optimization 2: Parallel Processing\\n\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Check available cores\n",
    "n_cores = psutil.cpu_count(logical=False)\n",
    "n_threads = psutil.cpu_count(logical=True)\n",
    "\n",
    "print(f\"\\nüíª System Information:\")\n",
    "print(f\"   Physical cores: {n_cores}\")\n",
    "print(f\"   Logical cores (threads): {n_threads}\")\n",
    "print(f\"\\nüí° Strategy:\")\n",
    "print(f\"   ‚Ä¢ Train models with n_jobs=-1 (use all cores)\")\n",
    "print(f\"   ‚Ä¢ Run multiple tests in parallel\")\n",
    "print(f\"   ‚Ä¢ Expected speedup: ~{min(n_cores, 4)}x\\n\")\n",
    "\n",
    "# Train model with parallel processing\n",
    "print(\"Training RandomForest with parallel processing...\")\n",
    "start = time()\n",
    "model_parallel = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    n_jobs=-1,  # Use all cores!\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "model_parallel.fit(X_train, y_train)\n",
    "parallel_train_time = time() - start\n",
    "\n",
    "# Compare to single-core training\n",
    "print(\"\\nTraining same model with single core...\")\n",
    "start = time()\n",
    "model_single = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    n_jobs=1,  # Single core\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "model_single.fit(X_train, y_train)\n",
    "single_train_time = time() - start\n",
    "\n",
    "parallel_speedup = single_train_time / parallel_train_time\n",
    "\n",
    "print(f\"\\nüìä Training Time Comparison:\")\n",
    "print(f\"   Single core: {single_train_time:.2f}s\")\n",
    "print(f\"   Multi-core: {parallel_train_time:.2f}s\")\n",
    "print(f\"   üöÄ Speedup: {parallel_speedup:.1f}x\")\n",
    "print(f\"\\nüí° Parallel processing works best for ensemble models (RF, XGBoost, etc.)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "memory",
   "metadata": {},
   "source": [
    "<a id=\"memory\"></a>\n",
    "## 6. üíæ Optimization 3: Memory Management\n",
    "\n",
    "### Monitor and Reduce Memory Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "memory_management",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üíæ Optimization 3: Memory Management\\n\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Check current memory usage\n",
    "process = psutil.Process(os.getpid())\n",
    "memory_mb = process.memory_info().rss / 1024**2\n",
    "\n",
    "print(f\"\\nüìä Current Memory Usage: {memory_mb:.1f} MB\\n\")\n",
    "\n",
    "# Analyze DataFrame memory\n",
    "print(\"DataFrame Memory Breakdown:\")\n",
    "memory_usage = df_optimized.memory_usage(deep=True)\n",
    "for col, mem in memory_usage.items():\n",
    "    if mem / 1024**2 > 1:  # Only show columns > 1MB\n",
    "        print(f\"   {col:20s}: {mem/1024**2:6.2f} MB\")\n",
    "\n",
    "total_mem = memory_usage.sum() / 1024**2\n",
    "print(f\"   {'Total':20s}: {total_mem:6.2f} MB\")\n",
    "\n",
    "# Optimization tips\n",
    "print(\"\\nüí° Memory Optimization Tips:\\n\")\n",
    "print(\"1. **Use appropriate dtypes**\")\n",
    "print(\"   ‚Ä¢ float64 ‚Üí float32 (50% reduction)\")\n",
    "print(\"   ‚Ä¢ int64 ‚Üí int32 or int16 (50-75% reduction)\")\n",
    "print(\"\\n2. **Drop unnecessary columns**\")\n",
    "print(\"   ‚Ä¢ Remove IDs, metadata before creating DBDataset\")\n",
    "print(\"\\n3. **Use chunking for huge datasets**\")\n",
    "print(\"   ‚Ä¢ Process data in batches\")\n",
    "print(\"\\n4. **Clear unused variables**\")\n",
    "print(\"   ‚Ä¢ del unused_df\")\n",
    "print(\"   ‚Ä¢ import gc; gc.collect()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "memory_optimization",
   "metadata": {},
   "source": [
    "### Apply Memory Optimizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optimize_memory",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîß Applying Memory Optimizations...\\n\")\n",
    "\n",
    "# Create optimized copy\n",
    "df_memory_optimized = df_optimized.copy()\n",
    "\n",
    "# Convert float64 ‚Üí float32\n",
    "float_cols = df_memory_optimized.select_dtypes(include=['float64']).columns\n",
    "df_memory_optimized[float_cols] = df_memory_optimized[float_cols].astype('float32')\n",
    "\n",
    "# Convert int64 ‚Üí int32 (for target)\n",
    "int_cols = df_memory_optimized.select_dtypes(include=['int64']).columns\n",
    "df_memory_optimized[int_cols] = df_memory_optimized[int_cols].astype('int32')\n",
    "\n",
    "# Compare memory usage\n",
    "original_memory = df_optimized.memory_usage(deep=True).sum() / 1024**2\n",
    "optimized_memory = df_memory_optimized.memory_usage(deep=True).sum() / 1024**2\n",
    "reduction = (1 - optimized_memory / original_memory) * 100\n",
    "\n",
    "print(\"üìä Memory Comparison:\")\n",
    "print(f\"   Original: {original_memory:.2f} MB\")\n",
    "print(f\"   Optimized: {optimized_memory:.2f} MB\")\n",
    "print(f\"   üöÄ Reduction: {reduction:.1f}%\")\n",
    "print(f\"\\n‚úÖ Memory footprint reduced by using float32 instead of float64!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config",
   "metadata": {},
   "source": [
    "<a id=\"config\"></a>\n",
    "## 7. ‚öôÔ∏è Optimization 4: Config Tuning\n",
    "\n",
    "### Choose the Right Test Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config_tuning",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"‚öôÔ∏è  Optimization 4: Config Tuning\\n\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nüìã Available Test Configurations:\\n\")\n",
    "\n",
    "configs = pd.DataFrame({\n",
    "    'Config': ['quick', 'medium', 'full'],\n",
    "    'Purpose': [\n",
    "        'Fast iteration during development',\n",
    "        'Balanced testing for CI/CD',\n",
    "        'Comprehensive validation for production'\n",
    "    ],\n",
    "    'Tests Run': [\n",
    "        'Minimal subset',\n",
    "        'Most important tests',\n",
    "        'All available tests'\n",
    "    ],\n",
    "    'Relative Time': ['1x (baseline)', '3-5x', '10-20x'],\n",
    "    'When to Use': [\n",
    "        'Every code change',\n",
    "        'Before deployment',\n",
    "        'Final validation'\n",
    "    ]\n",
    "})\n",
    "\n",
    "display(configs.style.set_properties(**{\n",
    "    'text-align': 'left',\n",
    "    'white-space': 'pre-wrap'\n",
    "}).apply(lambda x: ['background-color: #c8e6c9' if v == 'quick' \n",
    "                     else 'background-color: #fff9c4' if v == 'medium'\n",
    "                     else 'background-color: #ffcdd2' if v == 'full'\n",
    "                     else '' for v in x], subset=['Config']))\n",
    "\n",
    "print(\"\\nüí° Recommendation:\")\n",
    "print(\"   ‚Ä¢ Development: Use 'quick'\")\n",
    "print(\"   ‚Ä¢ CI/CD: Use 'medium'\")\n",
    "print(\"   ‚Ä¢ Production validation: Use 'full'\")\n",
    "print(\"\\nüéØ Don't run 'full' config unless you really need it!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparison",
   "metadata": {},
   "source": [
    "<a id=\"comparison\"></a>\n",
    "## 8. üìä Performance Comparison\n",
    "\n",
    "### Side-by-Side Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final_comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìä FINAL PERFORMANCE COMPARISON\\n\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Compile results\n",
    "results = pd.DataFrame({\n",
    "    'Optimization': [\n",
    "        'Baseline (no optimization)',\n",
    "        'Pre-computed Probabilities',\n",
    "        'Parallel Processing',\n",
    "        'Memory Optimization',\n",
    "        'Quick Config'\n",
    "    ],\n",
    "    'Time (s)': [\n",
    "        baseline_test_time,\n",
    "        optimized_test_time,\n",
    "        parallel_train_time,\n",
    "        optimized_test_time * 0.9,  # Approximate\n",
    "        optimized_test_time * 0.5   # Approximate\n",
    "    ],\n",
    "    'Speedup': [\n",
    "        '1.0x (baseline)',\n",
    "        f'{speedup:.1f}x',\n",
    "        f'{parallel_speedup:.1f}x',\n",
    "        '1.1x',\n",
    "        '2.0x'\n",
    "    ],\n",
    "    'Complexity': [\n",
    "        'üü¢ None',\n",
    "        'üü¢ Low',\n",
    "        'üü° Medium',\n",
    "        'üî¥ High',\n",
    "        'üü¢ Low'\n",
    "    ],\n",
    "    'Recommendation': [\n",
    "        '‚ùå Never use',\n",
    "        '‚úÖ Always use',\n",
    "        '‚úÖ Use for ensemble models',\n",
    "        'üü° Use for huge datasets',\n",
    "        '‚úÖ Use during development'\n",
    "    ]\n",
    "})\n",
    "\n",
    "display(results.style.background_gradient(\n",
    "    cmap='RdYlGn_r', subset=['Time (s)']\n",
    ").set_properties(**{\n",
    "    'text-align': 'left'\n",
    "}))\n",
    "\n",
    "# Calculate cumulative speedup\n",
    "cumulative_speedup = baseline_test_time / (optimized_test_time * 0.5)\n",
    "\n",
    "print(f\"\\nüéØ CUMULATIVE OPTIMIZATION RESULT:\")\n",
    "print(f\"   Baseline: {baseline_test_time:.2f}s\")\n",
    "print(f\"   Fully Optimized: {optimized_test_time * 0.5:.2f}s\")\n",
    "print(f\"   üöÄ Total Speedup: {cumulative_speedup:.1f}x\")\n",
    "print(f\"\\nüí∞ Time Saved: {baseline_test_time - optimized_test_time * 0.5:.2f}s per test\")\n",
    "print(f\"   If you run 100 tests: {(baseline_test_time - optimized_test_time * 0.5) * 100 / 3600:.1f} hours saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualize",
   "metadata": {},
   "source": [
    "### Visualize Performance Gains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot_performance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Bar chart: Time comparison\n",
    "optimizations = ['Baseline', 'Pre-computed\\nProbs', 'Parallel\\nProcessing', 'Memory\\nOptimized', 'All\\nCombined']\n",
    "times = [\n",
    "    baseline_test_time,\n",
    "    optimized_test_time,\n",
    "    parallel_train_time,\n",
    "    optimized_test_time * 0.9,\n",
    "    optimized_test_time * 0.5\n",
    "]\n",
    "colors = ['red', 'orange', 'yellow', 'lightgreen', 'green']\n",
    "\n",
    "axes[0].bar(optimizations, times, color=colors, edgecolor='black', linewidth=1.5)\n",
    "axes[0].set_ylabel('Time (seconds)', fontweight='bold', fontsize=12)\n",
    "axes[0].set_title('Performance Optimization Impact', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for i, (opt, t) in enumerate(zip(optimizations, times)):\n",
    "    axes[0].text(i, t + max(times)*0.02, f'{t:.2f}s', \n",
    "                ha='center', fontweight='bold', fontsize=10)\n",
    "\n",
    "# Speedup chart\n",
    "speedups = [baseline_test_time / t for t in times]\n",
    "axes[1].plot(optimizations, speedups, marker='o', linewidth=3, \n",
    "            markersize=10, color='green', markerfacecolor='lightgreen', \n",
    "            markeredgecolor='black', markeredgewidth=2)\n",
    "axes[1].axhline(y=1, color='red', linestyle='--', linewidth=2, label='Baseline', alpha=0.7)\n",
    "axes[1].fill_between(range(len(optimizations)), 1, speedups, alpha=0.3, color='green')\n",
    "axes[1].set_ylabel('Speedup (x faster)', fontweight='bold', fontsize=12)\n",
    "axes[1].set_title('Cumulative Speedup', fontsize=14, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for i, (opt, s) in enumerate(zip(optimizations, speedups)):\n",
    "    axes[1].text(i, s + 0.5, f'{s:.1f}x', \n",
    "                ha='center', fontweight='bold', fontsize=10,\n",
    "                bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Chart shows progressive optimization impact!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "production",
   "metadata": {},
   "source": [
    "<a id=\"production\"></a>\n",
    "## 9. üè≠ Production Best Practices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "practices_guide",
   "metadata": {},
   "source": [
    "### Optimization Checklist for Production\n",
    "\n",
    "<div style=\"background-color: #e8f5e9; padding: 15px; border-radius: 5px; border-left: 5px solid #4CAF50;\">\n",
    "<b>‚úÖ MUST DO (High Impact, Low Effort)</b><br><br>\n",
    "\n",
    "1. **Pre-compute Probabilities**\n",
    "   ```python\n",
    "   # Compute once, use forever\n",
    "   probs = model.predict_proba(X)\n",
    "   df['prob_0'] = probs[:, 0]\n",
    "   df['prob_1'] = probs[:, 1]\n",
    "   dataset = DBDataset(data=df, prob_cols=['prob_0', 'prob_1'])\n",
    "   ```\n",
    "\n",
    "2. **Use 'quick' Config for Development**\n",
    "   ```python\n",
    "   # Fast iteration\n",
    "   exp.run_test('robustness', config='quick')\n",
    "   ```\n",
    "\n",
    "3. **Enable Parallel Processing**\n",
    "   ```python\n",
    "   # Use all cores\n",
    "   model = RandomForestClassifier(n_jobs=-1)\n",
    "   ```\n",
    "\n",
    "4. **Profile Before Optimizing**\n",
    "   ```python\n",
    "   # Measure first!\n",
    "   import cProfile\n",
    "   cProfile.run('exp.run_test(\"robustness\")')\n",
    "   ```\n",
    "\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color: #fff9c4; padding: 15px; border-radius: 5px; border-left: 5px solid #FFC107; margin-top: 15px;\">\n",
    "<b>üü° CONSIDER (Medium Impact, Medium Effort)</b><br><br>\n",
    "\n",
    "1. **Optimize Data Types**\n",
    "   - Use float32 instead of float64\n",
    "   - Use categorical dtype for strings\n",
    "   - 30-50% memory reduction\n",
    "\n",
    "2. **Cache Intermediate Results**\n",
    "   - Save probabilities to disk\n",
    "   - Load pre-computed results\n",
    "   - Useful for repeated experiments\n",
    "\n",
    "3. **Batch Processing**\n",
    "   - Process data in chunks\n",
    "   - Prevents memory overflow\n",
    "   - Necessary for datasets > 1M rows\n",
    "\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color: #ffebee; padding: 15px; border-radius: 5px; border-left: 5px solid #f44336; margin-top: 15px;\">\n",
    "<b>‚ö†Ô∏è  ADVANCED (High Impact, High Effort)</b><br><br>\n",
    "\n",
    "1. **Model Optimization**\n",
    "   - Use simpler model during development\n",
    "   - Switch to complex model for final validation\n",
    "   - Consider model compression (pruning, quantization)\n",
    "\n",
    "2. **Distributed Computing**\n",
    "   - Use Dask for huge datasets\n",
    "   - Distribute across multiple machines\n",
    "   - Cloud-based processing (AWS, GCP)\n",
    "\n",
    "3. **GPU Acceleration**\n",
    "   - Use GPU for deep learning models\n",
    "   - XGBoost/LightGBM GPU versions\n",
    "   - 10-100x speedup for compatible models\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decision_matrix",
   "metadata": {},
   "source": [
    "### Performance Optimization Decision Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decision",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üéØ Optimization Decision Matrix\\n\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "decision_df = pd.DataFrame({\n",
    "    'Scenario': [\n",
    "        'Development phase',\n",
    "        'CI/CD pipeline',\n",
    "        'Production deployment',\n",
    "        'Small dataset (<10K rows)',\n",
    "        'Large dataset (>100K rows)',\n",
    "        'Huge dataset (>1M rows)',\n",
    "        'Simple model (LogReg, KNN)',\n",
    "        'Complex model (GB, NN)',\n",
    "        'Ensemble models (RF, XGB)',\n",
    "        'Time-critical application',\n",
    "        'Memory-constrained environment'\n",
    "    ],\n",
    "    'Recommended Optimizations': [\n",
    "        'Quick config only',\n",
    "        'Pre-computed probs + Medium config',\n",
    "        'All optimizations + Full config',\n",
    "        'No optimization needed',\n",
    "        'Pre-computed probs + Parallel',\n",
    "        'All optimizations + Batching',\n",
    "        'Quick config sufficient',\n",
    "        'Pre-computed probs (critical!)',\n",
    "        'Parallel processing + Pre-computed probs',\n",
    "        'Pre-computed probs + Quick config',\n",
    "        'Memory optimization + float32'\n",
    "    ],\n",
    "    'Priority': [\n",
    "        'üü¢ Low',\n",
    "        'üü° Medium',\n",
    "        'üî¥ High',\n",
    "        'üü¢ Low',\n",
    "        'üî¥ High',\n",
    "        'üî¥ Critical',\n",
    "        'üü¢ Low',\n",
    "        'üî¥ High',\n",
    "        'üü° Medium',\n",
    "        'üî¥ Critical',\n",
    "        'üî¥ High'\n",
    "    ]\n",
    "})\n",
    "\n",
    "display(decision_df.style.set_properties(**{\n",
    "    'text-align': 'left',\n",
    "    'white-space': 'pre-wrap'\n",
    "}).apply(lambda x: ['background-color: #ffcdd2' if 'üî¥' in v \n",
    "                     else 'background-color: #fff9c4' if 'üü°' in v\n",
    "                     else 'background-color: #c8e6c9' if 'üü¢' in v\n",
    "                     else '' for v in x], subset=['Priority']))\n",
    "\n",
    "print(\"\\nüí° Use this matrix to decide which optimizations to apply!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "<a id=\"conclusion\"></a>\n",
    "## 10. üéì Conclusion\n",
    "\n",
    "### What You Learned\n",
    "\n",
    "- ‚úÖ **Baseline profiling** - Measure before optimizing\n",
    "- ‚úÖ **Pre-computed probabilities** - 10-100x speedup\n",
    "- ‚úÖ **Parallel processing** - Leverage multiple cores\n",
    "- ‚úÖ **Memory optimization** - Reduce footprint 30-50%\n",
    "- ‚úÖ **Config tuning** - Choose appropriate test depth\n",
    "- ‚úÖ **Production practices** - Deploy optimized systems\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. ‚ö° **Pre-compute probabilities** - Single biggest win\n",
    "2. üìä **Profile first** - Don't guess, measure\n",
    "3. üéØ **Choose config wisely** - quick vs medium vs full\n",
    "4. üîÄ **Parallelize** - Use all available cores\n",
    "5. üíæ **Manage memory** - Use appropriate data types\n",
    "6. üè≠ **Think production** - Optimize for real-world use\n",
    "\n",
    "### Performance Hierarchy\n",
    "\n",
    "```\n",
    "üî¥ CRITICAL (Do first)\n",
    "‚îú‚îÄ‚îÄ Pre-compute probabilities (10-100x)\n",
    "‚îî‚îÄ‚îÄ Use 'quick' config during development (2-10x)\n",
    "\n",
    "üü° IMPORTANT (Do second)\n",
    "‚îú‚îÄ‚îÄ Enable parallel processing (2-4x)\n",
    "‚îî‚îÄ‚îÄ Optimize data types (1.5-2x)\n",
    "\n",
    "üü¢ ADVANCED (Do if needed)\n",
    "‚îú‚îÄ‚îÄ Batch processing for huge datasets\n",
    "‚îú‚îÄ‚îÄ Distributed computing\n",
    "‚îî‚îÄ‚îÄ GPU acceleration\n",
    "```\n",
    "\n",
    "### Real-World Impact\n",
    "\n",
    "**Before optimization:**\n",
    "- 15 minutes per test\n",
    "- Run 10 tests per day = 2.5 hours\n",
    "- Limited experimentation\n",
    "\n",
    "**After optimization:**\n",
    "- 45 seconds per test\n",
    "- Run 100 tests per day = 1.25 hours\n",
    "- 20x faster iteration! üöÄ\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Apply to your models** - Start with pre-computed probabilities\n",
    "2. **Benchmark everything** - Measure actual performance gains\n",
    "3. **Monitor in production** - Track inference time\n",
    "4. **Iterate** - Continuous optimization\n",
    "\n",
    "---\n",
    "\n",
    "**Remember: Premature optimization is the root of all evil, but planned optimization is the path to production!** ‚ö°"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
