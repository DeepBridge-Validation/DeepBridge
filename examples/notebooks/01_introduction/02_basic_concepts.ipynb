{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cell-0",
      "metadata": {},
      "source": [
        "# ğŸ“š DeepBridge Basic Concepts\n",
        "\n",
        "<div style=\"background-color: #e3f2fd; padding: 15px; border-radius: 5px; border-left: 5px solid #2196F3;\">\n",
        "<b>ğŸ““ Notebook Information</b><br>\n",
        "<b>Level:</b> Beginner<br>\n",
        "<b>Estimated Time:</b> 15-20 minutes<br>\n",
        "<b>Prerequisites:</b> 01_first_steps.ipynb<br>\n",
        "<b>Dataset:</b> Titanic\n",
        "</div>\n",
        "\n",
        "## ğŸ¯ Objectives\n",
        "\n",
        "- âœ… Understand DeepBridge architecture\n",
        "- âœ… Learn about DBDataset in depth\n",
        "- âœ… Learn about Experiment (orchestrator)\n",
        "- âœ… Experiment and test types\n",
        "- âœ… Configurations (quick/medium/full)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-1",
      "metadata": {},
      "source": [
        "## 1. ğŸ—ï¸ DeepBridge Architecture\n",
        "\n",
        "```\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚         DBDataset                    â”‚  â† Data container\n",
        "â”‚   (data + model + predictions)      â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "               â†“\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚         Experiment                   â”‚  â† Orchestrator\n",
        "â”‚   (coordinates everything)          â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "               â†“\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚      Validation Tests                â”‚\n",
        "â”‚  â€¢ Robustness  â€¢ Uncertainty         â”‚\n",
        "â”‚  â€¢ Resilience  â€¢ Hyperparameter      â”‚\n",
        "â”‚  â€¢ Fairness                          â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "               â†“\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚      HTML Reports                    â”‚\n",
        "â”‚   (interactive and professional)     â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from deepbridge import DBDataset, Experiment\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "print(\"âœ… Imports completed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-3",
      "metadata": {},
      "source": [
        "## 2. ğŸ“¦ DBDataset In Depth\n",
        "\n",
        "### Create example dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simulate simplified Titanic dataset\n",
        "np.random.seed(42)\n",
        "n = 500\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'age': np.random.normal(30, 10, n),\n",
        "    'fare': np.random.exponential(30, n),\n",
        "    'pclass': np.random.choice([1, 2, 3], n),\n",
        "    'sex': np.random.choice(['male', 'female'], n),\n",
        "    'survived': np.random.choice([0, 1], n, p=[0.6, 0.4])\n",
        "})\n",
        "\n",
        "print(f\"Dataset created: {df.shape}\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-5",
      "metadata": {},
      "source": [
        "### Different ways to create DBDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# METHOD 1: Single dataset (automatic split)\n",
        "dataset1 = DBDataset(\n",
        "    data=df,\n",
        "    target_column='survived',\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"Method 1: Automatic split\")\n",
        "print(f\"  Train: {len(dataset1.train_data)}, Test: {len(dataset1.test_data)}\")\n",
        "print(f\"  Features: {dataset1.features}\")\n",
        "print(f\"  Categorical features: {dataset1.categorical_features}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-7",
      "metadata": {},
      "source": [
        "## 3. ğŸ”¬ Experiment - The Orchestrator\n",
        "\n",
        "### Experiment Types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train a simple model\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Prepare data\n",
        "df_encoded = df.copy()\n",
        "df_encoded['sex'] = LabelEncoder().fit_transform(df_encoded['sex'])\n",
        "\n",
        "X = df_encoded.drop('survived', axis=1)\n",
        "y = df_encoded['survived']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train\n",
        "clf = RandomForestClassifier(n_estimators=50, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "print(f\"âœ… Model trained: Acc={clf.score(X_test, y_test):.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create DBDataset with model\n",
        "dataset_with_model = DBDataset(\n",
        "    data=df_encoded,\n",
        "    target_column='survived',\n",
        "    model=clf,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"DBDataset with model created!\")\n",
        "print(f\"Predictions available: {dataset_with_model.test_predictions is not None}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-10",
      "metadata": {},
      "source": [
        "### Create Experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-11",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Experiment: binary_classification\n",
        "exp = Experiment(\n",
        "    dataset=dataset_with_model,\n",
        "    experiment_type='binary_classification',  # or 'regression', 'forecasting'\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"âœ… Experiment created!\")\n",
        "print(f\"Type: {exp.experiment_type}\")\n",
        "print(f\"Initial metrics: {list(exp.initial_results.keys())[:5]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-12",
      "metadata": {},
      "source": [
        "## 4. ğŸ§ª Available Test Types\n",
        "\n",
        "### 4.1 Robustness"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-13",
      "metadata": {},
      "source": [
        "**What it tests:** Resistance to data perturbations\n",
        "\n",
        "**Why it matters:** Robust models are reliable in production\n",
        "\n",
        "**How it works:**\n",
        "- Perturbs features with noise\n",
        "- Measures performance degradation\n",
        "- Identifies sensitive features"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-14",
      "metadata": {},
      "source": [
        "### 4.2 Uncertainty"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-15",
      "metadata": {},
      "source": [
        "**What it tests:** Quantifies prediction uncertainty\n",
        "\n",
        "**Why it matters:** Critical decisions need confidence levels\n",
        "\n",
        "**How it works:**\n",
        "- CRQR (Conformalized Quantile Regression)\n",
        "- Confidence intervals\n",
        "- Probability calibration"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-16",
      "metadata": {},
      "source": [
        "### 4.3 Resilience"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-17",
      "metadata": {},
      "source": [
        "**What it tests:** Resistance to drift (distribution changes)\n",
        "\n",
        "**Why it matters:** Data changes over time\n",
        "\n",
        "**How it works:**\n",
        "- Detects covariate drift\n",
        "- Detects concept drift\n",
        "- Recommends retraining"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-18",
      "metadata": {},
      "source": [
        "### 4.4 Hyperparameter"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-19",
      "metadata": {},
      "source": [
        "**What it tests:** Hyperparameter importance\n",
        "\n",
        "**Why it matters:** Focus tuning on what matters\n",
        "\n",
        "**How it works:**\n",
        "- Optuna optimization\n",
        "- Importance analysis\n",
        "- Sensitivity"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-20",
      "metadata": {},
      "source": [
        "### 4.5 Fairness"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-21",
      "metadata": {},
      "source": [
        "**What it tests:** Bias and discrimination\n",
        "\n",
        "**Why it matters:** Legal compliance (EEOC, etc.)\n",
        "\n",
        "**How it works:**\n",
        "- 15 fairness metrics\n",
        "- EEOC verification (80% rule)\n",
        "- Analysis by protected group"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-22",
      "metadata": {},
      "source": [
        "## 5. âš™ï¸ Configurations: quick vs medium vs full\n",
        "\n",
        "| Config | Time | Use Case | Detail Level |\n",
        "|--------|-------|----------|-------------|\n",
        "| **quick** | ~1-2 min | Dev, CI/CD | Basic |\n",
        "| **medium** | ~5-10 min | Regular validation | Balanced â­ |\n",
        "| **full** | ~20-30 min | Critical production | Complete |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-23",
      "metadata": {},
      "source": [
        "## 6. ğŸ¯ Simple Practical Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-24",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run quick robustness test\n",
        "print(\"Running robustness test (config='quick')...\")\n",
        "print(\"Note: This test takes ~1-2 minutes\\n\")\n",
        "\n",
        "# Uncomment to run (takes some time)\n",
        "# results = exp.run_test('robustness', config_name='quick')\n",
        "# print(f\"\\nâœ… Test completed!\")\n",
        "# print(f\"Robustness Score: {results.get('robustness_score', 'N/A')}\")\n",
        "\n",
        "print(\"(Test commented out to save time - run it if you want to see!)\") "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-25",
      "metadata": {},
      "source": [
        "## 7. ğŸ‰ Conclusion\n",
        "\n",
        "### You learned:\n",
        "- âœ… Architecture: DBDataset â†’ Experiment â†’ Tests â†’ Reports\n",
        "- âœ… DBDataset: Creation methods, properties, flexibility\n",
        "- âœ… Experiment: Central orchestrator\n",
        "- âœ… 5 test types: Robustness, Uncertainty, Resilience, Hyperparameter, Fairness\n",
        "- âœ… Configs: quick/medium/full\n",
        "\n",
        "### Next:\n",
        "ğŸ“˜ **`03_complete_workflow.ipynb`** â­ - See everything working together!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}