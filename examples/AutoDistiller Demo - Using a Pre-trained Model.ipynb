{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepBridge AutoDistiller Demo - Using a Pre-trained Model\n",
    "\n",
    "This notebook demonstrates how to use the DeepBridge `AutoDistiller` to compress a complex neural network model into a simpler one, starting with a pre-trained model file rather than pre-calculated probabilities.\n",
    "\n",
    "## Overview\n",
    "\n",
    "Knowledge distillation is a technique where a simpler model (student) learns to mimic the behavior of a more complex model (teacher). This allows us to create models that are:\n",
    "- Smaller and faster\n",
    "- Easier to deploy\n",
    "- Often more interpretable\n",
    "\n",
    "In this demo, we'll:\n",
    "1. Create and train a neural network as our teacher model\n",
    "2. Save the model to disk\n",
    "3. Use AutoDistiller to create a simpler model that mimics the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, roc_auc_score\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Neural network libraries\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Sequential, load_model\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dense, Dropout\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import joblib\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# Neural network libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# Import DeepBridge components\n",
    "from deepbridge.db_data import DBDataset\n",
    "from deepbridge.auto_distiller import AutoDistiller\n",
    "from deepbridge.distillation.classification.model_registry import ModelType\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Sample Data\n",
    "\n",
    "Let's create a synthetic classification dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a binary classification dataset\n",
    "X, y = make_classification(\n",
    "    n_samples=2000, \n",
    "    n_features=20, \n",
    "    n_informative=10, \n",
    "    n_redundant=5, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Split into train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features (important for neural networks)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert to DataFrames\n",
    "feature_names = [f'feature_{i}' for i in range(X.shape[1])]\n",
    "train_df = pd.DataFrame(X_train_scaled, columns=feature_names)\n",
    "train_df['target'] = y_train\n",
    "\n",
    "test_df = pd.DataFrame(X_test_scaled, columns=feature_names)\n",
    "test_df['target'] = y_test\n",
    "\n",
    "# Display the first few rows\n",
    "print(\"Training data shape:\", train_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Train a Neural Network Teacher Model\n",
    "\n",
    "Now we'll create a neural network as our teacher model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a neural network model\n",
    "def create_neural_network():\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        Dropout(0.3),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create and train the model\n",
    "teacher_model = create_neural_network()\n",
    "\n",
    "# Add early stopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = teacher_model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Teacher Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "test_loss, test_acc = teacher_model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# Get predictions\n",
    "y_pred_proba = teacher_model.predict(X_test_scaled)\n",
    "y_pred = (y_pred_proba > 0.5).astype(int).flatten()\n",
    "\n",
    "# Calculate AUC\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"AUC-ROC: {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Teacher Model\n",
    "\n",
    "Now let's save our neural network model to disk. We'll save both a TensorFlow model (which will be loaded by TensorFlow) and a scikit-learn compatible wrapper (which will be used by DeepBridge):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory for models if it doesn't exist\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# Save the TensorFlow model\n",
    "tf_model_path = 'models/teacher_nn_model'\n",
    "teacher_model.save(tf_model_path)\n",
    "print(f\"TensorFlow model saved to {tf_model_path}\")\n",
    "\n",
    "# Create a scikit-learn compatible wrapper for the neural network\n",
    "class NeuralNetworkWrapper:\n",
    "    def __init__(self, model_path):\n",
    "        self.model = load_model(model_path)\n",
    "        self.classes_ = np.array([0, 1])\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return (self.predict_proba(X) > 0.5).astype(int)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        # Get raw predictions\n",
    "        y_pred = self.model.predict(X)\n",
    "        # Convert to 2-column format for compatibility with sklearn\n",
    "        return np.column_stack([1-y_pred, y_pred])\n",
    "\n",
    "# Create and save the wrapper\n",
    "nn_wrapper = NeuralNetworkWrapper(tf_model_path)\n",
    "sklearn_model_path = 'models/teacher_sklearn_model.pkl'\n",
    "joblib.dump(nn_wrapper, sklearn_model_path)\n",
    "print(f\"Scikit-learn compatible model saved to {sklearn_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Saved Model\n",
    "\n",
    "Let's verify that our saved model wrapper works correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model wrapper\n",
    "loaded_model = joblib.load(sklearn_model_path)\n",
    "\n",
    "# Test predictions\n",
    "test_probs = loaded_model.predict_proba(X_test_scaled)\n",
    "test_preds = loaded_model.predict(X_test_scaled)\n",
    "\n",
    "# Check shape and format\n",
    "print(f\"Probability predictions shape: {test_probs.shape}\")\n",
    "print(f\"First 5 probability predictions:\\n{test_probs[:5]}\")\n",
    "print(f\"Binary predictions shape: {test_preds.shape}\")\n",
    "print(f\"First 5 predictions: {test_preds[:5]}\")\n",
    "\n",
    "# Verify accuracy\n",
    "accuracy = accuracy_score(y_test, test_preds)\n",
    "print(f\"Loaded model accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEEPBRIDGE #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DBDataset with Model Path\n",
    "\n",
    "Now we'll create a DBDataset using our saved model path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DBDataset with model path\n",
    "dataset = DBDataset(\n",
    "    train_data=train_df,\n",
    "    test_data=test_df,\n",
    "    target_column='target',\n",
    "    model_path=sklearn_model_path\n",
    ")\n",
    "\n",
    "# Verify the dataset\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run AutoDistiller with the Model\n",
    "\n",
    "Now that we have our dataset with the model path configured, we can run the AutoDistiller to find the best student model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the AutoDistiller\n",
    "distiller = AutoDistiller(\n",
    "    dataset=dataset,\n",
    "    output_dir=\"nn_distillation_results\",\n",
    "    test_size=0.2,  # For internal validation\n",
    "    n_trials=10,    # Number of hyperparameter trials\n",
    "    random_state=42,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Customize the configuration to test different models\n",
    "distiller.customize_config(\n",
    "    model_types=[\n",
    "        ModelType.LOGISTIC_REGRESSION,\n",
    "        ModelType.DECISION_TREE,\n",
    "        ModelType.GBM,\n",
    "        ModelType.XGB\n",
    "    ],\n",
    "    temperatures=[0.5, 1.0, 2.0],\n",
    "    alphas=[0.3, 0.5, 0.7]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the distillation process\n",
    "# Use use_probabilities=False to indicate we're using the model to generate probabilities\n",
    "results_df = distiller.run(use_probabilities=False)\n",
    "\n",
    "# Display the results\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Results\n",
    "\n",
    "Now let's analyze the results to find the best student model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best model based on accuracy\n",
    "best_accuracy_config = distiller.find_best_model(metric='test_accuracy')\n",
    "print(\"Best model configuration by accuracy:\")\n",
    "for key, value in best_accuracy_config.items():\n",
    "    if key not in ['best_params']:\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "# Find the best model based on KL divergence\n",
    "best_kl_config = distiller.find_best_model(metric='test_kl_divergence', minimize=True)\n",
    "print(\"\\nBest model configuration by KL divergence (lower is better):\")\n",
    "for key, value in best_kl_config.items():\n",
    "    if key not in ['best_params']:\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "# Compare the accuracy of the teacher model with the distilled model\n",
    "print(\"\\nModel Performance Comparison:\")\n",
    "print(f\"  Teacher Neural Network Accuracy: {test_acc:.4f}\")\n",
    "print(f\"  Best Distilled Model Accuracy: {best_accuracy_config.get('test_accuracy', 'N/A')}\")\n",
    "print(f\"  Teacher Neural Network AUC: {auc:.4f}\")\n",
    "print(f\"  Best Distilled Model AUC: {best_accuracy_config.get('test_auc_roc', 'N/A')}\")\n",
    "\n",
    "# Generate a summary report\n",
    "print(\"\\n----- Summary Report -----\")\n",
    "summary = distiller.generate_summary()\n",
    "print(summary)\n",
    "\n",
    "# Create visualizations\n",
    "distiller.create_visualizations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best distilled model\n",
    "model_path = distiller.save_best_model(\n",
    "    metric='test_kl_divergence', \n",
    "    minimize=True,\n",
    "    file_path='models/best_distilled_model.pkl'\n",
    ")\n",
    "print(f\"\\nBest model saved to: {model_path}\")\n",
    "\n",
    "# Compare model sizes\n",
    "import os\n",
    "\n",
    "tf_model_size = sum(os.path.getsize(os.path.join(tf_model_path, f)) for f in os.listdir(tf_model_path) if os.path.isfile(os.path.join(tf_model_path, f)))\n",
    "distilled_model_size = os.path.getsize(model_path)\n",
    "\n",
    "print(f\"\\nModel Size Comparison:\")\n",
    "print(f\"  Neural Network Teacher Model: {tf_model_size / (1024*1024):.2f} MB\")\n",
    "print(f\"  Distilled Model: {distilled_model_size / (1024*1024):.2f} MB\")\n",
    "print(f\"  Compression Ratio: {tf_model_size / distilled_model_size:.1f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check inference speed\n",
    "import time\n",
    "\n",
    "# Measure neural network inference time\n",
    "start_time = time.time()\n",
    "for _ in range(100):\n",
    "    teacher_model.predict(X_test_scaled)\n",
    "nn_time = time.time() - start_time\n",
    "\n",
    "# Load the distilled model\n",
    "best_distilled_model = joblib.load(model_path)\n",
    "\n",
    "# Measure distilled model inference time\n",
    "start_time = time.time()\n",
    "for _ in range(100):\n",
    "    best_distilled_model.predict(X_test_scaled)\n",
    "distilled_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\nInference Speed Comparison (100 predictions):\")\n",
    "print(f\"  Neural Network Time: {nn_time:.4f} seconds\")\n",
    "print(f\"  Distilled Model Time: {distilled_time:.4f} seconds\")\n",
    "print(f\"  Speedup: {nn_time / distilled_time:.1f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conclusion\n",
    "print(\"\\n----- Conclusion -----\")\n",
    "print(f\"We've successfully distilled a complex neural network with {teacher_model.count_params():,} parameters\")\n",
    "print(f\"into a simpler {best_kl_config['model_type']} model that offers:\")\n",
    "print(f\"  - {tf_model_size / distilled_model_size:.1f}x smaller model size\")\n",
    "print(f\"  - {nn_time / distilled_time:.1f}x faster inference\")\n",
    "print(f\"  - Comparable accuracy ({test_acc:.4f} vs {best_accuracy_config.get('test_accuracy', 0):.4f})\")\n",
    "print(\"\\nThis demonstrates how knowledge distillation can maintain performance while significantly\")\n",
    "print(\"reducing resource requirements, making complex models more deployable in production environments.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional analysis: Feature importance comparison\n",
    "if hasattr(best_distilled_model, 'student_model') and hasattr(best_distilled_model.student_model, 'feature_importances_'):\n",
    "    # Plot feature importance for the distilled model\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Get feature importance\n",
    "    importances = best_distilled_model.student_model.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    \n",
    "    plt.bar(range(X_test.shape[1]), importances[indices], align='center')\n",
    "    plt.xticks(range(X_test.shape[1]), [feature_names[i] for i in indices], rotation=90)\n",
    "    plt.title('Feature Importance in Distilled Model')\n",
    "    plt.xlabel('Features')\n",
    "    plt.ylabel('Importance')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nThe feature importance visualization shows which features the distilled model relies on most.\")\n",
    "    print(\"This can provide insights into model interpretability, which is an additional benefit of\")\n",
    "    print(\"using simpler models through knowledge distillation.\")\n",
    "\n",
    "# Save experiment artifacts\n",
    "os.makedirs('experiment_results', exist_ok=True)\n",
    "results_df.to_csv('experiment_results/distillation_results.csv', index=False)\n",
    "print(\"\\nExperiment results saved to: experiment_results/distillation_results.csv\")\n",
    "\n",
    "# Create predictions on test data using both models\n",
    "teacher_test_preds = teacher_model.predict(X_test_scaled)\n",
    "distilled_test_preds = best_distilled_model.predict(X_test_scaled)\n",
    "\n",
    "# Check agreement between teacher and student models\n",
    "agreement = np.mean(teacher_test_preds == distilled_test_preds)\n",
    "print(f\"\\nAgreement between teacher and distilled model predictions: {agreement:.4f} ({agreement*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nFinal Remarks:\")\n",
    "print(\"1. The distilled model achieves comparable accuracy to the complex neural network\")\n",
    "print(\"2. The model size is significantly reduced, enabling deployment in constrained environments\")\n",
    "print(\"3. Inference speed is much faster, which is crucial for real-time applications\")\n",
    "print(\"4. The simpler model may offer better interpretability and explainability\")\n",
    "print(\"\\nThese benefits make knowledge distillation a valuable technique for productionizing\")\n",
    "print(\"complex models while maintaining their performance characteristics.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_prod_deepbridge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
