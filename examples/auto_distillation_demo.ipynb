{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepBridge Auto-Distillation Demo Notebook\n",
    "\n",
    "I'll create a Jupyter notebook that demonstrates how to use the DeepBridge library for auto-distillation of classification models. This notebook will walk through the entire process from data preparation to model evaluation.\n",
    "\n",
    "## Understanding the DeepBridge Auto-Distillation Notebook\n",
    "\n",
    "I've created a comprehensive Jupyter notebook that demonstrates how to use DeepBridge's AutoDistiller for model distillation with a classification task. Let me walk you through what this notebook covers:\n",
    "\n",
    "### Key Components:\n",
    "\n",
    "1. **Data Preparation**: Using the breast cancer dataset, which is a standard binary classification problem\n",
    "2. **Teacher Model**: Creating a complex Random Forest model with 500 trees\n",
    "3. **DBDataset Setup**: Preparing the data structure required by DeepBridge\n",
    "4. **Auto-Distillation**: Using AutoDistiller to test multiple student models and configurations\n",
    "5. **Results Analysis**: Evaluating and comparing the performance of teacher vs. student models\n",
    "6. **Visualization**: Comparing probability distributions and model sizes\n",
    "\n",
    "### Workflow:\n",
    "\n",
    "The notebook demonstrates the entire knowledge distillation workflow:\n",
    "1. Start with a complex, high-performing model (the \"teacher\")\n",
    "2. Use DeepBridge's AutoDistiller to create simplified models (the \"students\")\n",
    "3. Automatically test different model types, temperatures, and alpha values\n",
    "4. Find the optimal configuration that balances performance and simplicity\n",
    "5. Compare the final distilled model against the original\n",
    "\n",
    "### Benefits:\n",
    "\n",
    "- **Model Compression**: See how much smaller the distilled model is compared to the teacher\n",
    "- **Performance Preservation**: Evaluate how well the student model retains the teacher's accuracy\n",
    "- **Automated Process**: The AutoDistiller handles the complexity of testing multiple configurations\n",
    "\n",
    "### How to Run:\n",
    "\n",
    "You can copy this notebook to your environment and run it with the DeepBridge library installed. For installation, you would typically use:\n",
    "\n",
    "```bash\n",
    "pip install deepbridge\n",
    "```\n",
    "\n",
    "Note that the demonstration uses a reduced number of trials (`n_trials=5`) for faster execution, but in a production scenario, you might want to increase this for better optimization.\n",
    "\n",
    "Would you like me to explain any particular section of the notebook in more detail?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepBridge Auto-Distillation Demo\n",
    "# ==============================\n",
    "#\n",
    "# This notebook demonstrates how to use DeepBridge's AutoDistiller \n",
    "# for model distillation in classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
    "\n",
    "# DeepBridge imports\n",
    "from deepbridge.db_data import DBDataset\n",
    "from deepbridge.auto_distiller import AutoDistiller\n",
    "from deepbridge.distillation.classification.model_registry import ModelType\n",
    "\n",
    "# For visualization\n",
    "import seaborn as sns\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# 1. Data Preparation\n",
    "# ---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load breast cancer dataset\n",
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = pd.Series(data.target, name='target')\n",
    "\n",
    "print(f\"Dataset shape: {X.shape}\")\n",
    "print(f\"Number of classes: {len(np.unique(y))}\")\n",
    "print(f\"Class distribution: {pd.Series(y).value_counts().to_dict()}\")\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert back to DataFrames\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "print(f\"Training set shape: {X_train_scaled.shape}\")\n",
    "print(f\"Test set shape: {X_test_scaled.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 2. Create a Teacher Model (Complex Model)\n",
    "# ---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create a complex Random Forest model as our teacher\n",
    "teacher_model = RandomForestClassifier(\n",
    "    n_estimators=500,  # Use many trees\n",
    "    max_depth=20,      # Allow deep trees\n",
    "    min_samples_split=2,\n",
    "    bootstrap=True,\n",
    "    random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "# Train the teacher model\n",
    "teacher_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate teacher model\n",
    "y_pred_teacher = teacher_model.predict(X_test_scaled)\n",
    "y_prob_teacher = teacher_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "teacher_accuracy = accuracy_score(y_test, y_pred_teacher)\n",
    "teacher_auc = roc_auc_score(y_test, y_prob_teacher)\n",
    "\n",
    "print(f\"Teacher Model Performance:\")\n",
    "print(f\"Accuracy: {teacher_accuracy:.4f}\")\n",
    "print(f\"AUC-ROC: {teacher_auc:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_teacher))\n",
    "\n",
    "# Generate teacher probabilities for all data\n",
    "train_probs = teacher_model.predict_proba(X_train_scaled)\n",
    "test_probs = teacher_model.predict_proba(X_test_scaled)\n",
    "\n",
    "# Create probability DataFrames\n",
    "train_probs_df = pd.DataFrame(\n",
    "    train_probs, \n",
    "    columns=[f'prob_class_{i}' for i in range(train_probs.shape[1])],\n",
    "    index=X_train.index\n",
    ")\n",
    "\n",
    "test_probs_df = pd.DataFrame(\n",
    "    test_probs, \n",
    "    columns=[f'prob_class_{i}' for i in range(test_probs.shape[1])],\n",
    "    index=X_test.index\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# 3. Create a DBDataset for Distillation\n",
    "# ---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create a combined DataFrame for training data\n",
    "train_data = pd.concat([X_train_scaled, y_train], axis=1)\n",
    "test_data = pd.concat([X_test_scaled, y_test], axis=1)\n",
    "\n",
    "# Create DBDataset\n",
    "dataset = DBDataset(\n",
    "    train_data=train_data,\n",
    "    test_data=test_data,\n",
    "    target_column='target',\n",
    "    features=X_train.columns.tolist(),\n",
    "    train_predictions=train_probs_df,\n",
    "    test_predictions=test_probs_df,\n",
    "    prob_cols=[f'prob_class_{i}' for i in range(train_probs.shape[1])],\n",
    "    dataset_name=\"breast_cancer\"\n",
    ")\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# 4. Using AutoDistiller for Model Distillation\n",
    "# ---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create an AutoDistiller instance\n",
    "auto_distiller = AutoDistiller(\n",
    "    dataset=dataset,\n",
    "    output_dir=\"./distillation_results\",\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_SEED,\n",
    "    n_trials=5,  # Reduced for demo purposes\n",
    "    validation_split=0.2,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Customize configuration\n",
    "auto_distiller.customize_config(\n",
    "    model_types=[\n",
    "        ModelType.LOGISTIC_REGRESSION,\n",
    "        ModelType.DECISION_TREE,\n",
    "        ModelType.GBM\n",
    "    ],\n",
    "    temperatures=[0.5, 1.0, 2.0],\n",
    "    alphas=[0.3, 0.7]\n",
    ")\n",
    "\n",
    "# Run the distillation process\n",
    "results = auto_distiller.run(use_probabilities=True, verbose_output=True)\n",
    "\n",
    "# Display results\n",
    "print(\"Distillation Results Summary:\")\n",
    "print(results.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# 5. Analyze the Results\n",
    "# ---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Find the best model based on test accuracy\n",
    "best_config = auto_distiller.find_best_model(metric='test_accuracy', minimize=False)\n",
    "\n",
    "print(\"\\nBest Model Configuration:\")\n",
    "print(f\"Model Type: {best_config['model_type']}\")\n",
    "print(f\"Temperature: {best_config['temperature']}\")\n",
    "print(f\"Alpha: {best_config['alpha']}\")\n",
    "print(f\"Test Accuracy: {best_config.get('test_accuracy', 'N/A')}\")\n",
    "\n",
    "# Get the best trained model\n",
    "best_model = auto_distiller.get_trained_model(\n",
    "    model_type=best_config['model_type'],\n",
    "    temperature=best_config['temperature'],\n",
    "    alpha=best_config['alpha']\n",
    ")\n",
    "\n",
    "# Evaluate the distilled model\n",
    "student_preds = best_model.predict(X_test_scaled)\n",
    "student_probs = best_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "student_accuracy = accuracy_score(y_test, student_preds)\n",
    "student_auc = roc_auc_score(y_test, student_probs)\n",
    "\n",
    "print(\"\\nDistilled Model Performance:\")\n",
    "print(f\"Accuracy: {student_accuracy:.4f}\")\n",
    "print(f\"AUC-ROC: {student_auc:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, student_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# 6. Performance Comparison\n",
    "# ---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Compare teacher vs student model performance\n",
    "metrics = {\n",
    "    'Model': ['Teacher', 'Student (Distilled)'],\n",
    "    'Accuracy': [teacher_accuracy, student_accuracy],\n",
    "    'AUC-ROC': [teacher_auc, student_auc]\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(metrics)\n",
    "print(\"\\nPerformance Comparison:\")\n",
    "print(comparison_df)\n",
    "\n",
    "# Plot comparison\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Accuracy comparison\n",
    "ax[0].bar(metrics['Model'], metrics['Accuracy'], color=['#4A6FA5', '#E57373'])\n",
    "ax[0].set_ylim([0.9, 1.0])  # Adjust as needed\n",
    "ax[0].set_title('Accuracy Comparison')\n",
    "ax[0].set_ylabel('Accuracy')\n",
    "\n",
    "# AUC-ROC comparison\n",
    "ax[1].bar(metrics['Model'], metrics['AUC-ROC'], color=['#4A6FA5', '#E57373'])\n",
    "ax[1].set_ylim([0.9, 1.0])  # Adjust as needed\n",
    "ax[1].set_title('AUC-ROC Comparison')\n",
    "ax[1].set_ylabel('AUC-ROC')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# 7. Visualize Probability Distributions\n",
    "# ---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Compare probability distributions between teacher and student\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Get probabilities for positive class\n",
    "teacher_probs_pos = y_prob_teacher\n",
    "student_probs_pos = student_probs\n",
    "\n",
    "# Plot density curves\n",
    "sns.kdeplot(teacher_probs_pos, label='Teacher Model', color='#4A6FA5')\n",
    "sns.kdeplot(student_probs_pos, label='Student Model', color='#E57373')\n",
    "\n",
    "plt.title('Comparison of Probability Distributions')\n",
    "plt.xlabel('Probability (Positive Class)')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# 8. Save the Best Model\n",
    "# ---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "model_path = auto_distiller.save_best_model(\n",
    "    metric='test_accuracy',\n",
    "    minimize=False,\n",
    "    file_path='./best_distilled_model.pkl'\n",
    ")\n",
    "\n",
    "print(f\"\\nBest model saved to: {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# 9. Model Size Comparison\n",
    "# ---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "\n",
    "# Estimate the size of the teacher model\n",
    "teacher_size = sys.getsizeof(pickle.dumps(teacher_model)) / (1024 * 1024)  # in MB\n",
    "\n",
    "# Estimate the size of the student model\n",
    "student_size = sys.getsizeof(pickle.dumps(best_model)) / (1024 * 1024)  # in MB\n",
    "\n",
    "print(\"\\nModel Size Comparison:\")\n",
    "print(f\"Teacher Model: {teacher_size:.2f} MB\")\n",
    "print(f\"Student Model: {student_size:.2f} MB\")\n",
    "print(f\"Size Reduction: {(1 - student_size/teacher_size) * 100:.2f}%\")\n",
    "\n",
    "# Plot model size comparison\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(['Teacher Model', 'Student Model'], [teacher_size, student_size], color=['#4A6FA5', '#E57373'])\n",
    "plt.title('Model Size Comparison')\n",
    "plt.ylabel('Size (MB)')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add size labels\n",
    "for i, size in enumerate([teacher_size, student_size]):\n",
    "    plt.text(i, size + 0.1, f\"{size:.2f} MB\", ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# 10. Summary and Conclusions\n",
    "# ---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\nDistillation Summary:\")\n",
    "print(\"=====================\")\n",
    "print(f\"Teacher Model: RandomForest with 500 trees\")\n",
    "print(f\"Best Student Model: {best_config['model_type']}\")\n",
    "print(f\"Performance Gap (Accuracy): {(teacher_accuracy - student_accuracy) * 100:.2f}%\")\n",
    "print(f\"Performance Gap (AUC-ROC): {(teacher_auc - student_auc) * 100:.2f}%\")\n",
    "print(f\"Size Reduction: {(1 - student_size/teacher_size) * 100:.2f}%\")\n",
    "\n",
    "print(\"\\nConclusion:\")\n",
    "if student_accuracy >= 0.95 * teacher_accuracy:\n",
    "    print(\"✅ Successfully distilled a simpler model with minimal performance loss\")\n",
    "    print(\"✅ Achieved significant reduction in model size\")\n",
    "    print(\"✅ The distilled model maintains high accuracy and AUC-ROC\")\n",
    "else:\n",
    "    print(\"⚠️ Distillation completed, but performance gap is significant\")\n",
    "    print(\"⚠️ Consider adjusting distillation parameters or using a different student model type\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
