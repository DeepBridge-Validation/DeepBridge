{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepBridge Machine Learning Workflow Tutorial\n",
    "\n",
    "## Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install DeepBridge and dependencies\n",
    "!pip install deepbridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook Walkthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# DeepBridge imports\n",
    "from deepbridge.db_data import DBDataset\n",
    "from deepbridge.auto_distiller import AutoDistiller\n",
    "from deepbridge.model_validation import ModelValidation\n",
    "\n",
    "# Scikit-learn imports for data preparation\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load breast cancer dataset\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Create DataFrame for better visualization\n",
    "df = pd.DataFrame(X, columns=data.feature_names)\n",
    "df['target'] = y\n",
    "\n",
    "# Display basic information\n",
    "print(\"Dataset Overview:\")\n",
    "print(df.head())\n",
    "print(\"\\nDataset Shape:\", df.shape)\n",
    "print(\"\\nTarget Distribution:\")\n",
    "print(df['target'].value_counts(normalize=True))\n",
    "\n",
    "# Visualize feature distributions\n",
    "plt.figure(figsize=(15, 10))\n",
    "df.drop('target', axis=1).boxplot()\n",
    "plt.title('Feature Distributions')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Data Preprocessing and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for DeepBridge\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "df_scaled = pd.DataFrame(X_scaled, columns=data.feature_names)\n",
    "df_scaled['target'] = y\n",
    "\n",
    "# Create DBDataset\n",
    "dataset = DBDataset(\n",
    "    data=df_scaled,\n",
    "    target_column='target',\n",
    "    synthetic=True  # Generate synthetic data for augmentation\n",
    ")\n",
    "\n",
    "# Perform model validation\n",
    "experiment = ModelValidation(\n",
    "    experiment_name=\"breast_cancer_classification\"\n",
    ")\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_scaled.drop('target', axis=1), \n",
    "    df_scaled['target'], \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Add data to experiment\n",
    "experiment.add_data(\n",
    "    X_train=X_train, \n",
    "    y_train=y_train, \n",
    "    X_test=X_test, \n",
    "    y_test=y_test\n",
    ")\n",
    "\n",
    "# Visualize synthetic data generation\n",
    "synthetic_data = dataset.synthetic_data\n",
    "plt.figure(figsize=(15, 10))\n",
    "synthetic_df = pd.DataFrame(synthetic_data, columns=data.feature_names + ['target'])\n",
    "\n",
    "# Compare original vs synthetic data distributions\n",
    "fig, axes = plt.subplots(2, 1, figsize=(15, 10))\n",
    "df['target'].value_counts().plot(kind='bar', ax=axes[0], title='Original Data Target Distribution')\n",
    "synthetic_df['target'].value_counts().plot(kind='bar', ax=axes[1], title='Synthetic Data Target Distribution')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print synthetic data quality metrics\n",
    "print(\"\\nSynthetic Data Quality Metrics:\")\n",
    "print(dataset.synthetic_quality_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Automated Model Distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize AutoDistiller\n",
    "auto_distiller = AutoDistiller(\n",
    "    dataset=dataset,\n",
    "    output_dir='./breast_cancer_results',\n",
    "    n_trials=20,  # Number of hyperparameter optimization trials\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Customize model configurations\n",
    "auto_distiller.customize_config(\n",
    "    model_types=['gbm', 'xgb', 'random_forest'],\n",
    "    temperatures=[0.5, 1.0, 2.0],\n",
    "    alphas=[0.3, 0.5, 0.7]\n",
    ")\n",
    "\n",
    "# Run distillation experiments\n",
    "results_df = auto_distiller.run()\n",
    "\n",
    "# Generate and print report\n",
    "report = auto_distiller.generate_report()\n",
    "print(\"\\nDistillation Experiment Report:\")\n",
    "print(report)\n",
    "\n",
    "# Visualize model performance\n",
    "plt.figure(figsize=(15, 10))\n",
    "results_df.boxplot(column=['test_accuracy'], by='model_type')\n",
    "plt.title('Model Accuracy by Model Type')\n",
    "plt.suptitle('')  # Remove automatic suptitle\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find and save best model\n",
    "best_model_path = auto_distiller.save_best_model(\n",
    "    metric='test_accuracy', \n",
    "    minimize=False\n",
    ")\n",
    "print(f\"\\nBest model saved to: {best_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Model Performance Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create detailed performance comparison\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Prepare performance metrics for visualization\n",
    "performance_metrics = [\n",
    "    'test_accuracy', \n",
    "    'test_precision', \n",
    "    'test_recall', \n",
    "    'test_f1', \n",
    "    'test_auc_roc'\n",
    "]\n",
    "\n",
    "# Melt the dataframe for easier plotting\n",
    "melted_df = results_df.melt(\n",
    "    id_vars=['model_type', 'temperature', 'alpha'], \n",
    "    value_vars=performance_metrics, \n",
    "    var_name='Metric', \n",
    "    value_name='Value'\n",
    ")\n",
    "\n",
    "# Create boxplot\n",
    "sns.boxplot(\n",
    "    x='model_type', \n",
    "    y='Value', \n",
    "    hue='Metric', \n",
    "    data=melted_df\n",
    ")\n",
    "plt.title('Model Performance Across Different Metrics')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Temperature and Alpha Impact\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.scatterplot(\n",
    "    data=results_df, \n",
    "    x='temperature', \n",
    "    y='test_accuracy', \n",
    "    hue='model_type', \n",
    "    size='alpha', \n",
    "    palette='viridis'\n",
    ")\n",
    "plt.title('Temperature and Alpha Impact on Model Accuracy')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Advanced Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best model\n",
    "best_config = auto_distiller.find_best_model(\n",
    "    metric='test_accuracy', \n",
    "    minimize=False\n",
    ")\n",
    "\n",
    "# Retrieve trained model\n",
    "best_model = auto_distiller.get_trained_model(\n",
    "    best_config['model_type'], \n",
    "    best_config['temperature'], \n",
    "    best_config['alpha']\n",
    ")\n",
    "\n",
    "# Feature importance for interpretability\n",
    "if hasattr(best_model, 'get_feature_importances'):\n",
    "    feature_importances = best_model.get_feature_importances()\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    feature_imp_df = pd.DataFrame.from_dict(\n",
    "        feature_importances, \n",
    "        orient='index', \n",
    "        columns=['Importance']\n",
    "    ).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    feature_imp_df.plot(kind='bar')\n",
    "    plt.title('Feature Importances in Best Model')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Print best model configuration\n",
    "print(\"\\nBest Model Configuration:\")\n",
    "print(json.dumps(best_config, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion and Next Steps\n",
    "This notebook demonstrated:\n",
    "\n",
    "Data preprocessing with DeepBridge\n",
    "Synthetic data generation\n",
    "Automated model distillation\n",
    "Performance comparison\n",
    "Model interpretation\n",
    "\n",
    "Recommended Next Steps:\n",
    "\n",
    "Experiment with different datasets\n",
    "Try various model configurations\n",
    "Use synthetic data for data augmentation\n",
    "Explore feature engineering techniques"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_prod_deepbridge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
