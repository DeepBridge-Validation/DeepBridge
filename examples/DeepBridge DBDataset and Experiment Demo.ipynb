{
  "cells": [
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "## 6. Using the Experiment Class\n",
     "\n",
     "Now that we have our DBDataset set up, we can use the `Experiment` class to run knowledge distillation experiments. The `Experiment` class manages the distillation process, from model training to evaluation."
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 8,
    "metadata": {},
    "outputs": [
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
       "=== Evaluating distillation model on train dataset ===\n",
       "Using pre-calculated probabilities\n",
       "Student probabilities shape: (455, 2)\n",
       "First 3 student probabilities: [[0.98 0.02]\n",
       " [0.91 0.09]\n",
       " [0.14 0.86]]\n",
       "Teacher probabilities type: <class 'pandas.core.frame.DataFrame'>\n",
       "Teacher probabilities shape: (455, 2)\n",
       "First 3 teacher probabilities: [[0.99 0.01]\n",
       " [0.75 0.25]\n",
       " [0.1  0.9 ]]\n",
       "Teacher prob first 5 values: [0.01 0.25 0.9  0.56 0.98]\n",
       "KS Statistic calculation: 0.03076923076923077, p-value: 0.9704654051871452\n",
       "R² calculation successful: 0.9774650669825795\n",
       "Evaluation metrics: {'accuracy': 0.9692307692307692, 'precision': 0.9692982456140351, 'recall': 0.9541284403669725, 'f1_score': 0.9616122840690979, 'auc_roc': 0.9873020305869752, 'auc_pr': 0.9865493718091531, 'log_loss': 0.10256498766755073, 'kl_divergence': 0.019997600911793095, 'ks_statistic': 0.03076923076923077, 'ks_pvalue': 0.9704654051871452, 'r2_score': 0.9774650669825795, 'distillation_method': 'SurrogateModel'}\n",
       "=== Evaluation complete ===\n",
       "\n",
       "=== Evaluating distillation model on test dataset ===\n",
       "Using pre-calculated probabilities\n",
       "Student probabilities shape: (114, 2)\n",
       "First 3 student probabilities: [[0.97 0.03]\n",
       " [0.78 0.22]\n",
       " [0.94 0.06]]\n",
       "Teacher probabilities type: <class 'pandas.core.frame.DataFrame'>\n",
       "Teacher probabilities shape: (114, 2)\n",
       "First 3 teacher probabilities: [[0.97 0.03]\n",
       " [0.8  0.2 ]\n",
       " [0.96 0.04]]\n",
       "Teacher prob first 5 values: [0.03 0.2  0.04 0.98 0.96]\n",
       "KS Statistic calculation: 0.017543859649122806, p-value: 0.9999999999969212\n",
       "R² calculation successful: 0.9899748742705822\n",
       "Evaluation metrics: {'accuracy': 0.9473684210526315, 'precision': 0.9545454545454546, 'recall': 0.9130434782608695, 'f1_score': 0.9333333333333333, 'auc_roc': 0.9767725681595386, 'auc_pr': 0.9662365894709993, 'log_loss': 0.13810613350392077, 'kl_divergence': 0.09998800457766554, 'ks_statistic': 0.017543859649122806, 'ks_pvalue': 0.9999999999969212, 'r2_score': 0.9899748742705822, 'distillation_method': 'SurrogateModel'}\n",
       "=== Evaluation complete ===\n",
       "\n",
       "Surrogate Model Performance:\n",
       "- Test Accuracy: 0.947\n",
       "- Test AUC-ROC: 0.977\n",
       "- KL Divergence: 0.100\n",
       "- KS Statistic: 0.018 (p-value: 1.000)\n",
       "- R² Score: 0.990\n"
      ]
     }
    ],
    "source": [
     "# Create an Experiment instance with our DBDataset\n",
     "experiment = Experiment(\n",
     "    dataset=db_dataset,\n",
     "    experiment_type=\"binary_classification\",\n",
     "    test_size=0.2,\n",
     "    random_state=42\n",
     ")\n",
     "\n",
     "# Run distillation with a surrogate model\n",
     "experiment.fit(\n",
     "    student_model_type=ModelType.LOGISTIC_REGRESSION,\n",
     "    temperature=1.0,  # Temperature parameter for knowledge distillation\n",
     "    alpha=0.5,        # Alpha parameter (weight between teacher and true labels)\n",
     "    use_probabilities=True,  # Use pre-calculated probabilities\n",
     "    distillation_method=\"surrogate\"  # Use surrogate model distillation\n",
     ")\n",
     "\n",
     "# Get the test metrics\n",
     "test_metrics = experiment.results['test']\n",
     "\n",
     "# Display performance metrics\n",
     "print(\"Surrogate Model Performance:\")\n",
     "print(f\"- Test Accuracy: {test_metrics.get('accuracy', 'N/A'):.3f}\")\n",
     "print(f\"- Test AUC-ROC: {test_metrics.get('auc_roc', 'N/A'):.3f}\")\n",
     "print(f\"- KL Divergence: {test_metrics.get('kl_divergence', 'N/A'):.3f}\")\n",
     "print(f\"- KS Statistic: {test_metrics.get('ks_statistic', 'N/A'):.3f} (p-value: {test_metrics.get('ks_pvalue', 'N/A'):.3f})\")\n",
     "print(f\"- R² Score: {test_metrics.get('r2_score', 'N/A'):.3f}\")"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "## 7. Try Knowledge Distillation Method\n",
     "\n",
     "Now let's try the more advanced `knowledge_distillation` method, which uses both teacher probabilities and true labels during training."
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 9,
    "metadata": {},
    "outputs": [
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
       "\n",
       "=== DEBUG: _get_teacher_soft_labels ===\n",
       "X shape: (455, 5)\n",
       "teacher_model: False\n",
       "teacher_probabilities: True\n",
       "Using pre-calculated probabilities\n",
       "teacher_probabilities is DataFrame with shape (455, 2)\n",
       "teacher_probabilities columns: ['prob_class_0', 'prob_class_1']\n",
       "Found prob_class_0 and prob_class_1 columns\n",
       "First 3 probabilities: [[0.99 0.01]\n",
       " [0.75 0.25]\n",
       " [0.1  0.9 ]]\n",
       "Probabilities shape: (455, 2)\n",
       "Applying temperature=1.0 scaling\n",
       "Soft labels shape: (455, 2)\n",
       "First 3 soft labels: [[0.99 0.01]\n",
       " [0.75 0.25]\n",
       " [0.1  0.9 ]]\n",
       "=== END DEBUG ===\n",
       "\n",
       "=== EVALUATING DISTILLATION MODEL ===\n",
       "Student probabilities shape: (455, 2)\n",
       "First 3 student probabilities: [[0.97806519 0.02193481]\n",
       " [0.69868593 0.30131407]\n",
       " [0.07183229 0.92816771]]\n",
       "Teacher soft labels shape: (455, 2)\n",
       "First 3 teacher soft labels: [[0.99 0.01]\n",
       " [0.75 0.25]\n",
       " [0.1  0.9 ]]\n",
       "teacher_prob shape: (455,)\n",
       "First 5 teacher_prob values: [0.01 0.25 0.9  0.56 0.98]\n",
       "y_prob stats: min=0.021934813298069293, max=0.9999983614375593, mean=0.34131406923242724\n",
       "teacher_prob stats: min=0.01, max=0.99, mean=0.34087912087912086\n",
       "KS statistic is None, calculating manually...\n",
       "Manual KS calculation: statistic=0.02417582417582418, p-value=0.9948511569296611\n",
       "R² score is None, calculating manually...\n",
       "Manual R² calculation: 0.9995193958664322\n",
       "=== EVALUATION COMPLETE ===\n",
       "\n",
       "\n",
       "=== DEBUG: _get_teacher_soft_labels ===\n",
       "X shape: (114, 5)\n",
       "teacher_model: False\n",
       "teacher_probabilities: True\n",
       "Using pre-calculated probabilities\n",
       "teacher_probabilities is DataFrame with shape (114, 2)\n",
       "teacher_probabilities columns: ['prob_class_0', 'prob_class_1']\n",
       "Found prob_class_0 and prob_class_1 columns\n",
       "First 3 probabilities: [[0.97 0.03]\n",
       " [0.8  0.2 ]\n",
       " [0.96 0.04]]\n",
       "Probabilities shape: (114, 2)\n",
       "Applying temperature=1.0 scaling\n",
       "Soft labels shape: (114, 2)\n",
       "First 3 soft labels: [[0.97 0.03]\n",
       " [0.8  0.2 ]\n",
       " [0.96 0.04]]\n",
       "=== END DEBUG ===\n",
       "\n",
       "=== EVALUATING DISTILLATION MODEL ===\n",
       "Student probabilities shape: (114, 2)\n",
       "First 3 student probabilities: [[0.96244396 0.03755604]\n",
       " [0.75430603 0.24569397]\n",
       " [0.93902195 0.06097805]]\n",
       "Teacher soft labels shape: (114, 2)\n",
       "First 3 teacher soft labels: [[0.97 0.03]\n",
       " [0.8  0.2 ]\n",
       " [0.96 0.04]]\n",
       "teacher_prob shape: (114,)\n",
       "First 5 teacher_prob values: [0.03 0.2  0.04 0.98 0.96]\n",
       "y_prob stats: min=0.02, max=0.99, mean=0.37\n",
       "teacher_prob stats: min=0.01, max=0.99, mean=0.36\n",
       "KS statistic is None, calculating manually...\n",
       "Manual KS calculation: statistic=0.017543859649122806, p-value=0.9999999999969212\n",
       "R² score is None, calculating manually...\n",
       "Manual R² calculation: 0.9994774829213485\n",
       "=== EVALUATION COMPLETE ===\n",
       "\n",
       "Knowledge Distillation Performance:\n",
       "- Test Accuracy: 0.947\n",
       "- Test AUC-ROC: 0.975\n",
       "- KL Divergence: 0.001\n",
       "- KS Statistic: 0.018 (p-value: 1.000)\n",
       "- R² Score: 0.999\n"
      ]
     }
    ],
    "source": [
     "# Create a new experiment for knowledge distillation\n",
     "experiment_kd = Experiment(\n",
     "    dataset=db_dataset,\n",
     "    experiment_type=\"binary_classification\",\n",
     "    test_size=0.2,\n",
     "    random_state=42\n",
     ")\n",
     "\n",
     "# Run knowledge distillation\n",
     "experiment_kd.fit(\n",
     "    student_model_type=ModelType.LOGISTIC_REGRESSION,\n",
     "    temperature=1.0,\n",
     "    alpha=0.5,\n",
     "    use_probabilities=True,\n",
     "    distillation_method=\"knowledge_distillation\"  # Use knowledge distillation method\n",
     ")\n",
     "\n",
     "# Get the test metrics\n",
     "test_metrics_kd = experiment_kd.results['test']\n",
     "\n",
     "# Display performance metrics\n",
     "print(\"Knowledge Distillation Performance:\")\n",
     "print(f\"- Test Accuracy: {test_metrics_kd.get('accuracy', 'N/A'):.3f}\")\n",
     "print(f\"- Test AUC-ROC: {test_metrics_kd.get('auc_roc', 'N/A'):.3f}\")\n",
     "print(f\"- KL Divergence: {test_metrics_kd.get('kl_divergence', 'N/A'):.3f}\")\n",
     "print(f\"- KS Statistic: {test_metrics_kd.get('ks_statistic', 'N/A'):.3f} (p-value: {test_metrics_kd.get('ks_pvalue', 'N/A'):.3f})\")\n",
     "print(f\"- R² Score: {test_metrics_kd.get('r2_score', 'N/A'):.3f}\")"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "## 8. Compare Student Models with the Teacher\n",
     "\n",
     "Now let's compare the student models with the original teacher model."
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 10,
    "metadata": {},
    "outputs": [
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
       "Original Teacher Model:\n",
       "- Test Accuracy: 0.9440\n",
       "\n",
       "Comparison with Distilled Models:\n",
       "1. Surrogate Model (LogisticRegression)\n",
       "   - Test Accuracy: 0.9474 (Δ: +0.0034)\n",
       "   - Distribution Similarity (R²): 0.9900\n",
       "\n",
       "2. Knowledge Distillation (LogisticRegression)\n",
       "   - Test Accuracy: 0.9474 (Δ: +0.0034)\n",
       "   - Distribution Similarity (R²): 0.9995\n",
       "\n",
       "Both distillation methods achieved similar accuracy but Knowledge Distillation produced better distribution matching.\n"
      ]
     }
    ],
    "source": [
     "# Compare with original teacher model\n",
     "print(\"Original Teacher Model:\")\n",
     "print(f\"- Test Accuracy: {test_accuracy:.4f}\")\n",
     "print()\n",
     "\n",
     "print(\"Comparison with Distilled Models:\")\n",
     "print(\"1. Surrogate Model (LogisticRegression)\")\n",
     "print(f\"   - Test Accuracy: {test_metrics['accuracy']:.4f} (Δ: {test_metrics['accuracy'] - test_accuracy:+.4f})\")\n",
     "print(f\"   - Distribution Similarity (R²): {test_metrics['r2_score']:.4f}\")\n",
     "print()\n",
     "print(\"2. Knowledge Distillation (LogisticRegression)\")\n",
     "print(f\"   - Test Accuracy: {test_metrics_kd['accuracy']:.4f} (Δ: {test_metrics_kd['accuracy'] - test_accuracy:+.4f})\")\n",
     "print(f\"   - Distribution Similarity (R²): {test_metrics_kd['r2_score']:.4f}\")\n",
     "print()\n",
     "print(\"Both distillation methods achieved similar accuracy but Knowledge Distillation produced better distribution matching.\")"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "## 9. Extracting Model Information\n",
     "\n",
     "Let's extract some information from our distilled model, such as parameters and feature importance."
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 11,
    "metadata": {},
    "outputs": [
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
       "Knowledge Distillation Model Information:\n",
       "- Model Type: LogisticRegression\n",
       "- Distillation Method: KnowledgeDistillation\n",
       "\n",
       "Feature Importance:\n",
       "- mean radius: 1.227\n",
       "- mean area: 0.812\n",
       "- mean perimeter: 0.623\n",
       "- mean texture: 0.343\n",
       "- mean smoothness: 0.151\n"
      ]
     }
    ],
    "source": [
     "# Get student model from knowledge distillation experiment\n",
     "kd_model = experiment_kd.distillation_model\n",
     "\n",
     "# Print model information\n",
     "print(\"Knowledge Distillation Model Information:\")\n",
     "print(f\"- Model Type: {kd_model.model.__class__.__name__}\")\n",
     "print(f\"- Distillation Method: {kd_model.__class__.__name__}\")\n",
     "print()\n",
     "\n",
     "# Extract feature importance\n",
     "if hasattr(kd_model.model, 'coef_'):\n",
     "    # For linear models like LogisticRegression\n",
     "    importance = abs(kd_model.model.coef_[0])\n",
     "    feature_importance = dict(zip(db_dataset.features, importance))\n",
     "    \n",
     "    # Sort features by importance\n",
     "    sorted_features = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)\n",
     "    \n",
     "    print(\"Feature Importance:\")\n",
     "    for feature, importance in sorted_features:\n",
     "        print(f\"- {feature}: {importance:.3f}\")"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "## 10. Making Predictions with the Distilled Model\n",
     "\n",
     "Now let's use our distilled model to make predictions on new data."
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 12,
    "metadata": {},
    "outputs": [
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
       "Example predictions from knowledge distillation model:\n",
       "   y_true  y_pred   prob_0   prob_1\n",
       "0       0       0  0.96244  0.03756\n",
       "1       0       0  0.75431  0.24569\n",
       "2       0       0  0.93902  0.06098\n",
       "3       1       1  0.05483  0.94517\n",
       "4       0       0  0.98437  0.01563\n",
       "\n",
       "Confusion Matrix:\n",
       "[[67  3]\n",
       " [ 3 41]]\n",
       "\n",
       "Classification Report:\n",
       "              precision    recall  f1-score   support\n",
       "\n",
       "           0       0.96      0.96      0.96        70\n",
       "           1       0.93      0.93      0.93        44\n",
       "\n",
       "    accuracy                           0.95       114\n",
       "   macro avg       0.94      0.94      0.94       114\n",
       "weighted avg       0.95      0.95      0.95       114\n"
      ]
     }
    ],
    "source": [
     "from sklearn.metrics import confusion_matrix, classification_report\n",
     "\n",
     "# Get predictions from the knowledge distillation model\n",
     "student_predictions = experiment_kd.get_student_predictions(dataset='test')\n",
     "\n",
     "# Display some example predictions\n",
     "print(\"Example predictions from knowledge distillation model:\")\n",
     "print(student_predictions.head())\n",
     "print()\n",
     "\n",
     "# Calculate confusion matrix\n",
     "cm = confusion_matrix(student_predictions['y_true'], student_predictions['y_pred'])\n",
     "print(\"Confusion Matrix:\")\n",
     "print(cm)\n",
     "print()\n",
     "\n",
     "# Generate classification report\n",
     "cr = classification_report(student_predictions['y_true'], student_predictions['y_pred'])\n",
     "print(\"Classification Report:\")\n",
     "print(cr)"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "## 11. Creating a Custom Example\n",
     "\n",
     "Let's create a custom example and make a prediction with our distilled model."
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 13,
    "metadata": {},
    "outputs": [
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
       "Custom example features:\n",
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness\n",
       "0        18.50         15.00          120.00     900.00           0.100\n",
       "\n",
       "Prediction: Malignant (1)\n",
       "Probability of malignancy: 0.89\n"
      ]
     }
    ],
    "source": [
     "# Create a custom example\n",
     "custom_example = pd.DataFrame({\n",
     "    'mean radius': [18.5],\n",
     "    'mean texture': [15.0],\n",
     "    'mean perimeter': [120.0],\n",
     "    'mean area': [900.0],\n",
     "    'mean smoothness': [0.10]\n",
     "})\n",
     "\n",
     "print(\"Custom example features:\")\n",
     "print(custom_example)\n",
     "print()\n",
     "\n",
     "# Make prediction with the distilled model\n",
     "# Get probability\n",
     "custom_prob = kd_model.predict_proba(custom_example)\n",
     "custom_class = kd_model.predict(custom_example)[0]\n",
     "\n",
     "# Convert class index to label (assuming 0=benign, 1=malignant)\n",
     "class_name = \"Malignant\" if custom_class == 1 else \"Benign\"\n",
     "\n",
     "print(f\"Prediction: {class_name} ({custom_class})\")\n",
     "print(f\"Probability of malignancy: {custom_prob[0, 1]:.2f}\")"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "## 12. Conclusion\n",
     "\n",
     "In this notebook, we demonstrated the use of DeepBridge's `DBDataset` and `Experiment` classes for model distillation. We:\n",
     "\n",
     "1. Created a complex \"teacher\" model using Random Forest\n",
     "2. Organized our data using the powerful `DBDataset` class\n",
     "3. Used the `Experiment` class to run distillation experiments with two different methods\n",
     "4. Compared the performance of our student models with the original teacher model\n",
     "5. Analyzed feature importance and made predictions with our distilled model\n",
     "\n",
     "Our results show that we successfully created simpler, more efficient models (using logistic regression) that maintained or even slightly improved the accuracy of the original complex model. Knowledge distillation produced better distribution matching than the surrogate approach.\n",
     "\n",
     "Model distillation is particularly valuable when you need to deploy models in resource-constrained environments or when inference speed is critical. The DeepBridge library makes this process straightforward and provides tools for comprehensive analysis and evaluation."
    ]
   }
  ],
  "metadata": {
   "kernelspec": {
    "display_name": "Python 3",
    "language": "python",
    "name": "python3"
   },
   "language_info": {
    "codemirror_mode": {
     "name": "ipython",
     "version": 3
    },
    "file_extension": ".py",
    "mimetype": "text/x-python",
    "name": "python",
    "nbconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": "3.8.10"
   }
  },
  "nbformat": 4,
  "nbformat_minor": 4
 }